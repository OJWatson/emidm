<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.43">

  <meta name="dcterms.date" content="2025-04-03">
  <title>emidm – Introduction to Deep Learning Frameworks with Python and PyTorch</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-fdaa6dbcb33b6dacc0bf34d8cf122307.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Introduction to Deep Learning Frameworks with Python and PyTorch</h1>
  <p class="subtitle">DIDE Training Series</p>

<div class="quarto-title-authors">
</div>

  <p class="date">April 3, 2025</p>
</section>
<section id="introduction" class="title-slide slide level1 smaller center">
<h1>Introduction</h1>
<ul>
<li><p>We’ll explore Python basics for R users, a new IDE (Positron), and deep learning concepts.</p></li>
<li><p><strong>Goal:</strong> Show you how to use <strong>PyTorch</strong> for training a surrogate infectious disease model.</p></li>
<li><p>Structure:</p>
<ul>
<li>2:00 - 2:30: Introduction Slides (python basics, positron, notebooks, deep learning)</li>
<li>2:30 - 3:00: Sharing Surrogate Notebook (making sure everyone can run Colab, everyone is zen 🧘)</li>
<li>3:00 - 3:30: Hands-on practice running PyTorch and checking it out</li>
<li>3:30 - 4:00: Extension exercises and wrap up</li>
</ul></li>
</ul>
</section>

<section>
<section id="introduction-to-python-for-r-users" class="title-slide slide level1 smaller center">
<h1>1. Introduction to Python for R Users</h1>

</section>
<section id="python-vs-r-syntax-structure-reminders" class="slide level2 smaller">
<h2>Python vs R: Syntax &amp; Structure Reminders</h2>
<ul>
<li><strong>Syntax:</strong> Python uses indentation instead of <code>{}</code>. No <code>&lt;-</code> assignment (use <code>=</code>).</li>
<li><strong>Indexing:</strong> Python indices start at 0 (R starts at 1). Slicing in Python excludes end index.</li>
<li><strong>Data structures:</strong> Python has lists, dicts, tuples (vs R’s vectors, lists, data frames). Python lists are heterogeneous like R lists.</li>
<li><strong>Example:</strong>
<ul>
<li>In Python, <code>mylist = [10, 20, 30]; mylist[0] = 10</code>.</li>
<li>In R, <code>myvec &lt;- c(10,20,30); myvec[1] = 10</code>.</li>
</ul></li>
</ul>
</section>
<section id="python-vs-r-deeper-overview" class="slide level2 smaller">
<h2>Python vs R: Deeper Overview</h2>
<ul>
<li><strong>Python Workshop:</strong> <a href="https://github.com/plietar/python-workshop/tree/main">Jesse and Paul python-workshop</a></li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">R</th>
<th style="text-align: left;">Python</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">whitespace</td>
<td style="text-align: left;">ignored</td>
<td style="text-align: left;">meaningful</td>
</tr>
<tr class="even">
<td style="text-align: left;">data frames &amp; stats</td>
<td style="text-align: left;">out-of-box</td>
<td style="text-align: left;">need package</td>
</tr>
<tr class="odd">
<td style="text-align: left;">packages</td>
<td style="text-align: left;">fussy</td>
<td style="text-align: left;">easy</td>
</tr>
<tr class="even">
<td style="text-align: left;">operate on language</td>
<td style="text-align: left;">yes</td>
<td style="text-align: left;">no</td>
</tr>
<tr class="odd">
<td style="text-align: left;">modifying variables</td>
<td style="text-align: left;">copy-on-modify</td>
<td style="text-align: left;">modify-in-place</td>
</tr>
<tr class="even">
<td style="text-align: left;">variable assignment</td>
<td style="text-align: left;"><code>&lt;-</code> (madness)</td>
<td style="text-align: left;"><code>=</code> (sane)</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>OJ Reflections on Above Table:</strong> 🤔</li>
</ul>
</section>
<section id="python-vs-r-deeper-overview-1" class="slide level2 smaller">
<h2>Python vs R: Deeper Overview</h2>
<ul>
<li><strong>Python Workshop:</strong> <a href="https://github.com/plietar/python-workshop/tree/main">Jesse and Paul python-workshop</a></li>
<li><strong>OJ Edits on Table:</strong> 🤔</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">R</th>
<th style="text-align: left;">Python</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">plotting</td>
<td style="text-align: left;">heavenly</td>
<td style="text-align: left;">hell</td>
</tr>
<tr class="even">
<td style="text-align: left;">documentation</td>
<td style="text-align: left;"><code>roxygen</code>❤️</td>
<td style="text-align: left;"><code>docstrings</code>😒</td>
</tr>
<tr class="odd">
<td style="text-align: left;">dependencies hell 😈</td>
<td style="text-align: left;">moderate</td>
<td style="text-align: left;">frequent</td>
</tr>
<tr class="even">
<td style="text-align: left;">virtual environments</td>
<td style="text-align: left;">less often</td>
<td style="text-align: left;">standard</td>
</tr>
</tbody>
</table>
</section></section>
<section>
<section id="positron-ide" class="title-slide slide level1 smaller center">
<h1>2. Positron IDE</h1>

</section>
<section id="what-is-positron" class="slide level2 smaller">
<h2>What is Positron?</h2>
<ul>
<li><strong>Positron</strong> is a next-generation IDE from Posit (RStudio) built on VS Code, tailored for data science. It feels like a blend of RStudio and VSCode in one interface.</li>
<li><strong>Polyglot support:</strong> Comes configured for both R <em>and</em> Python out of the box – you can run R scripts and Jupyter Python notebooks in the same environment.</li>
<li><strong>Familiar interface:</strong> Shares RStudio’s layout (source, console, plots, environment) with VSCode’s extensibility. This makes the transition easier for R users.</li>
<li><strong>Why use it?</strong> Simplifies working on projects that use R <strong>and</strong> Python together, without switching IDEs. Familiiar IDE experience for R users learning/transitioning to Python.</li>
</ul>
<p>(<a href="https://positron.posit.co/">Positron</a>) <em>Positron IDE combines a Visual Studio Code foundation with an RStudio-like layout, supporting multi-language notebooks and scripts (R and Python) seamlessly.</em></p>
</section>
<section id="benefits-for-r-users" class="slide level2 smaller">
<h2>Benefits for R Users</h2>
<ul>
<li><strong>Unified Workflow:</strong> Work with <code>.R</code> and <code>.py</code> files in one place, share workspace and variables. For example, run an R analysis then a Python machine learning step in one project.</li>
<li><strong>Jupyter integration:</strong> Built-in support for Jupyter notebooks (no separate JupyterLab needed).</li>
<li><strong>Extensions:</strong> Leverage VSCode extensions (linting, Git integration, etc.) in Positron. Most VSCode extensions (except a few Microsoft-specific) are available (<a href="https://www.andrewheiss.com/blog/2024/07/08/fun-with-positron/#:~:text=Extension%20page%20for%20Stan">Fun with Positron | Andrew Heiss – Andrew Heiss</a>).</li>
<li><strong>Transition ease:</strong> Minimal setup – Positron auto-detects R and Python installations. Familiar shortcuts (e.g.&nbsp;Ctrl+Enter to run code) work for both languages.</li>
<li><strong>REPL-like development experience:</strong> Positron has a REPL-style development environment, similar to RStudio. You can run code, see results, and modify the environment as you go, putting you closer to understanding the code you write.</li>
<li><strong>Bottom line: Positron lowers the barrier for R programmers to start incorporating Python into their workflow within a single IDE.</strong></li>
</ul>
</section>
<section id="google-colab" class="slide level2">
<h2>Google Colab</h2>
<p><a href="https://ojwatson.github.io/emidm/examples/notebooks_intro.html" data-preview-link="true" style="text-align: center">Intro to Colab Notebook</a></p>
</section></section>
<section>
<section id="deep-learning-basics" class="title-slide slide level1 smaller center">
<h1>3. Deep Learning Basics</h1>

</section>
<section id="what-is-deep-learning" class="slide level2 smaller">
<h2>What is Deep Learning?</h2>
<ul>
<li><strong>Definition:</strong> Deep learning is a subset of machine learning that uses multi-layered neural networks to simulate complex decision-making, akin to the human brain 🧠.</li>
<li><strong>Key idea:</strong> Instead of manual feature engineering, a deep neural network learns representations through layers of neurons.</li>
<li><strong>Why it matters:</strong> Achieved breakthroughs in many fields, takes advantage of GPUs, there is a small window where people think AI da 💣 and it’s on lots of grant calls… (Truth 💣).</li>
<li><strong>In short:</strong> Deep learning can automatically extract complex patterns from data, making it extremely powerful for modeling nonlinear relationships.</li>
</ul>
</section>
<section id="key-concepts-neural-networks" class="slide level2 smaller">
<h2>Key Concepts: Neural Networks</h2>
<ul>
<li><strong>Neurons &amp; Layers:</strong> Basic unit is a <em>neuron</em> (takes inputs, applies weights and activation). Neurons are organized into layers (input layer -&gt; hidden layers -&gt; output layer). Multiple hidden layers = a “deep” network.</li>
<li><strong>Activation Functions:</strong> Non-linear functions applied at neurons (e.g.&nbsp;ReLU, sigmoid). They enable networks to learn complex non-linear mappings.</li>
<li><strong>Loss Function:</strong> Metric that quantifies error between the network’s prediction and true values (e.g.&nbsp;mean squared error, cross-entropy). The network’s goal is to minimize this during training.</li>
<li><strong>Forward Propagation:</strong> Data flows through the network layer by layer to produce an output (prediction).</li>
<li><strong>Backpropagation:</strong> The training algorithm – compute the loss, then propagate the error gradients backward adjusting weights (via gradient descent). This is how the network “learns” from mistakes.</li>
<li><strong>Optimization:</strong> An optimizer (SGD, Adam, etc.) uses those gradients to update weights iteratively, gradually improving the model’s performance.</li>
<li><strong>In short:</strong>: At it’s core it’s quite simple stats, and more complex is the types of neural network architectures for different problems.</li>
</ul>
</section>
<section id="training-process-recap" class="slide level2 smaller">
<h2>Training Process Recap</h2>
<ul>
<li><strong>Initialize</strong> weights (often random small values).</li>
<li><strong>Forward pass:</strong> Input data -&gt; compute outputs and loss.</li>
<li><strong>Backward pass:</strong> Compute gradients of loss w.rt each weight (this is automatic via backpropagation).</li>
<li><strong>Weight update:</strong> Adjust weights using gradients (optimizer step).</li>
<li><strong>Epoch:</strong> A complete pass through the entire training dataset. Training typically requires multiple epochs to converge.</li>
<li><strong>Iterate:</strong> Repeat for many epochs (passes through data) until loss converges or performance is sufficient.</li>
<li><strong>Batch size:</strong> The number of training examples in a mini-batch. Affects training speed, memory usage, and generalization.</li>
<li><strong>Result:</strong> A trained neural network model that hopefully generalizes to new data.</li>
<li>Throughout training, we monitor metrics on a <strong>validation set</strong> to avoid overfitting. If validation performance plateaus or worsens, we consider techniques like early stopping or regularization.</li>
</ul>
</section></section>
<section>
<section id="introduction-to-pytorch" class="title-slide slide level1 smaller center">
<h1>4. Introduction to PyTorch</h1>

</section>
<section id="what-is-pytorch" class="slide level2 smaller">
<h2>What is PyTorch?</h2>
<ul>
<li><strong>PyTorch</strong> is an open-source deep learning framework based on Python (and Torch library). It’s one of the most popular platforms for deep learning research and deployment.</li>
<li>Developed by researchers at <strong>Facebook (Meta)</strong> in 2016, it accelerated from prototyping to production with a flexible, pythonic approach and is arguably one of the most robust and mature software ecosystems for deep learning.</li>
<li><strong>Dynamic computation graph:</strong> PyTorch uses a “define-by-run” approach – the neural network graph is built on the fly as you run code, making it intuitive to debug and modify.</li>
<li><strong>Why PyTorch?</strong>
<ul>
<li><em>Easy to learn:</em> Pythonic API feels natural if you know Python.</li>
<li><em>Flexibility:</em> Define complex models imperatively (no static graphs).</li>
<li><em>Community &amp; Ecosystem:</em> Huge community, lots of pre-trained models and tutorials. Backed by Meta and the open-source community (now part of Linux Foundation).</li>
</ul></li>
<li><strong>Usage:</strong> Widely used in academia and industry (Meta uses PyTorch to power all its AI workloads) and it has become a go-to framework for many application areas.</li>
</ul>
</section>
<section id="core-components-of-pytorch" class="slide level2 smaller">
<h2>Core Components of PyTorch</h2>
<ul>
<li><strong>Tensor:</strong> Fundamental data structure in PyTorch. A tensor is a homogeneous multi-dimensional array (similar to a NumPy array) that can be processed on CPU or GPU.
<ul>
<li>Example: <code>torch.tensor([[1,2],[3,4]])</code> is a 2x2 tensor of integers.</li>
</ul></li>
<li><strong>Autograd:</strong> PyTorch’s automatic differentiation engine. It records operations on tensors so that gradients can be computed via backpropagation. This means if you have a loss computed from tensors, you can call <code>.backward()</code> to get gradients of all parameters – no manual calculus needed.</li>
<li><strong><code>nn</code> Module:</strong> High-level neural network APIs. <code>torch.nn</code> provides building blocks like layers (Linear, Conv2d, LSTM, etc.), activation functions, loss functions, etc., to easily build complex networks.
<ul>
<li>You define a neural network as a class inheriting <code>nn.Module</code>, compose layers in the constructor, and define the forward pass. PyTorch takes care of gradient computation for the parameters.</li>
</ul></li>
<li><strong>Optimizers:</strong> <code>torch.optim</code> has algorithms like SGD, Adam for updating model parameters based on computed gradients.</li>
<li><strong>DataLoader:</strong> Utility to load and batch your dataset conveniently, with shuffling and parallel loading.</li>
<li><strong>Device:</strong> Specification of where tensors and models should be stored/executed (CPU or GPU). Example: <code>device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")</code></li>
</ul>
</section>
<section id="pytorch-in-action-basic-operations" class="slide level2 smaller">
<h2>PyTorch in Action: Basic Operations</h2>
<p>Let’s see a simple example creating a tensor, doing a computation, and using autograd to get gradients:</p>
<div id="a04af992" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a></a></span>
<span id="cb1-3"><a></a><span class="co"># Create a tensor with gradient tracking</span></span>
<span id="cb1-4"><a></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-5"><a></a><span class="co"># Perform operations on the tensor</span></span>
<span id="cb1-6"><a></a>y <span class="op">=</span> x <span class="op">*</span> <span class="dv">2</span>  <span class="co"># y = [2.0, 4.0, 6.0]</span></span>
<span id="cb1-7"><a></a>y_sum <span class="op">=</span> y.<span class="bu">sum</span>()  <span class="co"># y_sum = 12.0 (scalar tensor)</span></span>
<span id="cb1-8"><a></a><span class="co"># Compute gradients (dy_sum/dx)</span></span>
<span id="cb1-9"><a></a>y_sum.backward()  <span class="co"># backpropagate through the computation</span></span>
<span id="cb1-10"><a></a><span class="bu">print</span>(x.grad)  <span class="co"># Gradient of y_sum w.r.t x</span></span>
<span id="cb1-11"><a></a><span class="co"># Expected output: tensor([2., 2., 2.])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([2., 2., 2.])</code></pre>
</div>
</div>
<ul>
<li>In this example, <code>y = 2*x</code>, and <code>y_sum = 2*x1 + 2*x2 + 2*x3</code>. The gradient ∂(y_sum)/∂x = <code>[2, 2, 2]</code>, which PyTorch computes for us.</li>
<li>This illustrates how <strong>autograd</strong> frees us from manual gradient derivation. We can then use these gradients in an optimizer to update <code>x</code> (or, typically, model parameters) during training.</li>
<li>PyTorch’s imperative style means we used standard Python control flow to compute <code>y</code> and <code>y_sum</code>. The framework built the computation graph dynamically and handled differentiation under the hood.</li>
</ul>
</section></section>
<section>
<section id="deep-learning-in-infectious-disease-modeling" class="title-slide slide level1 smaller center">
<h1>5. Deep Learning in Infectious Disease Modeling</h1>

</section>
<section id="why-ai-in-epidemiology" class="slide level2 smaller">
<h2>Why AI in Epidemiology?</h2>
<ul>
<li><strong>Data-driven insights:</strong> Infectious disease modeling traditionally relies on differential equations and statistical models. Machine learning (ML) offers an alternative approach to identify patterns in epidemiological data (e.g.&nbsp;forecasting outbreaks from trends).</li>
<li><strong>Deep learning advantages:</strong> Ability to model complex, non-linear relationships. For instance, neural networks can capture patterns in time-series infection data that might be hard to specify in a parametric model.</li>
<li><strong>Large Development Community:</strong> PyTorch has a large and active community, with many pre-trained models and tutorials. Other popular tools such as Jax/flax underpin the development by large tech companies like Google and Meta, which likely predicates a more robust ecosystem and rapid development and contributions from the community.</li>
</ul>
</section>
<section id="why-ai-in-epidemiology-1" class="slide level2 smaller">
<h2>Why AI in Epidemiology?</h2>
<ul>
<li><strong>Enhancing traditional models:</strong> AI can be combined with mechanistic models. For example, researchers have integrated neural networks with compartmental models to help estimate parameters that are hard to infer otherwise (<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9970927/#:~:text=Differential%20equations,to%20solve%20the%20ordinary%20differential">Epi-DNNs: Epidemiological priors informed deep neural networks for modeling COVID-19 dynamics - PMC</a>). This can merge domain knowledge (e.g.&nbsp;SIR model structure) with data-driven flexibility.</li>
<li><strong>Physics-informed NN:</strong> There is a trend of <em>physics-informed neural networks</em> for epidemic forecasting (<a href="https://pubmed.ncbi.nlm.nih.gov/39876937/#:~:text=Physics,area%20of%20scientific%20machine%20learning">Physics-informed deep learning for infectious disease forecasting</a>) – these models incorporate the known dynamics (e.g.&nbsp;equations of disease spread) into the training of a neural network, ensuring predictions that respect known laws while still learning from data.</li>
</ul>
<p><img data-src="images/pinn.png" style="height:300px;"></p>
</section>
<section id="why-ai-in-epidemiology-2" class="slide level2 smaller">
<h2>Why AI in Epidemiology?</h2>
<ul>
<li><strong>Surrogate models:</strong> Using AI to approximate the input-output behavior of complex simulation models. This is particularly useful to speed up scenario analysis in infectious disease simulations that would otherwise be computationally intensive.</li>
<li><strong>It is likely going to be everywhere:</strong> <a href="https://www.nature.com/articles/s41586-024-08564-w">Artificial intelligence for modelling infectious disease epidemics</a></li>
</ul>
<p><img data-src="images/ID_ML.png" style="height:400px;"></p>
</section>
<section id="surrogate-modeling-bridging-simulation-and-ai" class="slide level2 smaller">
<h2>Surrogate Modeling: Bridging Simulation and AI</h2>
<ul>
<li><strong>What is a surrogate model?</strong> It’s an AI model trained to emulate another process or simulation. For infectious diseases, a surrogate model can learn to reproduce the outcomes of a complex epidemic simulation (e.g.&nbsp;an agent-based model or a stochastic SIR model), given certain inputs, but much faster.</li>
<li><strong>Why use it?</strong> Simulations (especially stochastic ones) can be slow when exploring many scenarios or doing real-time forecasting. A surrogate (once trained) runs almost instantly, allowing rapid experimentation or even real-time applications (like outbreak forecast updates).</li>
<li><strong>In epidemiology:</strong> Surrogates can learn the mapping from disease parameters (like transmission rate, recovery rate) to outputs of interest (like peak infected, time series of infections). Then we can query the surrogate for any parameter combination instead of rerunning the simulation.</li>
<li><strong>Considerations:</strong> Surrogate models need a comprehensive training dataset from the simulation (covering the range of scenarios). They should be validated to ensure they accurately reflect the simulation’s behavior, especially in the regime of interest (e.g.&nbsp;epidemic growth vs decline phases).</li>
</ul>
</section></section>
<section>
<section id="surrogate-modeling-for-epidemic-simulations" class="title-slide slide level1 smaller center">
<h1>6. Surrogate Modeling for Epidemic Simulations</h1>

</section>
<section id="case-study-surrogating-a-stochastic-sir-model" class="slide level2 smaller">
<h2>Case Study: Surrogating a Stochastic SIR Model</h2>
<ul>
<li>We’ll use the classic <strong>SIR model</strong> (Susceptible-Infectious-Recovered) as an example of building a surrogate. In a stochastic SIR simulation, each run with given parameters produces a trajectory of S, I, R over time.</li>
</ul>
<div id="f3131e10" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="im">from</span> emidm.sir <span class="im">import</span> run_sir, run_model_with_replicates, plot_model_outputs</span>
<span id="cb3-2"><a></a>plot_model_outputs(run_model_with_replicates(run_sir, reps<span class="op">=</span><span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="emidm_intro1_files/figure-revealjs/cell-3-output-1.png" width="960" height="480"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="emidm_intro1_files/figure-revealjs/cell-3-output-2.png" width="960" height="480"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="building-the-surrogate" class="slide level2 smaller">
<h2>Building the Surrogate</h2>
<ul>
<li><strong>1. Generate simulation data:</strong> Sample a range of parameter sets (e.g.&nbsp;transmission rate β, recovery rate γ, possibly initial population sizes). For each set, run the SIR simulation and record the resulting infection curves (S(t), I(t), R(t) over time).</li>
<li><strong>2. Prepare training dataset:</strong> From these runs, construct input-output pairs for learning. One approach is to provide the parameters (β, γ, time t) as inputs and the corresponding S, I, R at that time as outputs. (Alternatively, train a model that directly outputs the entire time-series given β and γ.)</li>
<li><strong>3. Train a neural network:</strong> Use PyTorch to define a network (for example, a simple feed-forward network or an RNN) that takes in parameters (and time) and outputs the state. Train it on the simulation data by minimizing the error between the network’s predicted epidemic curve and the simulation’s actual values.</li>
<li><strong>4. Validate the model:</strong> Test the surrogate on simulation runs it hasn’t seen. Check that it can predict the trajectory for new β, γ with reasonable accuracy (e.g., the peak and timing of infections match the simulation).</li>
<li><strong>5. Use the surrogate:</strong> Now you have a fast approximation of the SIR model. You can sweep through parameter space quickly, perform uncertainty quantification (by sampling many β, γ from distributions and getting outcomes rapidly), or embed this surrogate inside larger frameworks (e.g., optimization or real-time forecasting systems).</li>
</ul>
</section>
<section id="surrogate-notebook" class="slide level2 smaller">
<h2>Surrogate Notebook</h2>
<p><a href="https://github.com/OJWatson/emidm/blob/main/examples/surrogate_notebook.ipynb" data-preview-link="false">Training Surrogates</a></p>
</section></section>
<section id="conclusion-and-next-steps" class="title-slide slide level1 smaller center">
<h1>7. Conclusion and Next Steps</h1>
<ul>
<li>We introduced Python again for R users but perhaps in a way focussed on actually using IDEs and emulating Rstudio experience.</li>
<li>We covered deep learning fundamentals – from what neural networks are to how we train them – setting the stage for using these techniques in epidemiology.</li>
<li>With <strong>PyTorch</strong>, you have a powerful tool to implement deep learning models. We saw how tensors and autograd work, and ran through a simple example.</li>
<li>Machine learning and deep learning are increasingly important in infectious disease modeling and surrogate models can accelerate simulation-based research.</li>
<li><strong>Next steps:</strong>
<ul>
<li>Hands-on practice: try running a simple PyTorch model (e.g., fit a curve) in Positron.</li>
<li>Experiment with the SIR surrogate idea: simulate data in R, train a PyTorch model in Python.</li>
<li>Explore real datasets: Can you use a neural network to forecast cases? How would you incorporate domain knowledge?</li>
<li>Alternative surrogate approaches</li>
</ul></li>
</ul>
</section>

<section>
<section id="alernative-surrogate-approaches" class="title-slide slide level1 center">
<h1>8. Alernative Surrogate Approaches</h1>

</section>
<section id="conditional-variational-autoencoders-cvaes.-what-is-a-cvae" class="slide level2 smaller">
<h2>Conditional Variational Autoencoders (cVAEs). What is a cVAE?</h2>
<ul>
<li>A <strong>Conditional Variational Autoencoder (cVAE)</strong> is an extension of the Variational Autoencoder that incorporates additional information (conditions) into the generation process.</li>
<li><strong>Recap VAE:</strong> A VAE consists of an encoder that compresses input data into a latent distribution (usually a Gaussian in a low-dimensional space) and a decoder that reconstructs data from a sample of that latent distribution. It’s trained to reconstruct inputs while keeping latent variables meaningful (via a KL divergence regularization).</li>
<li><strong>Conditional part:</strong> In a cVAE, we “condition” both encoder and decoder on some extra context. For example, when dealing with images of digits, we can provide the digit label as a condition. The encoder then learns latent variables <em>given</em> that label, and the decoder can generate data conditioned on a specific label.</li>
</ul>
</section>
<section id="conditional-variational-autoencoders-cvaes.-what-is-a-cvae-1" class="slide level2 smaller">
<h2>Conditional Variational Autoencoders (cVAEs). What is a cVAE?</h2>
<ul>
<li><strong>Effect:</strong> This allows directed generation – e.g., “generate samples that look like digit 5” or, in our context, “generate epidemic curves under a certain scenario”. The latent space then captures variations <em>other than</em> the condition.
<ul>
<li>For digits, the label fixes which digit, and the latent variables can capture style (thickness of writing, slant, etc.).</li>
<li>For epidemics, one could imagine conditioning on, say, the basic reproduction number <span class="math inline">\(R_0\)</span> or other known factors, and the latent variables capture random effects or unknown influences.</li>
</ul></li>
<li><strong>Uncertainty modeling:</strong> cVAEs are useful for representing uncertainty. Instead of a single prediction, a cVAE can generate a <em>distribution</em> of possible outcomes for a given condition. For instance, given an initial infection count and <span class="math inline">\(R_0\)</span>, a cVAE could generate many possible epidemic trajectories (reflecting stochastic variations).</li>
</ul>
</section>
<section id="potential-application-of-cvae-in-epidemiology" class="slide level2 smaller">
<h2>Potential Application of cVAE in Epidemiology</h2>
<ul>
<li><strong>Scenario:</strong> We have many observed epidemic curves (from simulations or real data) under various conditions (e.g.&nbsp;different intervention strategies). We want to model the distribution of epidemic outcomes for a new condition.</li>
<li><strong>Using cVAE:</strong> We could train a cVAE where:
<ul>
<li>The input to the encoder is an epidemic trajectory with its condition (e.g.&nbsp;“with lockdown” vs “no lockdown”).</li>
<li>The condition is also fed into the decoder.</li>
<li>The cVAE learns a latent space of other factors (like unobserved socio-behavioral factors or stochastic effects).</li>
</ul></li>
<li>Once trained, for a given condition (say “lockdown from day 30”), we can sample different latent vectors to generate a variety of plausible epidemic curves that all reflect that condition. This gives a principled way to explore uncertainty and variability in outcomes.</li>
<li><strong>Why cVAE?</strong> Unlike a standard deterministic model, a cVAE provides a distribution of outcomes, not just one. This is valuable for risk assessment – e.g., what’s the worst-case scenario vs best-case scenario under a specific intervention?</li>
<li><strong>Note:</strong> This is an advanced technique and an active research area. It combines deep learning’s generative power with the need in epidemiology to quantify uncertainty.</li>
</ul>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="images/logos.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>Introduction to Deep Learning Frameworks with Python and PyTorch · DIDE Training Series · 03 April 2025</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/OJWatson\.github\.io\/emidm\/");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>