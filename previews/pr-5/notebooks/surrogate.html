
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Training Surrogates &#8212; emidm  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/surrogate';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introduction to Jupyter and Colab Notebooks" href="intro.html" />
    <link rel="prev" title="Bayesian Inference with Differentiable Models" href="bayesian_inference.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">emidm  documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide.html">
    User Guide
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development.html">
    Development Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../slides.html">
    Slides
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/OJWatson/emidm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide.html">
    User Guide
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../development.html">
    Development Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../slides.html">
    Slides
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/OJWatson/emidm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="calibration.html">Calibrating a Differentiable SIR Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_inference.html">Bayesian Inference with Differentiable Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Training Surrogates</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction to Jupyter and Colab Notebooks</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../tutorials.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Training Surrogates</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="training-surrogates">
<h1>Training Surrogates<a class="headerlink" href="#training-surrogates" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/OJWatson/emidm/blob/main/examples/surrogate_notebook.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>This notebook demonstrates how to generate data using a Susceptible-Infected-Recovered (SIR) model with the <code class="docutils literal notranslate"><span class="pre">emidm</span></code> package. The generated data can be used to train deep learning surrogates for infectious disease modeling.</p>
<p>The first two sections (<code class="docutils literal notranslate"><span class="pre">Generate</span> <span class="pre">Simulation</span> <span class="pre">Data</span></code> and <code class="docutils literal notranslate"><span class="pre">Prepare</span> <span class="pre">Training</span> <span class="pre">Dataset</span></code>) make use of <code class="docutils literal notranslate"><span class="pre">emidm</span></code> to generate our training data and are provided in brief to show what data is being generated and to ease into the notebook. The next three sections introduce how to train your surrogate model, validate this and explore ways of using this.</p>
<p>The last section are possible extensions for those who finish early, which ask you to think about tweaking the code used to test your understanding about how surrogates are trained, or to explore how to use them further analysis.</p>
<section id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Simulate SIR model dynamics using the <code class="docutils literal notranslate"><span class="pre">emidm</span></code> package.</p></li>
<li><p>Generate multiple realizations of the model with varying parameters.</p></li>
<li><p>Prepare the simulated data for training deep learning surrogates.</p></li>
<li><p>Train different surrogate models and compare these</p></li>
<li><p>Visualise performance of surrogates</p></li>
</ul>
</section>
<section id="enabling-gpu-acceleration">
<h2>Enabling GPU Acceleration<a class="headerlink" href="#enabling-gpu-acceleration" title="Link to this heading">#</a></h2>
<p>To utilize GPUs for faster training of our neural networks, we need to change the runtime type in your Colab notebook or similar cloud-based environments. Here are the general steps:</p>
<ol class="arabic simple">
<li><p>Navigate to Runtime Settings:</p></li>
</ol>
<ul class="simple">
<li><p>In Colab, go to ‚ÄúRuntime‚Äù &gt; ‚ÄúChange runtime type.‚Äù</p></li>
<li><p>In other environments, look for similar options in the settings or configuration menu.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Select Hardware Accelerator:</p></li>
</ol>
<ul class="simple">
<li><p>Choose ‚ÄúGPU‚Äù from the ‚ÄúHardware accelerator‚Äù dropdown menu.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Save and Restart Runtime:</p></li>
</ol>
<ul class="simple">
<li><p>Click ‚ÄúSave‚Äù to apply the changes. This will usually restart the runtime environment.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Verify GPU Availability:</p></li>
</ol>
<ul class="simple">
<li><p>After the restart, you can run a code snippet like this to confirm that the GPU is recognized and accessible.</p></li>
<li><p>You do not need to do this as we will check this later, but if you want to (and want to practice adding a code cell then plaese do</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

     <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
         <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is available!&quot;</span><span class="p">)</span>
         <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using device: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
     <span class="k">else</span><span class="p">:</span>
         <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is not available. Using CPU.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<p>We will be using the helper functions in the <code class="docutils literal notranslate"><span class="pre">emidm</span></code> package, which will be installed and all relevant modules from this as well as other required packages loaded below in two steps.</p>
<p>First we will install <code class="docutils literal notranslate"><span class="pre">emidm</span></code> from Github:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">OJWatson</span><span class="o">/</span><span class="n">emidm</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting git+https://github.com/OJWatson/emidm.git
  Cloning https://github.com/OJWatson/emidm.git to /tmp/pip-req-build-vwefrxg2
  Running command git clone --filter=blob:none --quiet https://github.com/OJWatson/emidm.git /tmp/pip-req-build-vwefrxg2
  Resolved https://github.com/OJWatson/emidm.git to commit 3708bab08df72a34ae788405142a8022a25ca52e
  Installing build dependencies ... ?25l?25hdone
  Getting requirements to build wheel ... ?25l?25hdone
  Preparing metadata (pyproject.toml) ... ?25l?25hdone
Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from emidm==0.1) (2.0.2)
Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from emidm==0.1) (2.2.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas-&gt;emidm==0.1) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas-&gt;emidm==0.1) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas-&gt;emidm==0.1) (2025.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;emidm==0.1) (1.17.0)
</pre></div>
</div>
</div>
</div>
<p>Next we will import any required modules once here. If this works then the rest of the notebook should work ü§û:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports from our own package</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">emidm.sir</span><span class="w"> </span><span class="kn">import</span> <span class="n">run_sir</span><span class="p">,</span> <span class="n">run_model_with_replicates</span><span class="p">,</span> <span class="n">plot_model_outputs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">emidm.sampler</span><span class="w"> </span><span class="kn">import</span> <span class="n">generate_lhs_samples</span>

<span class="c1"># imports of other common packages</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># for those who like me prescrbe to Hadley Wickham&#39;s one truth of a grammar of graphics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">plotnine</span><span class="w"> </span><span class="kn">import</span> <span class="n">ggplot</span><span class="p">,</span> <span class="n">aes</span><span class="p">,</span> <span class="n">geom_line</span><span class="p">,</span> <span class="n">facet_wrap</span>

<span class="c1"># for providing times on notebook for loops</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.notebook</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Import necessary libraries for neural networks and ML aspect</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReduceLROnPlateau</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="generate-simulation-data">
<h2>1. Generate Simulation Data<a class="headerlink" href="#generate-simulation-data" title="Link to this heading">#</a></h2>
<section id="running-a-single-sir-model-simulation">
<h3>Running a Single SIR Model Simulation<a class="headerlink" href="#running-a-single-sir-model-simulation" title="Link to this heading">#</a></h3>
<p>We can use <code class="docutils literal notranslate"><span class="pre">emidm</span></code> to ssimulate the SIR model dynamics using default parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Demonstrate running one model</span>
<span class="n">single</span> <span class="o">=</span> <span class="n">run_sir</span><span class="p">()</span>

<span class="c1"># Show the output</span>
<span class="n">single</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-25afb226-161f-4891-9c49-26fdcf3bf4d7" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>t</th>
      <th>N</th>
      <th>S</th>
      <th>I</th>
      <th>R</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1000</td>
      <td>990</td>
      <td>10</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1000</td>
      <td>988</td>
      <td>10</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1000</td>
      <td>986</td>
      <td>12</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>1000</td>
      <td>985</td>
      <td>10</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>1000</td>
      <td>984</td>
      <td>11</td>
      <td>5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>96</td>
      <td>1000</td>
      <td>206</td>
      <td>32</td>
      <td>762</td>
    </tr>
    <tr>
      <th>97</th>
      <td>97</td>
      <td>1000</td>
      <td>204</td>
      <td>33</td>
      <td>763</td>
    </tr>
    <tr>
      <th>98</th>
      <td>98</td>
      <td>1000</td>
      <td>201</td>
      <td>33</td>
      <td>766</td>
    </tr>
    <tr>
      <th>99</th>
      <td>99</td>
      <td>1000</td>
      <td>200</td>
      <td>32</td>
      <td>768</td>
    </tr>
    <tr>
      <th>100</th>
      <td>100</td>
      <td>1000</td>
      <td>200</td>
      <td>30</td>
      <td>770</td>
    </tr>
  </tbody>
</table>
<p>101 rows √ó 5 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-25afb226-161f-4891-9c49-26fdcf3bf4d7')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-25afb226-161f-4891-9c49-26fdcf3bf4d7 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-25afb226-161f-4891-9c49-26fdcf3bf4d7');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-19e80514-6cee-4a1f-8956-9930fea08c07">
  <button class="colab-df-quickchart" onclick="quickchart('df-19e80514-6cee-4a1f-8956-9930fea08c07')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-19e80514-6cee-4a1f-8956-9930fea08c07 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_9e42cf67-97db-4e65-bddd-9e8d90a18ad5">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('single')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_9e42cf67-97db-4e65-bddd-9e8d90a18ad5 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('single');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div></div>
</div>
<p>The output is a <code class="docutils literal notranslate"><span class="pre">pandas</span> <span class="pre">DataFrame</span></code> containing the number of susceptible (S), infected (I), and recovered (R) individuals over time.</p>
<p>To visualize the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show a single plot line</span>
<span class="n">single</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;t&#39;&gt;
</pre></div>
</div>
<img alt="../_images/2ed0c7dd22a00987fca071da2e43b7190932bae8c92fb311abb04eea12969cae.png" src="../_images/2ed0c7dd22a00987fca071da2e43b7190932bae8c92fb311abb04eea12969cae.png" />
</div>
</div>
<p>We can adjust parameters such as the transmission rate (<code class="docutils literal notranslate"><span class="pre">beta</span></code>) to observe different dynamics:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can also vary the parameters</span>
<span class="n">alt</span> <span class="o">=</span> <span class="n">run_sir</span><span class="p">(</span><span class="n">beta</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">alt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;t&#39;&gt;
</pre></div>
</div>
<img alt="../_images/c53a32c4f36df46ba3f4c972007b39ace1a2e1ae368eea96edd84de806b547a7.png" src="../_images/c53a32c4f36df46ba3f4c972007b39ace1a2e1ae368eea96edd84de806b547a7.png" />
</div>
</div>
</section>
<section id="running-multiple-stochastic-realisations">
<h3>Running Multiple Stochastic Realisations<a class="headerlink" href="#running-multiple-stochastic-realisations" title="Link to this heading">#</a></h3>
<p>To account for stochasticity, we can run multiple realizations of the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># we can run multiple realisations</span>
<span class="n">reps</span> <span class="o">=</span> <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">run_sir</span><span class="p">,</span> <span class="n">reps</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># and plot these</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">plot_model_outputs</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/b92c7d9c91a3b0504a9840aa293e804ac01696c829391faece027956d869da43.png"><img alt="../_images/b92c7d9c91a3b0504a9840aa293e804ac01696c829391faece027956d869da43.png" src="../_images/b92c7d9c91a3b0504a9840aa293e804ac01696c829391faece027956d869da43.png" style="width: 640px; height: 480px;" />
</a>
</div>
</div>
<p>And we can also pass through any of the arguments to <code class="docutils literal notranslate"><span class="pre">run_sir</span></code> to our <code class="docutils literal notranslate"><span class="pre">run_model_with_replicates</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># we can also by args to run_sir through kwargs</span>
<span class="n">reps</span> <span class="o">=</span> <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">run_sir</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># and plot these</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">plot_model_outputs</span><span class="p">(</span><span class="n">reps</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/5120e283cd2d5125cbd050f9364ea83887506771ac591983fb798094c19490dd.png"><img alt="../_images/5120e283cd2d5125cbd050f9364ea83887506771ac591983fb798094c19490dd.png" src="../_images/5120e283cd2d5125cbd050f9364ea83887506771ac591983fb798094c19490dd.png" style="width: 640px; height: 480px;" />
</a>
</div>
</div>
</section>
</section>
<section id="prepare-training-dataset">
<h2>2. Prepare Training Dataset<a class="headerlink" href="#prepare-training-dataset" title="Link to this heading">#</a></h2>
<section id="sampling-parameter-space-with-latin-hypercube-sampling">
<h3>Sampling Parameter Space with Latin Hypercube Sampling<a class="headerlink" href="#sampling-parameter-space-with-latin-hypercube-sampling" title="Link to this heading">#</a></h3>
<p>To systematically explore the parameter space, we use Latin Hypercube Sampling (LHS), which we have again provided helper functions from <code class="docutils literal notranslate"><span class="pre">emidm</span></code> for you to use.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># now to generate a lhs sample based on R0 and gamma</span>
<span class="k">def</span><span class="w"> </span><span class="nf">beta_gamma_from_r0_gamma</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">param_ranges</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="n">df_samples</span> <span class="o">=</span> <span class="n">generate_lhs_samples</span><span class="p">(</span><span class="n">param_ranges</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">df_samples</span> <span class="o">=</span> <span class="n">df_samples</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">beta</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;R0&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">])</span>
    <span class="n">df_samples</span> <span class="o">=</span> <span class="n">df_samples</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;R0&quot;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">df_samples</span>

<span class="n">param_ranges</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;R0&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]}</span>
<span class="n">df_samples</span> <span class="o">=</span> <span class="n">beta_gamma_from_r0_gamma</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">param_ranges</span> <span class="o">=</span> <span class="n">param_ranges</span><span class="p">)</span>
<span class="n">df_samples</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-33973c68-fe96-491c-beae-8090ce5d3f9d" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gamma</th>
      <th>beta</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.129136</td>
      <td>0.401118</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.101170</td>
      <td>0.148495</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.183875</td>
      <td>0.374429</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.165865</td>
      <td>0.569336</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.084436</td>
      <td>0.198222</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.140516</td>
      <td>0.409444</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.231716</td>
      <td>0.878792</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.067172</td>
      <td>0.172515</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.226360</td>
      <td>0.281483</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-33973c68-fe96-491c-beae-8090ce5d3f9d')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-33973c68-fe96-491c-beae-8090ce5d3f9d button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-33973c68-fe96-491c-beae-8090ce5d3f9d');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-ffc334e8-f40d-4fc8-a97e-55eabd5678f8">
  <button class="colab-df-quickchart" onclick="quickchart('df-ffc334e8-f40d-4fc8-a97e-55eabd5678f8')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-ffc334e8-f40d-4fc8-a97e-55eabd5678f8 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_17f1659d-73d1-4186-8205-2fc06d832298">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('df_samples')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_17f1659d-73d1-4186-8205-2fc06d832298 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('df_samples');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div></div>
</div>
<p>This generates a set of parameter combinations, which we can then pass to our <code class="docutils literal notranslate"><span class="pre">run_model_with_replicates</span></code> function. We have just used 9 samples here initially just to show you the outputs and understand it. Later we will generate more samples to build a robust training dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the model for each row of samples:</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">reps</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df_samples</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()</span>
<span class="p">]</span>

<span class="c1"># Combine results into one DataFrame:</span>
<span class="n">df_all_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reshape dataframe into tidy long-format</span>
<span class="n">df_long</span> <span class="o">=</span> <span class="n">df_all_results</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span>
    <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="s2">&quot;replicate&quot;</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">],</span>
    <span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">],</span>
    <span class="n">var_name</span><span class="o">=</span><span class="s2">&quot;Compartment&quot;</span><span class="p">,</span>
    <span class="n">value_name</span><span class="o">=</span><span class="s2">&quot;Value&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Add unique identifier for group plotting</span>
<span class="n">df_long</span> <span class="o">=</span> <span class="n">df_long</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">uid</span><span class="o">=</span><span class="n">df_long</span><span class="p">[</span><span class="s2">&quot;Compartment&quot;</span><span class="p">]</span>
    <span class="o">+</span> <span class="n">df_long</span><span class="p">[</span><span class="s2">&quot;replicate&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Add facet identifier for group plotting</span>
<span class="n">df_long</span> <span class="o">=</span> <span class="n">df_long</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">facet</span><span class="o">=</span><span class="s2">&quot;beta = &quot;</span>
    <span class="o">+</span> <span class="n">df_long</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
    <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="o">+</span> <span class="s2">&quot;gamma = &quot;</span>
    <span class="o">+</span> <span class="n">df_long</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Plot: color by compartment, lines grouped by replicate</span>
<span class="n">p</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span>
        <span class="n">df_long</span><span class="p">,</span>
        <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Value&quot;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;uid&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;Compartment&quot;</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">facet_wrap</span><span class="p">(</span><span class="s2">&quot;facet&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Explicitly plot</span>
<span class="n">ggplot</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/318879a6d2b20b3e836b249d738708b1660ba6abef102c6c5c1ab3a3a2d87232.png"><img alt="../_images/318879a6d2b20b3e836b249d738708b1660ba6abef102c6c5c1ab3a3a2d87232.png" src="../_images/318879a6d2b20b3e836b249d738708b1660ba6abef102c6c5c1ab3a3a2d87232.png" style="width: 640px; height: 480px;" />
</a>
</div>
</div>
</section>
<section id="generating-training-and-test-data">
<h3>Generating Training and Test Data<a class="headerlink" href="#generating-training-and-test-data" title="Link to this heading">#</a></h3>
<p>Now that we have seen how LHS is being used to sample different $\beta$ and $\gamma$ parameters and to generate simulations, we will now generate training, validation and test data in much the same way:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set random seed for reproducibility</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Create output directory for saving models and plots</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;emulator_results&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># larger training data</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_valid</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># generate train samples and data</span>
<span class="n">train_samples</span> <span class="o">=</span> <span class="n">beta_gamma_from_r0_gamma</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">param_ranges</span> <span class="o">=</span> <span class="n">param_ranges</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">reps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_samples</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_samples</span><span class="p">))</span>
<span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># generate test samples</span>
<span class="n">test_samples</span> <span class="o">=</span> <span class="n">beta_gamma_from_r0_gamma</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_test</span><span class="p">,</span> <span class="n">param_ranges</span> <span class="o">=</span> <span class="n">param_ranges</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">reps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_samples</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_samples</span><span class="p">))</span>
<span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># generate valid samples</span>
<span class="n">valid_samples</span> <span class="o">=</span> <span class="n">beta_gamma_from_r0_gamma</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_valid</span><span class="p">,</span> <span class="n">param_ranges</span> <span class="o">=</span> <span class="n">param_ranges</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">reps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="o">.</span><span class="n">to_dict</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">valid_samples</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_samples</span><span class="p">))</span>
<span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "55f207ca6b89414690459becb05bb00e"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "fb99d36aa2a543e0885db1d5a74479a0"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "54a1b342527b46a58fae719e10a93ae9"}</script></div>
</div>
</section>
</section>
<section id="train-a-neural-network">
<h2>3. Train a neural network<a class="headerlink" href="#train-a-neural-network" title="Link to this heading">#</a></h2>
<section id="creating-dataset-class-and-dataloader">
<h3>Creating Dataset Class and Dataloader<a class="headerlink" href="#creating-dataset-class-and-dataloader" title="Link to this heading">#</a></h3>
<p>While we have generated our training and test data, we need to prepare it into a PyTorch dataset and dataloader. The dataloader is a way of iterating through our data in batches, which is useful for training deep learning models. Batches are used to train the model in mini-batches, which is more efficient than training on the entire dataset at once. It also has the advantage of allowing us to use GPU acceleration if available.</p>
<p>We have not created this dataset class yet in <code class="docutils literal notranslate"><span class="pre">emidm</span></code>, so that we can show you how it works, so we will do that next. We will also use this an opportunity to learn a bit more about PyTorch and also how (more often) Python leverages classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SIRTimeSeriesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataframe</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">],</span> <span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span>

        <span class="c1"># Group by parameter sets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grouped</span> <span class="o">=</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">features</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;replicate&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_sets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grouped</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataframe</span> <span class="o">=</span> <span class="n">dataframe</span>

        <span class="c1"># Extract timepoints (assuming they&#39;re the same for all parameter sets)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timepoints</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="s1">&#39;t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">timepoints</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="s1">&#39;N&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Create samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">param_set</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_sets</span><span class="p">:</span>
            <span class="n">df_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grouped</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="n">param_set</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>

            <span class="c1"># Extract feature and target time series</span>
            <span class="n">feature_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">param_set</span><span class="p">[</span><span class="n">features</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">)],</span>
                                      <span class="n">param_set</span><span class="p">[</span><span class="n">features</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;gamma&#39;</span><span class="p">)]])</span>

            <span class="c1"># Extract full target time series</span>
            <span class="n">target_series</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">df_group</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">])</span>

            <span class="c1"># Store full time series with parameter info</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;features&#39;</span><span class="p">:</span> <span class="n">feature_values</span><span class="p">,</span>
                <span class="s1">&#39;targets&#39;</span><span class="p">:</span> <span class="n">target_series</span><span class="p">,</span>
                <span class="s1">&#39;param_values&#39;</span><span class="p">:</span> <span class="n">param_set</span>
            <span class="p">})</span>

        <span class="c1"># Normalize input features</span>
        <span class="n">feature_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feature_array</span><span class="p">)</span>

        <span class="c1"># No need to normalize S and I as they&#39;re already in [0,1] range</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># Normalize features</span>
        <span class="n">features_normalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">features_normalized</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> \
               <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;targets&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Having made our daa<code class="docutils literal notranslate"><span class="pre">SIRTimeSeriesDataset</span></code> class, we can use this to create a <code class="docutils literal notranslate"><span class="pre">SIRTimeSeriesDataset</span></code> object for each of our different data sets (train, validation, test).</p>
<p>After this we then create <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code>. This is a PyTorch class used to efficiently iterate through the datasets during training. It handles tasks like batching, shuffling (for the training set), and potentially loading data in parallel.</p>
<p>Batching controls the size of the data that will be fed to the model, which here we are doing in groups of 64 samples at a time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create datasets</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">SIRTimeSeriesDataset</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">SIRTimeSeriesDataset</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">SIRTimeSeriesDataset</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1"># Create data loaders</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="batch-size-explained">
<h4>Batch Size Explained<a class="headerlink" href="#batch-size-explained" title="Link to this heading">#</a></h4>
<p>In the code above, <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is set to 64. This means that during training, the model will see 64 samples of data before updating its internal parameters (weights and biases). This process of seeing a batch of data and then updating is called one <strong>iteration</strong>.</p>
<p>Instead of training on the entire dataset at once (which can be computationally expensive and memory-intensive), the data is divided into smaller batches. The model iterates through these batches, making adjustments to its parameters after seeing each batch.</p>
<section id="why-use-batches">
<h5><em>Why Use Batches?</em><a class="headerlink" href="#why-use-batches" title="Link to this heading">#</a></h5>
<p><strong>1. Computational Efficiency:</strong> Processing the entire dataset in one go can be very slow, especially for large datasets. Batches make the process more manageable by breaking it down into smaller steps. This is crucial for training deep learning models which often require vast amounts of data.</p>
<p><strong>2. Memory Management:</strong> Loading the entire dataset into memory might not be feasible, especially when dealing with very large datasets or limited hardware resources. Batching allows the model to work with a smaller subset of the data at any given time, reducing memory requirements.</p>
<p><strong>3. Generalization:</strong> Training on batches can improve the model‚Äôs ability to generalize to unseen data. This is because the model is exposed to a variety of data points in each batch, preventing it from overfitting to specific examples in the training set. Updates based on a single data point at a time (e.g., with a batch size of 1 which is called stochastic gradient descent) could update the weights in a way that is not good for the model‚Äôs prediction performance over all of the data. Using batches provides a better average for what data the model tends to see and thus better update performance.</p>
<p><strong>4. Noise Reduction:</strong> The gradients (directions for updating model parameters) calculated on a batch are less noisy compared to those calculated on individual samples. This leads to more stable and smoother training, potentially helping the model converge faster to a good solution.</p>
</section>
<section id="choosing-the-right-batch-size">
<h5><em>Choosing the Right Batch Size</em><a class="headerlink" href="#choosing-the-right-batch-size" title="Link to this heading">#</a></h5>
<p>The choice of batch size is a hyperparameter that can significantly impact the training process. There‚Äôs no one-size-fits-all answer, and the optimal batch size often depends on factors like:</p>
<p><strong>1. Dataset Size:</strong> Larger datasets can handle larger batch sizes, while smaller datasets might require smaller batches to avoid overfitting.
<strong>2. Model Architecture:</strong> Complex models with many parameters might benefit from larger batch sizes for better gradient estimations.
<strong>3. Hardware:</strong> Available memory and processing power influence the maximum batch size you can use.
<strong>4. Training Time:</strong> Larger batches can lead to faster training epochs (one pass through the entire dataset), but they might require more epochs to converge. Smaller batches require more iterations per epoch and are usually slower but are helpful in preventing issues like overfitting.</p>
</section>
<section id="in-practice">
<h5><em>In Practice:</em><a class="headerlink" href="#in-practice" title="Link to this heading">#</a></h5>
<ul class="simple">
<li><p>Common Batch Sizes: 32, 64, 128, 256 are frequently used batch sizes.</p></li>
<li><p>Experimentation: It‚Äôs often necessary to experiment with different batch sizes to find the best one for a particular problem. You can evaluate performance on a validation set to guide your choice.</p></li>
</ul>
</section>
</section>
</section>
<section id="building-neural-network-models">
<h3>Building Neural Network Models<a class="headerlink" href="#building-neural-network-models" title="Link to this heading">#</a></h3>
<p>This section of the code defines and trains three different types of neural networks to predict the Susceptible (S) and Infected (I) populations in the SIR model given the input parameters beta and gamma.</p>
<p>Before we delve into the specific model types, let‚Äôs define some key terminology in neural networks:</p>
<ul class="simple">
<li><p><strong>Input Size:</strong> The number of input features to the network. In this case, it‚Äôs 2, representing beta and gamma.</p></li>
<li><p><strong>Hidden Size:</strong> The number of neurons in the hidden layers of the network. This controls the complexity and capacity of the model. A larger hidden size means the model can learn more complex patterns but might be prone to overfitting. Here, hidden_size is set to 64.</p></li>
<li><p><strong>Output Size:</strong> The number of output values the network produces. Here, it‚Äôs 2, corresponding to the predicted S and I values.</p></li>
<li><p><strong>Layers:</strong> Neural networks consist of interconnected layers of neurons. Hidden layers process the input data and extract features, while the output layer produces the final predictions. Deeper networks (more hidden layers) can learn more complex relationships, but they are also more computationally intensive to train. This code uses hidden layers.</p></li>
<li><p><strong>Dropout:</strong> A regularization technique that helps prevent overfitting. During training, dropout randomly ignores a fraction of the neurons in a layer, forcing the network to learn more robust features that are not dependent on any single neuron. dropout_prob (set to 0.1 here) controls the probability of a neuron being dropped out.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define constants</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># beta and gamma</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># S and I</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dropout_prob</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>
</div>
</div>
</div>
<section id="feedforward-neural-network-ffnn">
<h4>Feedforward Neural Network (FFNN)<a class="headerlink" href="#feedforward-neural-network-ffnn" title="Link to this heading">#</a></h4>
<p>This is the simplest type of neural network, where data flows in one direction from input to output. It has multiple layers, each containing a number of neurons (or units). It uses dropout for regularization, with a probability defined by dropout_prob that a neuron is ignored in a given step. It also has batch normalization and ReLU activation function for each hidden layer.</p>
<p>In our case, The FFNN model takes $\beta$ and $\gamma$ as input and aims to predict the time series of <code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> values. Here‚Äôs a simplified breakdown of how it works:</p>
<ul class="simple">
<li><p><strong>Input:</strong> The input values (beta and gamma) are fed into the first layer of the network.</p></li>
<li><p><strong>Hidden Layers:</strong> The input values are processed through a series of hidden layers. Each layer consists of neurons that perform calculations on the input data using weights and biases.</p>
<ul>
<li><p>The output of each neuron is passed through an activation function (ReLU here), which introduces non-linearity to the model.</p></li>
<li><p>Dropout is applied within the hidden layers to prevent overfitting.</p></li>
<li><p>Batch normalization is used to improve training stability and performance by normalizing the inputs to each layer.</p></li>
</ul>
</li>
<li><p><strong>Output Layer:</strong> The final hidden layer‚Äôs output is fed to the output layer, which produces the predictions for <code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code>. The output uses a sigmoid activation function, ensuring output values are between 0 and 1, representing the proportion of the population.</p></li>
<li><p><strong>Training:</strong> During training, the network‚Äôs weights and biases are adjusted to minimize the difference between the predicted and actual <code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> values (the loss). This adjustment is done using an optimization algorithm like Adam.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Feedforward Neural Network</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FFNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FFNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_steps</span> <span class="o">=</span> <span class="n">time_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

        <span class="c1"># Deeper network with dropout and batch normalization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_prob</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_prob</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_prob</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">time_steps</span> <span class="o">*</span> <span class="n">output_channels</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output shape: [batch_size, time_steps, output_channels]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>  <span class="c1"># Apply sigmoid</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="gated-recurrent-unit-gru">
<h4>Gated Recurrent Unit (GRU)<a class="headerlink" href="#gated-recurrent-unit-gru" title="Link to this heading">#</a></h4>
<p>This is a type of recurrent neural network (RNN) that is designed to handle sequential data, like the time series data from the SIR model. GRUs have a special mechanism called ‚Äúgates‚Äù that help them learn long-term dependencies in the data. The key features of GRUs are:</p>
<ul class="simple">
<li><p><strong>Update Gate:</strong> Decides how much past information to keep and how much to update.</p></li>
<li><p><strong>Reset Gate:</strong> Controls how much past information to ignore when computing the new state.</p></li>
<li><p><strong>Hidden State:</strong> Represents the current input and relevant past information.</p></li>
</ul>
<p><strong>How it Works Here:</strong></p>
<ul class="simple">
<li><p>Inside the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of the <code class="docutils literal notranslate"><span class="pre">GRUModel</span></code>, this input vector is projected to a higher-dimensional space and then repeated for each time step to create a sequence (<code class="docutils literal notranslate"><span class="pre">x_seq</span></code>). This effectively creates a constant input sequence where the same <code class="docutils literal notranslate"><span class="pre">beta</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> values are presented to the GRU at each time step.</p></li>
<li><p>The GRU layer then processes this input sequence, but its primary focus is on learning the temporal relationships within the output sequence (<code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> over time). The hidden state of the GRU evolves based on both the input and the previous hidden state, capturing the dynamic changes in <code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> as the SIR model progresses.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRU Model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">GRUModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRUModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

        <span class="c1"># Project parameters to a sequence</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># GRU layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_prob</span> <span class="k">if</span> <span class="n">num_layers</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># Output layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_prob</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">time_length</span>

        <span class="c1"># Create a sequence from the parameter input</span>
        <span class="n">x_seq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_projection</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Process with GRU</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Apply sigmoid activation</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="long-short-term-memory-lstm">
<h4>Long Short-Term Memory (LSTM)<a class="headerlink" href="#long-short-term-memory-lstm" title="Link to this heading">#</a></h4>
<p>This is another type of RNN, closely related to GRUs, also designed to handle sequential data like the time series from the SIR model. LSTMs use a more complex gating mechanism than GRUs, involving three gates (input, forget, output) and a cell state, enabling them to learn long-term dependencies and handle vanishing gradients effectively. The key features of LSTMs are:</p>
<ul class="simple">
<li><p><strong>Input Gate:</strong> Regulates the flow of new information into the cell state.</p></li>
<li><p><strong>Forget Gate:</strong> Controls what information to discard from the cell state.</p></li>
<li><p><strong>Output Gate:</strong> Determines what information from the cell state is outputted.</p></li>
<li><p><strong>Cell State:</strong> Acts as a memory unit, storing and carrying information across time steps.</p></li>
<li><p><strong>Hidden State:</strong> Represents the current output and is influenced by the cell state and the output gate.</p></li>
</ul>
<p><strong>How it Works Here:</strong></p>
<p>Similar to the GRU, inside the forward method of the <code class="docutils literal notranslate"><span class="pre">LSTMModel</span></code>, the input vector is projected to a higher-dimensional space and repeated for each time step to form a sequence (<code class="docutils literal notranslate"><span class="pre">x_seq</span></code>). This creates a constant input sequence where the same beta and gamma values are presented to the LSTM at each time step.</p>
<p>The LSTM layer processes this input sequence, but its primary focus is on learning the temporal relationships within the output sequence (<code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> over time). Using its three gates and the cell state, the LSTM carefully controls the flow of information, allowing it to selectively remember and forget relevant parts of the past while updating its hidden state to capture the dynamic changes in <code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> as the SIR model progresses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># LSTM Model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LSTMModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTMModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

        <span class="c1"># Project parameters to a sequence</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># LSTM layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_prob</span> <span class="k">if</span> <span class="n">num_layers</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># Output layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_prob</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">time_length</span>

        <span class="c1"># Create a sequence from the parameter input</span>
        <span class="n">x_seq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_projection</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Process with LSTM</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># Apply sigmoid activation</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="creating-and-training-our-models">
<h3>Creating and Training Our Models<a class="headerlink" href="#creating-and-training-our-models" title="Link to this heading">#</a></h3>
<p>Now that we have created our NN classes, we can initialise these models, and determine whether a GPU is available for computation (it should be if you changed your Runtime earlier).</p>
<p>If a GPU is found (<code class="docutils literal notranslate"><span class="pre">torch.cuda.is_available()</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code>), it sets the device to ‚Äòcuda‚Äô (indicating GPU usage); otherwise, it defaults to ‚Äòcpu‚Äô for CPU-based calculations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize models</span>
<span class="n">ffnn_model</span> <span class="o">=</span> <span class="n">FFNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">time_length</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
<span class="n">gru_model</span> <span class="o">=</span> <span class="n">GRUModel</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">lstm_model</span> <span class="o">=</span> <span class="n">LSTMModel</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>

<span class="c1"># Move models to GPU if available</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">ffnn_model</span> <span class="o">=</span> <span class="n">ffnn_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gru_model</span> <span class="o">=</span> <span class="n">gru_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">lstm_model</span> <span class="o">=</span> <span class="n">lstm_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Models initialized and moved to </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Models initialized and moved to cuda
</pre></div>
</div>
</div>
</div>
<section id="model-training">
<h4>Model Training<a class="headerlink" href="#model-training" title="Link to this heading">#</a></h4>
<p>Below, we have provided the <code class="docutils literal notranslate"><span class="pre">train_model</span></code> function, which trains the neural network models using the following steps:</p>
<ol class="arabic simple">
<li><p><strong>Initialization:</strong></p>
<ul class="simple">
<li><p>Defines the loss function (<code class="docutils literal notranslate"><span class="pre">nn.MSELoss</span></code> for Mean Squared Error).</p></li>
<li><p>Sets up the optimizer (<code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code>) to update model parameters.</p></li>
<li><p>Creates a learning rate scheduler (<code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>) to adjust the learning rate by a factor (here, 0.5) when the validation stops improving for a certain number of epochs (here, <code class="docutils literal notranslate"><span class="pre">patience=5</span></code>).</p></li>
<li><p>Early stopping criterria are also set, so if there is no improvement in validation loss for a number of epochs (here, <code class="docutils literal notranslate"><span class="pre">patience=10</span></code>), then training is stopped earlier.</p></li>
</ul>
</li>
<li><p><strong>Training Loop:</strong></p>
<ul class="simple">
<li><p>Iterates through a specified number of epochs.</p></li>
<li><p><strong>Training Phase:</strong></p>
<ul>
<li><p>The model is set to training mode (<code class="docutils literal notranslate"><span class="pre">model.train()</span></code>).</p></li>
<li><p>Processes batches of training data, making predictions and calculating the loss:</p>
<ul>
<li><p><em>Forward Pass:</em> The model makes predictions (outputs) based on the input data (inputs).</p></li>
<li><p><em>Calculate Loss:</em> The loss function (criterion) is used to calculate the error between the predictions (outputs) and the actual target values (targets)</p></li>
<li><p><em>Backward Pass and Optimise:</em> <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code> resets the gradients of the model‚Äôs parameters. <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> calculates the gradients of the loss with respect to the model‚Äôs parameters. <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code> updates the model‚Äôs parameters based on the calculated gradients and the learning rate.</p></li>
</ul>
</li>
<li><p>Tracks the average training loss for the epoch.</p></li>
</ul>
</li>
<li><p><strong>Validation Phase:</strong></p>
<ul>
<li><p>The model is set to evaluation mode (<code class="docutils literal notranslate"><span class="pre">model.eval()</span></code>).</p></li>
<li><p>Processes batches of validation data, making predictions and calculating the validation loss (without updating model parameters).</p></li>
<li><p>Tracks the average validation loss for the epoch.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Model Saving and Early Stopping:</strong></p>
<ul class="simple">
<li><p>Saves the best model (lowest validation loss) during training.</p></li>
<li><p>Implements early stopping to prevent overfitting if the validation loss doesn‚Äôt improve for a certain number of epochs.</p></li>
</ul>
</li>
<li><p><strong>Returning Results:</strong></p>
<ul class="simple">
<li><p>Returns the trained model and a history dictionary containing training and validation losses, epochs, and information about the best model.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Initialize criterion, optimizer and scheduler</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># For tracking loss and best model</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
    <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Path to save best model</span>
    <span class="n">best_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_best.pt&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Training phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">total_train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Forward pass</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Calculate loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

            <span class="c1"># Backward pass and optimize</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Calculate average training loss</span>
        <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">total_train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span>

        <span class="c1"># Validation phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">total_val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># Forward pass</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

                <span class="c1"># Calculate loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
                <span class="n">total_val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Calculate average validation loss</span>
        <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="n">total_val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_val_loss</span><span class="p">)</span>

        <span class="c1"># Update scheduler</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">avg_val_loss</span><span class="p">)</span>

        <span class="c1"># Print progress every 10 epochs</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1"> - &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;Train Loss: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Loss: </span><span class="si">{</span><span class="n">avg_val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1"># Check if this is the best model so far</span>
        <span class="k">if</span> <span class="n">avg_val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">avg_val_loss</span>
            <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
            <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Save the best model</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
                <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">avg_val_loss</span><span class="p">,</span>
                <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">avg_train_loss</span>
            <span class="p">},</span> <span class="n">best_model_path</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New best model saved at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> with validation loss: </span><span class="si">{</span><span class="n">avg_val_loss</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation loss did not improve. Patience: </span><span class="si">{</span><span class="n">patience_counter</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">patience</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Early stopping check</span>
        <span class="k">if</span> <span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="n">patience</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping triggered after </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> epochs. Best was epoch </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="c1"># Save training history</span>
    <span class="n">history</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">,</span>
        <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">val_losses</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="s1">&#39;best_epoch&#39;</span><span class="p">:</span> <span class="n">best_epoch</span><span class="p">,</span>
        <span class="s1">&#39;best_val_loss&#39;</span><span class="p">:</span> <span class="n">best_val_loss</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_history.json&quot;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="c1"># Load the best model</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">best_model_path</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">history</span>

</pre></div>
</div>
</div>
</div>
<p>We can now actually train our models!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set training parameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">patience</span> <span class="o">=</span> <span class="mi">10</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training FFNN model...&quot;</span><span class="p">)</span>
<span class="n">ffnn_model</span><span class="p">,</span> <span class="n">ffnn_history</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
    <span class="n">ffnn_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="s2">&quot;ffnn&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">patience</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training GRU model...&quot;</span><span class="p">)</span>
<span class="n">gru_model</span><span class="p">,</span> <span class="n">gru_history</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
    <span class="n">gru_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="s2">&quot;gru&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">patience</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training LSTM model...&quot;</span><span class="p">)</span>
<span class="n">lstm_model</span><span class="p">,</span> <span class="n">lstm_history</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span>
    <span class="n">lstm_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="s2">&quot;lstm&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">patience</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training FFNN model...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>New best model saved at epoch 1 with validation loss: 0.005242
New best model saved at epoch 2 with validation loss: 0.003290
New best model saved at epoch 3 with validation loss: 0.002707
New best model saved at epoch 9 with validation loss: 0.002256
Epoch 10/100, ffnn - Train Loss: 0.0037, Val Loss: 0.0023
Validation loss did not improve. Patience: 1/10
New best model saved at epoch 12 with validation loss: 0.002102
Epoch 20/100, ffnn - Train Loss: 0.0033, Val Loss: 0.0021
Validation loss did not improve. Patience: 8/10
Early stopping triggered after 22 epochs. Best was epoch 12.
Training GRU model...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>New best model saved at epoch 1 with validation loss: 0.011058
New best model saved at epoch 2 with validation loss: 0.006320
New best model saved at epoch 3 with validation loss: 0.003598
New best model saved at epoch 4 with validation loss: 0.002484
New best model saved at epoch 9 with validation loss: 0.002197
Epoch 10/100, gru - Train Loss: 0.0025, Val Loss: 0.0025
Validation loss did not improve. Patience: 1/10
New best model saved at epoch 14 with validation loss: 0.002080
New best model saved at epoch 17 with validation loss: 0.002057
Epoch 20/100, gru - Train Loss: 0.0021, Val Loss: 0.0023
Validation loss did not improve. Patience: 3/10
Early stopping triggered after 27 epochs. Best was epoch 17.
Training LSTM model...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>New best model saved at epoch 1 with validation loss: 0.008221
New best model saved at epoch 2 with validation loss: 0.004299
New best model saved at epoch 3 with validation loss: 0.003685
New best model saved at epoch 4 with validation loss: 0.002275
New best model saved at epoch 7 with validation loss: 0.002167
Epoch 10/100, lstm - Train Loss: 0.0024, Val Loss: 0.0022
Validation loss did not improve. Patience: 3/10
New best model saved at epoch 11 with validation loss: 0.002145
New best model saved at epoch 16 with validation loss: 0.002080
Epoch 20/100, lstm - Train Loss: 0.0022, Val Loss: 0.0027
Validation loss did not improve. Patience: 4/10
Early stopping triggered after 26 epochs. Best was epoch 16.
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-training-history">
<h3>Model Training History<a class="headerlink" href="#model-training-history" title="Link to this heading">#</a></h3>
<p>Below we visualize the training history of three different neural network models (FFNN, GRU, and LSTM), showing the training loss and validation loss over the training epochs and highlighting the epoch where each model achieved its best validation performance.</p>
<p>This is important to track the learning process of each model and evaluate their overall performance, and potentially assess for overfitting to the training data, in which training loss can be low but the validation loss is not decreasing. This could require changing model parameters such as <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code>, the number of hidden layers in the network, or using more regularisation techniques.</p>
<p>However, for these simple models, we will see that the models train well and reaching best performance quickly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Plot FFNN losses</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ffnn_history</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span> <span class="n">ffnn_history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ffnn_history</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span> <span class="n">ffnn_history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">ffnn_history</span><span class="p">[</span><span class="s1">&#39;best_epoch&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Best epoch (</span><span class="si">{</span><span class="n">ffnn_history</span><span class="p">[</span><span class="s1">&#39;best_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;FFNN Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Plot GRU losses</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gru_history</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span> <span class="n">gru_history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gru_history</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span> <span class="n">gru_history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">gru_history</span><span class="p">[</span><span class="s1">&#39;best_epoch&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Best epoch (</span><span class="si">{</span><span class="n">gru_history</span><span class="p">[</span><span class="s1">&#39;best_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;GRU Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Plot LSTM losses</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lstm_history</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span> <span class="n">lstm_history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lstm_history</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">],</span> <span class="n">lstm_history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">lstm_history</span><span class="p">[</span><span class="s1">&#39;best_epoch&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Best epoch (</span><span class="si">{</span><span class="n">lstm_history</span><span class="p">[</span><span class="s1">&#39;best_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;LSTM Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;training_history.png&quot;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f9936b959974749019babec01e5796ce3e0dbd638915dcbaef255883464740b3.png" src="../_images/f9936b959974749019babec01e5796ce3e0dbd638915dcbaef255883464740b3.png" />
</div>
</div>
</section>
</section>
<section id="validate-the-model">
<h2>4. Validate the model<a class="headerlink" href="#validate-the-model" title="Link to this heading">#</a></h2>
<p>Now that we have trained the models, and checked for possible issues around overfitting, we can start using these to make predictions.</p>
<p>To do so, we have created a simple function <code class="docutils literal notranslate"><span class="pre">predict_random_samples</span></code> which predicts the time series of <code class="docutils literal notranslate"><span class="pre">S</span></code> and <code class="docutils literal notranslate"><span class="pre">I</span></code> for random samples of beta and gamma combinations from a provided <code class="docutils literal notranslate"><span class="pre">SIRTimeSeriesDataset</span></code>. The function makes predictions for whichever models you pass, and from the predictions creates a data frame with the predictions as well as the equivalent ground-truth from the actual SIR model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">predict_random_samples</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model_names</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">],</span> <span class="n">targets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Predicts the time series of S and I for random samples of beta and gamma combinations,</span>
<span class="sd">    compares to ground truth, and returns a DataFrame with predictions and ground truth.</span>

<span class="sd">    Args:</span>
<span class="sd">        models: List of trained models [FFNN, GRU, LSTM].</span>
<span class="sd">        dataset: The dataset containing the input features and target values.</span>
<span class="sd">        model_names: List of model names [&quot;FFNN&quot;, &quot;GRU&quot;, &quot;LSTM&quot;].</span>
<span class="sd">        num_samples: Number of random samples to generate (default: 9).</span>
<span class="sd">        features: List of feature names (default: [&#39;beta&#39;, &#39;gamma&#39;]).</span>
<span class="sd">        targets: List of target names (default: [&#39;S&#39;, &#39;I&#39;]).</span>

<span class="sd">    Returns:</span>
<span class="sd">        df_long: A Pandas DataFrame containing predictions, ground truth, and metadata.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_predictions</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Get unique beta and gamma combinations (ignoring replicates)</span>
    <span class="n">unique_combinations</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">param_set</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">param_set</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">param_sets</span><span class="p">]</span>  <span class="c1"># Extract only beta and gamma</span>
    <span class="n">unique_combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">unique_combinations</span><span class="p">))</span>  <span class="c1"># Remove duplicates</span>
    <span class="n">selected_combinations</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">unique_combinations</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
      <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set model to evaluation mode</span>
      <span class="k">for</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">selected_combinations</span><span class="p">:</span>
        <span class="c1"># Normalize features using the dataset&#39;s scaler</span>
        <span class="n">features_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">])</span>  <span class="c1"># Create features array</span>
        <span class="n">features_normalized</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">feature_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="c1"># Normalize features using the dataset&#39;s scaler</span>
        <span class="n">features_normalized</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">feature_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="c1"># Create input tensor</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">features_normalized</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>


        <span class="c1"># Predict using the model</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># Store predictions and ground truth for each replicate</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">all_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>  <span class="c1"># Add model name</span>
                <span class="o">**</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">features_values</span><span class="p">)),</span>
                <span class="o">**</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">*</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">N</span><span class="p">)),</span>
                <span class="s1">&#39;t&#39;</span><span class="p">:</span> <span class="n">t</span>
            <span class="p">})</span>

    <span class="c1"># Create DataFrame for plotting</span>
    <span class="n">df_predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_predictions</span><span class="p">)</span>
    <span class="n">df_predictions</span> <span class="o">=</span> <span class="n">df_predictions</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">replicate</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">df_predictions</span> <span class="o">=</span> <span class="n">df_predictions</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">N</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">N</span><span class="p">)</span>
    <span class="n">df_predictions</span> <span class="o">=</span> <span class="n">df_predictions</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">R</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="n">df_predictions</span><span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_predictions</span><span class="p">[</span><span class="s2">&quot;S&quot;</span><span class="p">])</span>

    <span class="c1"># Create filtered of test_data</span>
    <span class="n">filtered_test_data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">dataframe</span><span class="p">[</span><span class="n">test_data</span><span class="p">[[</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">df_predictions</span><span class="p">[[</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))]</span>
    <span class="n">filtered_test_data</span> <span class="o">=</span> <span class="n">filtered_test_data</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;TRUTH&quot;</span><span class="p">)</span>
    <span class="c1"># Combine</span>
    <span class="n">df_combine</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">filtered_test_data</span><span class="p">,</span> <span class="n">df_predictions</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">df_combine</span>

</pre></div>
</div>
</div>
</div>
<p>When we created our datasets, we kept one dataset back to be our test dataset, which will use here by selecting 9 random combinations of $\beta$ and $\gamma$ and creating the predictions of each model as well as the true SIR model runs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df_predictions</span> <span class="o">=</span> <span class="n">predict_random_samples</span><span class="p">(</span>
    <span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">ffnn_model</span><span class="p">,</span> <span class="n">gru_model</span><span class="p">,</span> <span class="n">lstm_model</span><span class="p">],</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="p">,</span>
    <span class="n">model_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;FFNN&quot;</span><span class="p">,</span> <span class="s2">&quot;GRU&quot;</span><span class="p">,</span> <span class="s2">&quot;LSTM&quot;</span><span class="p">],</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">9</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can then wrangle this into long data and return to our beloved ggplot style for plotting the model predictions and the replicates of the stochastic SIR model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reshape dataframe into tidy long-format</span>
<span class="n">df_long_preds</span> <span class="o">=</span> <span class="n">df_predictions</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span>
    <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&quot;</span><span class="p">,</span> <span class="s2">&quot;replicate&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">],</span>  <span class="c1"># Include model in id_vars</span>
    <span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">],</span>
    <span class="n">var_name</span><span class="o">=</span><span class="s2">&quot;Compartment&quot;</span><span class="p">,</span>
    <span class="n">value_name</span><span class="o">=</span><span class="s2">&quot;Value&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Add unique identifier for group plotting</span>
<span class="n">df_long_preds</span> <span class="o">=</span> <span class="n">df_long_preds</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">uid</span><span class="o">=</span><span class="n">df_long_preds</span><span class="p">[</span><span class="s2">&quot;Compartment&quot;</span><span class="p">]</span>
    <span class="o">+</span> <span class="n">df_long_preds</span><span class="p">[</span><span class="s2">&quot;replicate&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">df_long_preds</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Add facet identifier for group plotting</span>
<span class="n">df_long_preds</span> <span class="o">=</span> <span class="n">df_long_preds</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">facet</span><span class="o">=</span><span class="s2">&quot;beta = &quot;</span>
    <span class="o">+</span> <span class="n">df_long_preds</span><span class="p">[</span><span class="s2">&quot;beta&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
    <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="o">+</span> <span class="s2">&quot;gamma = &quot;</span>
    <span class="o">+</span> <span class="n">df_long_preds</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">p</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ggplot</span><span class="p">(</span>
        <span class="n">df_long_preds</span><span class="p">,</span>
        <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Value&quot;</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="s2">&quot;uid&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;Compartment&quot;</span><span class="p">,</span> <span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="o">+</span> <span class="n">geom_line</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">facet_wrap</span><span class="p">(</span><span class="s2">&quot;facet&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">ggplot</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/78a28f0a10dcb58bc2f6f12084d7d86de45b690ba0eb14cd6876193aa7fb29ac.png"><img alt="../_images/78a28f0a10dcb58bc2f6f12084d7d86de45b690ba0eb14cd6876193aa7fb29ac.png" src="../_images/78a28f0a10dcb58bc2f6f12084d7d86de45b690ba0eb14cd6876193aa7fb29ac.png" style="width: 640px; height: 480px;" />
</a>
</div>
</div>
</section>
<section id="run-the-model">
<h2>5. Run the model<a class="headerlink" href="#run-the-model" title="Link to this heading">#</a></h2>
<p>The section below will allow you to engage in a hands-on approach to actually using your trained emulator!</p>
<p>Eveyrthing that we have done so far looks good, however we‚Äôve not actually shown you how to use the emulator, below we have written a little script that allows you to interface with the emulators you‚Äôve trained and the SIR model such that you can visually see the outputs of your emulators in real time.</p>
<p>Have a go and try different parameter combinations, can you guess what will happen if you feed in a beta and gamma value that sits outside of the trained range?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Interactive Emulator Validation Widget</span>
<span class="c1"># Uncomment to get interactive widget in notebook - does not render in Github Jupyter Render Currently</span>

<span class="c1"># Interactive section for testing model performance with custom parameters</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ipywidgets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">widgets</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">clear_output</span>


<span class="k">def</span><span class="w"> </span><span class="nf">run_interactive_comparison</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Interactive widget to compare model predictions with actual SIR simulations</span>
<span class="sd">    for user-defined parameter values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Default values</span>
    <span class="n">default_beta</span> <span class="o">=</span> <span class="mf">0.3</span>
    <span class="n">default_gamma</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="c1"># Create widgets</span>
    <span class="n">beta_slider</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">default_beta</span><span class="p">,</span>
        <span class="nb">min</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
        <span class="nb">max</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Beta:&#39;</span><span class="p">,</span>
        <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">,</span>
        <span class="n">readout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">readout_format</span><span class="o">=</span><span class="s1">&#39;.2f&#39;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">gamma_slider</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">default_gamma</span><span class="p">,</span>
        <span class="nb">min</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
        <span class="nb">max</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Gamma:&#39;</span><span class="p">,</span>
        <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">,</span>
        <span class="n">readout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">readout_format</span><span class="o">=</span><span class="s1">&#39;.2f&#39;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">num_replicates_slider</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Replicates:&#39;</span><span class="p">,</span>
        <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;horizontal&#39;</span><span class="p">,</span>
        <span class="n">readout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">run_button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Run Simulation&#39;</span><span class="p">,</span>
        <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">button_style</span><span class="o">=</span><span class="s1">&#39;success&#39;</span><span class="p">,</span>
        <span class="n">tooltip</span><span class="o">=</span><span class="s1">&#39;Click to run the simulation&#39;</span><span class="p">,</span>
        <span class="n">icon</span><span class="o">=</span><span class="s1">&#39;play&#39;</span>
    <span class="p">)</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_simulation</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">beta_slider</span><span class="o">.</span><span class="n">value</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma_slider</span><span class="o">.</span><span class="n">value</span>
        <span class="n">reps</span> <span class="o">=</span> <span class="n">num_replicates_slider</span><span class="o">.</span><span class="n">value</span>

        <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
            <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Check if we&#39;re in a potentially unstable region</span>
            <span class="k">if</span> <span class="n">gamma</span> <span class="o">&gt;</span> <span class="n">beta</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚ö†Ô∏è Warning: gamma (</span><span class="si">{</span><span class="n">gamma</span><span class="si">}</span><span class="s2">) &gt; beta (</span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s2">). This is outside the training distribution and may produce poor predictions.&quot;</span><span class="p">)</span>

            <span class="c1"># Run actual SIR model with these parameters</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running SIR model with beta=</span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s2">, gamma=</span><span class="si">{</span><span class="n">gamma</span><span class="si">}</span><span class="s2">, replicates=</span><span class="si">{</span><span class="n">reps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">sir_results</span> <span class="o">=</span> <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="n">reps</span><span class="p">)</span>

            <span class="c1"># Normalize inputs for surrogate models</span>
            <span class="n">features_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">])</span>
            <span class="n">features_normalized</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">feature_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">features_normalized</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Get predictions from all models</span>
            <span class="n">model_predictions</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                    <span class="c1"># Convert to actual compartment values (S, I)</span>
                    <span class="n">S_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dataset</span><span class="o">.</span><span class="n">N</span>
                    <span class="n">I_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">dataset</span><span class="o">.</span><span class="n">N</span>
                    <span class="n">R_pred</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="n">S_pred</span> <span class="o">-</span> <span class="n">I_pred</span>
                    <span class="n">model_predictions</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s1">&#39;S&#39;</span><span class="p">:</span> <span class="n">S_pred</span><span class="p">,</span>
                        <span class="s1">&#39;I&#39;</span><span class="p">:</span> <span class="n">I_pred</span><span class="p">,</span>
                        <span class="s1">&#39;R&#39;</span><span class="p">:</span> <span class="n">R_pred</span>
                    <span class="p">}</span>

            <span class="c1"># Create time points</span>
            <span class="n">timepoints</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">timepoints</span>

            <span class="c1"># Plot results</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
            <span class="n">compartments</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">]</span>
            <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">comp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">compartments</span><span class="p">):</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

                <span class="c1"># Plot actual SIR results</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
                    <span class="n">replicate_data</span> <span class="o">=</span> <span class="n">sir_results</span><span class="p">[</span><span class="n">sir_results</span><span class="p">[</span><span class="s1">&#39;replicate&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">r</span><span class="p">]</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">replicate_data</span><span class="p">[</span><span class="s1">&#39;t&#39;</span><span class="p">],</span> <span class="n">replicate_data</span><span class="p">[</span><span class="n">comp</span><span class="p">],</span>
                            <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;SIR </span><span class="si">{</span><span class="n">comp</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

                <span class="c1"># Plot model predictions</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model_predictions</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">timepoints</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="n">comp</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span>
                            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">comp</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                            <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

                <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">comp</span><span class="si">}</span><span class="s1"> Compartment&#39;</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Population&#39;</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">run_button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">run_simulation</span><span class="p">)</span>

    <span class="c1"># Create layout and display widgets</span>
    <span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span>
        <span class="n">widgets</span><span class="o">.</span><span class="n">HBox</span><span class="p">([</span><span class="n">beta_slider</span><span class="p">,</span> <span class="n">gamma_slider</span><span class="p">]),</span>
        <span class="n">widgets</span><span class="o">.</span><span class="n">HBox</span><span class="p">([</span><span class="n">num_replicates_slider</span><span class="p">,</span> <span class="n">run_button</span><span class="p">]),</span>
        <span class="n">output</span>
    <span class="p">]))</span>

    <span class="c1"># Run once with default values</span>
    <span class="n">run_button</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>

<span class="c1"># Run the interactive comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Use the sliders to change beta and gamma values, then click &#39;Run Simulation&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Try setting gamma &gt; beta to see how models perform outside their training distribution&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The models were trained with beta &gt; gamma, so they may not generalize well to other scenarios&quot;</span><span class="p">)</span>

<span class="n">run_interactive_comparison</span><span class="p">(</span>
    <span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="n">ffnn_model</span><span class="p">,</span> <span class="n">gru_model</span><span class="p">,</span> <span class="n">lstm_model</span><span class="p">],</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;FFNN&quot;</span><span class="p">,</span> <span class="s2">&quot;GRU&quot;</span><span class="p">,</span> <span class="s2">&quot;LSTM&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Use the sliders to change beta and gamma values, then click &#39;Run Simulation&#39;
Try setting gamma &gt; beta to see how models perform outside their training distribution
The models were trained with beta &gt; gamma, so they may not generalize well to other scenarios
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "d6d4396f9f774037811d9e3ca8884b05"}</script></div>
</div>
</section>
<section id="evaluate-the-model">
<h2>6. Evaluate the model<a class="headerlink" href="#evaluate-the-model" title="Link to this heading">#</a></h2>
<p>Error metrics provide essential information about model performance. In epidemiological modeling, understanding how well our models predict disease spread under different transmission (beta) and recovery (gamma) parameters is crucial. The heatmaps we‚Äôll generate visualize performance across the parameter space, highlighting where models excel and where they struggle.
These standardized metrics (scaled from 0-1) allow for fair comparisons between different models and across different parameter combinations. Higher values (greener colors) always indicate better performance.</p>
<p>In essence, the code below systematically evaluates the accuracy of three different neural network models (FFNN, GRU, LSTM) in emulating an SIR epidemiological model. By generating high-resolution heatmaps, it visually compares their performance across a range of infection and recovery rates, providing valuable insights into the models‚Äô strengths and weaknesses in predicting disease dynamics, and how the performance varies across the parameter space that was used in training and that which is outside this space.</p>
<p><strong>Don‚Äôt worry too much about this code, and focus on looking at the outputs and thinking about whether the results surprise you</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Higher Resolution Standardized Error Metrics Heatmap</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.colors</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearSegmentedColormap</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calculate_metrics</span><span class="p">(</span><span class="n">true_values</span><span class="p">,</span> <span class="n">predicted_values</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate multiple error metrics between true and predicted values.&quot;&quot;&quot;</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">true_values</span><span class="p">,</span> <span class="n">predicted_values</span><span class="p">)</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">true_values</span><span class="p">,</span> <span class="n">predicted_values</span><span class="p">)</span>

    <span class="c1"># For R¬≤, handle potential errors (R¬≤ can be negative if predictions are poor)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">true_values</span><span class="p">,</span> <span class="n">predicted_values</span><span class="p">)</span>
        <span class="c1"># Clip R¬≤ to prevent extreme negative values from skewing the heatmap</span>
        <span class="n">r2</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">r2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;MSE&#39;</span><span class="p">:</span> <span class="n">mse</span><span class="p">,</span>
        <span class="s1">&#39;RMSE&#39;</span><span class="p">:</span> <span class="n">rmse</span><span class="p">,</span>
        <span class="s1">&#39;R¬≤&#39;</span><span class="p">:</span> <span class="n">r2</span><span class="p">,</span>
        <span class="s1">&#39;MAE&#39;</span><span class="p">:</span> <span class="n">mae</span>
    <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_high_resolution_heatmaps</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model_names</span><span class="p">,</span> <span class="n">n_replicates</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">grid_resolution</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate error heatmaps across beta-gamma space with standardized metrics (0-1 scale)</span>
<span class="sd">    with one plot per metric and three panels per plot (one for each model).</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    models : list</span>
<span class="sd">        List of trained models</span>
<span class="sd">    dataset : Dataset</span>
<span class="sd">        Dataset containing the input features and target values</span>
<span class="sd">    model_names : list</span>
<span class="sd">        List of model names as strings</span>
<span class="sd">    n_replicates : int</span>
<span class="sd">        Number of SIR model replicates to run for each parameter combination</span>
<span class="sd">    grid_resolution : int</span>
<span class="sd">        Number of grid points in each dimension (higher = smaller squares)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generating high-resolution standardized error heatmaps with </span><span class="si">{</span><span class="n">grid_resolution</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">grid_resolution</span><span class="si">}</span><span class="s2"> grid...&quot;</span><span class="p">)</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Define grid resolution (increased from previous 12x12)</span>
    <span class="n">n_points</span> <span class="o">=</span> <span class="n">grid_resolution</span>

    <span class="c1"># Define beta and gamma ranges - extend to full 0-1 range</span>
    <span class="c1"># Starting slightly above 0 to avoid division by zero when calculating R0</span>
    <span class="n">beta_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_points</span><span class="p">)</span>
    <span class="n">gamma_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_points</span><span class="p">)</span>

    <span class="c1"># Create meshgrid for visualization</span>
    <span class="n">beta_grid</span><span class="p">,</span> <span class="n">gamma_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">beta_values</span><span class="p">,</span> <span class="n">gamma_values</span><span class="p">)</span>

    <span class="c1"># Define error metrics to track</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="s1">&#39;RMSE&#39;</span><span class="p">,</span> <span class="s1">&#39;R¬≤&#39;</span><span class="p">,</span> <span class="s1">&#39;MAE&#39;</span><span class="p">]</span>

    <span class="c1"># Initialize error arrays - shape: (models, metrics, gamma_points, beta_points)</span>
    <span class="n">error_grids</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">metric</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">beta_grid</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span>
        <span class="p">}</span> <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span>
    <span class="p">}</span>

    <span class="c1"># Create a progress counter</span>
    <span class="n">total_points</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">beta_values</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">gamma_values</span><span class="p">)</span>
    <span class="n">completed_points</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Track which points are outside the training distribution</span>
    <span class="n">is_outside_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">beta_grid</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>

    <span class="c1"># Loop through each point in the grid</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gamma_values</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">beta</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beta_values</span><span class="p">):</span>
            <span class="c1"># Check if this point is outside the typical training distribution</span>
            <span class="n">is_outside_training</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">gamma</span> <span class="o">&gt;</span> <span class="n">beta</span><span class="p">)</span>

            <span class="c1"># Run the actual SIR model with multiple replicates</span>
            <span class="n">sir_results</span> <span class="o">=</span> <span class="n">run_model_with_replicates</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="n">n_replicates</span><span class="p">)</span>

            <span class="c1"># Calculate mean of SIR replicates as ground truth</span>
            <span class="n">sir_mean</span> <span class="o">=</span> <span class="n">sir_results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()[[</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

            <span class="c1"># Normalize input for surrogate models</span>
            <span class="n">features_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">])</span>
            <span class="n">features_normalized</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">feature_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features_values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">features_normalized</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Get predictions from each model</span>
            <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_names</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

                    <span class="c1"># Convert to actual compartment values (S, I, R)</span>
                    <span class="n">S_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dataset</span><span class="o">.</span><span class="n">N</span>
                    <span class="n">I_pred</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">dataset</span><span class="o">.</span><span class="n">N</span>
                    <span class="n">R_pred</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">N</span> <span class="o">-</span> <span class="n">S_pred</span> <span class="o">-</span> <span class="n">I_pred</span>

                    <span class="c1"># Combine all compartments for overall metrics</span>
                    <span class="n">all_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">sir_mean</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">],</span> <span class="n">sir_mean</span><span class="p">[</span><span class="s1">&#39;I&#39;</span><span class="p">],</span> <span class="n">sir_mean</span><span class="p">[</span><span class="s1">&#39;R&#39;</span><span class="p">]])</span>
                    <span class="n">all_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">S_pred</span><span class="p">,</span> <span class="n">I_pred</span><span class="p">,</span> <span class="n">R_pred</span><span class="p">])</span>

                    <span class="c1"># Calculate metrics</span>
                    <span class="n">metrics_results</span> <span class="o">=</span> <span class="n">calculate_metrics</span><span class="p">(</span><span class="n">all_true</span><span class="p">,</span> <span class="n">all_pred</span><span class="p">)</span>

                    <span class="c1"># Store in the error grids</span>
                    <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_value</span> <span class="ow">in</span> <span class="n">metrics_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="n">error_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric_name</span><span class="p">][</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">metric_value</span>

            <span class="c1"># Update progress</span>
            <span class="n">completed_points</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">completed_points</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">completed_points</span> <span class="o">==</span> <span class="n">total_points</span><span class="p">:</span>
                <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
                <span class="n">estimated_total</span> <span class="o">=</span> <span class="n">elapsed</span> <span class="o">/</span> <span class="n">completed_points</span> <span class="o">*</span> <span class="n">total_points</span>
                <span class="n">remaining</span> <span class="o">=</span> <span class="n">estimated_total</span> <span class="o">-</span> <span class="n">elapsed</span>
                <span class="n">percent_complete</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">completed_points</span> <span class="o">/</span> <span class="n">total_points</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Progress: </span><span class="si">{</span><span class="n">percent_complete</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">% complete (</span><span class="si">{</span><span class="n">completed_points</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total_points</span><span class="si">}</span><span class="s2"> points). &quot;</span> <span class="o">+</span>
                      <span class="sa">f</span><span class="s2">&quot;Time remaining: ~</span><span class="si">{</span><span class="n">remaining</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> minutes&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Heatmap generation completed in </span><span class="si">{</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_time</span><span class="p">)</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> minutes&quot;</span><span class="p">)</span>

    <span class="c1"># Create a custom colormap (green for good, red for bad)</span>
    <span class="n">custom_cmap</span> <span class="o">=</span> <span class="n">LinearSegmentedColormap</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="s1">&#39;custom_cmap&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;crimson&#39;</span><span class="p">,</span> <span class="s1">&#39;gold&#39;</span><span class="p">,</span> <span class="s1">&#39;darkgreen&#39;</span><span class="p">])</span>

    <span class="c1"># Standardize metrics to 0-1 scale</span>
    <span class="n">standardized_grids</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">metric</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">error_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span>
        <span class="p">}</span> <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span>
    <span class="p">}</span>

    <span class="c1"># Process each metric</span>
    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
        <span class="c1"># Collect all values for this metric across all models</span>
        <span class="n">all_values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
            <span class="n">all_values</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">error_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># Get min and max for scaling (with protection against outliers)</span>
        <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;R¬≤&#39;</span><span class="p">:</span>
            <span class="c1"># R¬≤ is already in a known range [-1, 1]</span>
            <span class="c1"># Transform to [0, 1] where 1 is best (highest R¬≤)</span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
                <span class="n">standardized_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">error_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For error metrics (MSE, RMSE, MAE), lower is better</span>
            <span class="c1"># Use percentiles to avoid extreme outliers</span>
            <span class="n">min_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">all_values</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
            <span class="n">max_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">all_values</span><span class="p">,</span> <span class="mi">95</span><span class="p">)</span>

            <span class="c1"># Transform to [0, 1] where 1 is best (lowest error)</span>
            <span class="k">for</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="n">model_names</span><span class="p">:</span>
                <span class="n">normalized</span> <span class="o">=</span> <span class="p">(</span><span class="n">error_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="o">-</span> <span class="n">min_val</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">max_val</span> <span class="o">-</span> <span class="n">min_val</span><span class="p">)</span>
                <span class="c1"># Clip to [0, 1] in case of values outside the percentile range</span>
                <span class="n">normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">normalized</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="c1"># Invert so that 1 means best performance (lowest error)</span>
                <span class="n">standardized_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">normalized</span>

    <span class="c1"># Calculate the min/max beta based on R0 and gamma (for plotting boundaries)</span>
    <span class="n">min_beta</span> <span class="o">=</span> <span class="n">param_ranges</span><span class="p">[</span><span class="s2">&quot;R0&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">param_ranges</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">max_beta</span> <span class="o">=</span> <span class="n">param_ranges</span><span class="p">[</span><span class="s2">&quot;R0&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">param_ranges</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Create one figure per metric (with three panels for the models)</span>
    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model_names</span><span class="p">):</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>

            <span class="c1"># Create the heatmap with standardized values</span>
            <span class="c1"># Use shading=&#39;gouraud&#39; for smoother interpolation between grid cells</span>
            <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">beta_grid</span><span class="p">,</span> <span class="n">gamma_grid</span><span class="p">,</span> <span class="n">standardized_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">],</span>
                               <span class="n">cmap</span><span class="o">=</span><span class="n">custom_cmap</span><span class="p">,</span>
                               <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">shading</span><span class="o">=</span><span class="s1">&#39;gouraud&#39;</span><span class="p">)</span>  <span class="c1"># Use &#39;gouraud&#39; for smooth interpolation</span>

            <span class="c1"># Add color bar</span>
            <span class="n">cbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;R¬≤&#39;</span><span class="p">:</span>
                <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Standardized </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s1"> (higher is better)&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Standardized </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s1"> (higher = lower error)&#39;</span><span class="p">)</span>

            <span class="c1"># Add R0 = 1 line (where beta = gamma)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">beta_values</span><span class="p">,</span> <span class="n">beta_values</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R‚ÇÄ = 1&#39;</span><span class="p">)</span>

            <span class="c1"># Add contour lines for R0 values</span>
            <span class="k">for</span> <span class="n">r0</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
                <span class="n">r0_gamma</span> <span class="o">=</span> <span class="n">beta_values</span> <span class="o">/</span> <span class="n">r0</span>
                <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">r0_gamma</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">gamma_values</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">):</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">beta_values</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">],</span> <span class="n">r0_gamma</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">],</span>
                            <span class="s1">&#39;k:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;R‚ÇÄ = </span><span class="si">{</span><span class="n">r0</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="c1"># Add training region boundary (using calculated beta values)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">(</span>
                <span class="p">(</span><span class="n">min_beta</span><span class="p">,</span> <span class="n">param_ranges</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span>
                <span class="n">max_beta</span> <span class="o">-</span> <span class="n">min_beta</span><span class="p">,</span>
                <span class="n">param_ranges</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">param_ranges</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Region&#39;</span><span class="p">))</span>

            <span class="c1"># Set labels and title</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Beta (infection rate)&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Gamma (recovery rate)&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="c1"># Set equal limits from 0 to 1 for both axes</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Add grid</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>

            <span class="c1"># Add legend</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

            <span class="c1"># For R¬≤, show the original R¬≤ = 0 contour</span>
            <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;R¬≤&#39;</span><span class="p">:</span>
                <span class="c1"># R¬≤ = 0 corresponds to standardized value of 0.5</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">beta_grid</span><span class="p">,</span> <span class="n">gamma_grid</span><span class="p">,</span> <span class="n">standardized_grids</span><span class="p">[</span><span class="n">model_name</span><span class="p">][</span><span class="n">metric</span><span class="p">],</span>
                          <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">],</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                          <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>

        <span class="c1"># Main title for the figure</span>
        <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;R¬≤&#39;</span><span class="p">:</span>
            <span class="n">metric_description</span> <span class="o">=</span> <span class="s2">&quot;(higher values = better fit)&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">metric_description</span> <span class="o">=</span> <span class="s2">&quot;(higher values = lower error)&quot;</span>

        <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Model Comparison: Standardized </span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s1"> across Parameter Space </span><span class="si">{</span><span class="n">metric_description</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

        <span class="c1"># Save figure</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;high_res_error_</span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Run the high-resolution analysis</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;This analysis visualizes model performance across the parameter space with higher grid resolution.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For all metrics, higher values (greener) indicate better performance.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Warning: Higher resolution means more computations and longer runtime.&quot;</span><span class="p">)</span>

<span class="c1"># Prompt user for desired resolution</span>
<span class="n">resolution</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Default resolution</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">resolution</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">resolution</span><span class="si">}</span><span class="s2"> grid (higher = smaller squares, but longer runtime)&quot;</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">plot_high_resolution_heatmaps</span><span class="p">(</span>
        <span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="n">ffnn_model</span><span class="p">,</span> <span class="n">gru_model</span><span class="p">,</span> <span class="n">lstm_model</span><span class="p">],</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;FFNN&quot;</span><span class="p">,</span> <span class="s2">&quot;GRU&quot;</span><span class="p">,</span> <span class="s2">&quot;LSTM&quot;</span><span class="p">],</span>
        <span class="n">n_replicates</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># Reduced from 10 to save time with higher resolution</span>
        <span class="n">grid_resolution</span><span class="o">=</span><span class="n">resolution</span>
    <span class="p">)</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error generating high-resolution error heatmaps: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span>
    <span class="n">traceback</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>This analysis visualizes model performance across the parameter space with higher grid resolution.
For all metrics, higher values (greener) indicate better performance.

Warning: Higher resolution means more computations and longer runtime.
Using 20x20 grid (higher = smaller squares, but longer runtime)
Generating high-resolution standardized error heatmaps with 20x20 grid...
Progress: 5.0% complete (20/400 points). Time remaining: ~0.5 minutes
Progress: 10.0% complete (40/400 points). Time remaining: ~0.5 minutes
Progress: 15.0% complete (60/400 points). Time remaining: ~0.5 minutes
Progress: 20.0% complete (80/400 points). Time remaining: ~0.5 minutes
Progress: 25.0% complete (100/400 points). Time remaining: ~0.5 minutes
Progress: 30.0% complete (120/400 points). Time remaining: ~0.4 minutes
Progress: 35.0% complete (140/400 points). Time remaining: ~0.4 minutes
Progress: 40.0% complete (160/400 points). Time remaining: ~0.3 minutes
Progress: 45.0% complete (180/400 points). Time remaining: ~0.3 minutes
Progress: 50.0% complete (200/400 points). Time remaining: ~0.3 minutes
Progress: 55.0% complete (220/400 points). Time remaining: ~0.3 minutes
Progress: 60.0% complete (240/400 points). Time remaining: ~0.2 minutes
Progress: 65.0% complete (260/400 points). Time remaining: ~0.2 minutes
Progress: 70.0% complete (280/400 points). Time remaining: ~0.2 minutes
Progress: 75.0% complete (300/400 points). Time remaining: ~0.1 minutes
Progress: 80.0% complete (320/400 points). Time remaining: ~0.1 minutes
Progress: 85.0% complete (340/400 points). Time remaining: ~0.1 minutes
Progress: 90.0% complete (360/400 points). Time remaining: ~0.1 minutes
Progress: 95.0% complete (380/400 points). Time remaining: ~0.0 minutes
Progress: 100.0% complete (400/400 points). Time remaining: ~0.0 minutes
Heatmap generation completed in 0.59 minutes
</pre></div>
</div>
<img alt="../_images/3c19647c4ef8d0e2513dca05e529edf741f1770d05075c15ba9344af379dfee9.png" src="../_images/3c19647c4ef8d0e2513dca05e529edf741f1770d05075c15ba9344af379dfee9.png" />
<img alt="../_images/5a55f91220d58a3f597d8ef38f3b139279d51d0b3b0d900f383b9754b942ba9e.png" src="../_images/5a55f91220d58a3f597d8ef38f3b139279d51d0b3b0d900f383b9754b942ba9e.png" />
<img alt="../_images/9d86672bd2cae2c48df5bc6e5e8e9ad5a9ca075e5b0659937c46596c34bb1fc8.png" src="../_images/9d86672bd2cae2c48df5bc6e5e8e9ad5a9ca075e5b0659937c46596c34bb1fc8.png" />
<img alt="../_images/1dec6926162e4f857f2895f6e665fe3aaf990b02f223b15dddaa1e860000f618.png" src="../_images/1dec6926162e4f857f2895f6e665fe3aaf990b02f223b15dddaa1e860000f618.png" />
</div>
</div>
<p>When looking at the heatmap above, think through these 3 questions to help guide your thinking:</p>
<blockquote>
<div><p><strong>1. Do the patterns of model performance across the beta-gamma parameter space make intuitive sense given your understanding of SIR dynamics?</strong> For example, are there regions where all models perform well or poorly? If so, how do those regions relate to the basic reproductive number (R0), which is influenced by beta and gamma? Can you explain why certain parameter combinations might be more challenging for the models to predict accurately?</p>
</div></blockquote>
<blockquote>
<div><p><strong>2. What specific features or boundaries can you identify in the heatmaps, and how might they be linked to the underlying SIR model or the training data used for the neural networks?</strong> Do you notice any sharp transitions in performance, or regions where one model significantly outperforms others? How might these features relate to the training region boundary, the line representing R0 = 1, or the contour lines for different R0 values? Is the training region shown with the blue box correct? Is this the entire region that it was trained on, and if not not does this explain the heatmap patterns?</p>
</div></blockquote>
<blockquote>
<div><p><strong>3. Considering the overall performance visualized in the heatmaps, which model appears to be the most robust and reliable surrogate for the SIR model across a wide range of parameter values?</strong> What specific evidence from the heatmaps supports your conclusion? Are there scenarios or parameter ranges where a particular model might be preferred over others, and why? How might you use these insights to make informed decisions about model selection for future epidemiological studies or simulations?</p>
</div></blockquote>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In this notebook, we explored the process of building and training deep learning surrogates for infectious disease modeling using the SIR model as an example. We covered the following key steps:</p>
<ol class="arabic simple">
<li><p><strong>Data Generation:</strong> We used the <code class="docutils literal notranslate"><span class="pre">emidm</span></code> package to simulate SIR model dynamics with varying parameters using Latin Hypercube Sampling (LHS) to systematically explore the parameter space and generate training, validation, and test datasets.</p></li>
<li><p><strong>Data Preparation:</strong> We created a custom PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class (<code class="docutils literal notranslate"><span class="pre">SIRTimeSeriesDataset</span></code>) to efficiently handle the time series data and implemented <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> for batch processing during training.</p></li>
<li><p><strong>Model Building and Training:</strong> We defined and trained three different neural network architectures:</p>
<ul class="simple">
<li><p><strong>Feedforward Neural Network (FFNN):</strong> A basic neural network with multiple layers.</p></li>
<li><p><strong>Gated Recurrent Unit (GRU):</strong> A recurrent neural network designed for sequential data.</p></li>
<li><p><strong>Long Short-Term Memory (LSTM):</strong> Another recurrent neural network with more complex gating mechanisms.
We trained these models using the Adam optimizer and a learning rate scheduler, monitoring their performance on validation data to prevent overfitting.</p></li>
<li><p>We also applied a sigmoid activation function to the final layer of each model to ensure the predictions were bound between 0 and 1 and included normalization.</p></li>
</ul>
</li>
<li><p><strong>Model Validation:</strong> We assessed the trained models‚Äô performance by predicting on a held-out test dataset and comparing the predictions to the ground truth SIR model simulations.</p></li>
<li><p><strong>Visualization:</strong> We visualized the training history, showing the training and validation losses over epochs, and highlighted the best-performing epochs for each model.</p></li>
</ol>
</section>
<section id="extensions-for-further-exploration">
<h2>Extensions for Further Exploration<a class="headerlink" href="#extensions-for-further-exploration" title="Link to this heading">#</a></h2>
<p>If you‚Äôve completed the main sections of this notebook and have some extra time, consider exploring these extensions to deepen your understanding of surrogate modeling.</p>
<section id="hyperparameter-tuning">
<h3>1. Hyperparameter Tuning<a class="headerlink" href="#hyperparameter-tuning" title="Link to this heading">#</a></h3>
<p><strong>Challenge:</strong> Experiment with different hyperparameters of the neural network models (e.g., hidden size, number of layers, dropout rate, learning rate) to see how they affect performance.</p>
<p><strong>Hint:</strong> Use a grid search or random search approach to systematically explore different hyperparameter combinations and evaluate their impact on validation loss.</p>
<p><strong>Code Snippet (Grid Search Example):</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>

<span class="c1"># Define hyperparameter ranges</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">dropout_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>

<span class="c1"># Create all possible combinations</span>
<span class="n">hyperparameter_combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout_rates</span><span class="p">))</span>

<span class="c1"># Loop through combinations and train models</span>
<span class="k">for</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout_rate</span> <span class="ow">in</span> <span class="n">hyperparameter_combinations</span><span class="p">:</span>

<span class="c1"># Create and train model with current hyperparameters</span>
<span class="c1"># ...</span>

</pre></div>
</div>
</section>
<section id="capturing-stochastic-uncertainty">
<h3>2. Capturing Stochastic Uncertainty<a class="headerlink" href="#capturing-stochastic-uncertainty" title="Link to this heading">#</a></h3>
<p><strong>Challenge:</strong> Modify the models to predict the variance in stochastic replicates over time, rather than just the point estimate. This can be used to create a surrogate that captures stochastic uncertainty, providing a more comprehensive representation of the SIR model‚Äôs behavior.</p>
<p><strong>Hint:</strong> Instead of predicting only the mean values of S and I, train the models to predict both the mean and variance (or standard deviation) for each time step. You‚Äôll need to adjust the output layer of the models and modify the loss function to account for both mean and variance predictions. You can consider using metrics like the negative log-likelihood (NLL) for evaluating the performance of models predicting distributions.</p>
<p><strong>Code Snippet (Modifying the FFNN model):</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">FFNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output now includes both mean and variance</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>  
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span>
</pre></div>
</div>
<blockquote>
<div><p>Further Hint: Instead of predicting only the mean values of S and I, train the models to predict both the mean and variance (or standard deviation) for each time step. You‚Äôll need to adjust the output layer of the models and modify the loss function to account for both mean and variance predictions. <strong>Importantly, you‚Äôll also need to change the SIRTimeSeriesDataset class to ensure that all stochastic replicates for a given parameter set are available during training, as the model now needs to learn the distribution of outcomes.</strong> You can consider using metrics like the negative log-likelihood (NLL) for evaluating the performance of models predicting distributions.</p>
</div></blockquote>
</section>
<section id="surrogate-assisted-inference">
<h3>3. Surrogate-Assisted Inference<a class="headerlink" href="#surrogate-assisted-inference" title="Link to this heading">#</a></h3>
<p><strong>Challenge:</strong> Use the trained surrogate model to perform tasks like parameter estimation or sensitivity analysis, which are typically computationally expensive with the original SIR model.</p>
<p><strong>Hint:</strong> You can use optimization algorithms to find parameter values that minimize the difference between the surrogate‚Äôs predictions and observed data. For parameter estimation, you can define an objective function that calculates the loss between the surrogate‚Äôs predictions and the observed data for a given set of parameters. Then, use an optimization algorithm like <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code> to find the parameter values that minimize this loss. For sensitivity analysis, you can vary the input parameters of the surrogate model and observe the corresponding changes in the output to understand the model‚Äôs sensitivity to different parameters.</p>
<p><strong>Code Snippet (Parameter Estimation):</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scipy</span><span class="o">.</span><span class="n">optimize</span> <span class="kn">import</span><span class="w"> </span><span class="nn">minimize</span>

<span class="k">def</span><span class="w"> </span><span class="nf">objective_function</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">surrogate_model</span><span class="p">,</span> <span class="n">observed_data</span><span class="p">):</span>
  <span class="c1"># ... (calculate surrogate predictions using params) ...</span>
  <span class="c1"># ... (calculate difference between predictions and observed_data) ...</span>
  <span class="k">return</span> <span class="n">loss</span>

<span class="c1"># Perform optimization</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective_function</span><span class="p">,</span> <span class="n">initial_params</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">surrogate_model</span><span class="p">,</span> <span class="n">observed_data</span><span class="p">))</span>
</pre></div>
</div>
<blockquote>
<div><blockquote>
<div><p>Further Hint: You can generate your own observed data by simulating an SIR epidemic using the functions from <code class="docutils literal notranslate"><span class="pre">emidm</span></code>. Or you could get data from a real outbreak from <a class="reference external" href="https://www.reconverse.org/outbreaks/">https://www.reconverse.org/outbreaks/</a>, e.g. the outbreak of influenza A (H1N1) in 1978 at a British boarding school of 763 children and changing your data generation to use a different <code class="docutils literal notranslate"><span class="pre">N</span></code>.</p>
</div></blockquote>
</div></blockquote>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="bayesian_inference.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Bayesian Inference with Differentiable Models</p>
      </div>
    </a>
    <a class="right-next"
       href="intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to Jupyter and Colab Notebooks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#objectives">Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enabling-gpu-acceleration">Enabling GPU Acceleration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-simulation-data">1. Generate Simulation Data</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-a-single-sir-model-simulation">Running a Single SIR Model Simulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-multiple-stochastic-realisations">Running Multiple Stochastic Realisations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-dataset">2. Prepare Training Dataset</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-parameter-space-with-latin-hypercube-sampling">Sampling Parameter Space with Latin Hypercube Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-training-and-test-data">Generating Training and Test Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-neural-network">3. Train a neural network</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-dataset-class-and-dataloader">Creating Dataset Class and Dataloader</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-size-explained">Batch Size Explained</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#why-use-batches"><em>Why Use Batches?</em></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-the-right-batch-size"><em>Choosing the Right Batch Size</em></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#in-practice"><em>In Practice:</em></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-neural-network-models">Building Neural Network Models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feedforward-neural-network-ffnn">Feedforward Neural Network (FFNN)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gated-recurrent-unit-gru">Gated Recurrent Unit (GRU)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#long-short-term-memory-lstm">Long Short-Term Memory (LSTM)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-and-training-our-models">Creating and Training Our Models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-training">Model Training</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-training-history">Model Training History</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#validate-the-model">4. Validate the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-model">5. Run the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluate-the-model">6. Evaluate the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extensions-for-further-exploration">Extensions for Further Exploration</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-tuning">1. Hyperparameter Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#capturing-stochastic-uncertainty">2. Capturing Stochastic Uncertainty</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#surrogate-assisted-inference">3. Surrogate-Assisted Inference</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/notebooks/surrogate.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>