{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating a Differentiable SIR Model\n",
    "\n",
    "This tutorial demonstrates how to use **emidm**'s differentiable SIR model to:\n",
    "\n",
    "1. Simulate synthetic epidemic data with known parameters\n",
    "2. Fit the transmission rate (β) using gradient-based optimization\n",
    "3. Compare the fitted model to the ground truth\n",
    "\n",
    "This is a key use case for differentiable epidemiological models: we can use automatic differentiation to efficiently calibrate model parameters to observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules. This example requires JAX and Optax, which can be installed with:\n",
    "\n",
    "```bash\n",
    "pip install emidm[jax]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from emidm.diff import DiffConfig, run_diff_sir\n",
    "from emidm.optim import optimize_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Data\n",
    "\n",
    "We'll simulate an epidemic using the differentiable SIR model with a known transmission rate β = 0.35. This will serve as our \"observed\" data that we'll try to recover through optimization.\n",
    "\n",
    "The differentiable SIR model uses **Gumbel-Softmax** sampling to make the stochastic transitions differentiable. The `DiffConfig` controls:\n",
    "- `tau`: temperature parameter (lower = more discrete-like)\n",
    "- `hard`: whether to use straight-through gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters\n",
    "BETA_TRUE = 0.35\n",
    "GAMMA = 0.2\n",
    "N_AGENTS = 200\n",
    "T = 30\n",
    "I0 = 5\n",
    "\n",
    "# Generate synthetic data\n",
    "key = jax.random.PRNGKey(42)\n",
    "data = run_diff_sir(\n",
    "    N_agents=N_AGENTS,\n",
    "    I0=I0,\n",
    "    beta=BETA_TRUE,\n",
    "    gamma=GAMMA,\n",
    "    T=T,\n",
    "    config=DiffConfig(tau=0.8, hard=True),\n",
    "    key=key,\n",
    ")\n",
    "\n",
    "print(f\"Generated epidemic with β = {BETA_TRUE}\")\n",
    "print(f\"Peak infections: {int(data['I'].max())} at day {int(jnp.argmax(data['I']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the synthetic epidemic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "t = jnp.arange(T + 1)\n",
    "ax.plot(t, data[\"S\"], label=\"Susceptible\", color=\"blue\", linewidth=2)\n",
    "ax.plot(t, data[\"I\"], label=\"Infected\", color=\"red\", linewidth=2)\n",
    "ax.plot(t, data[\"R\"], label=\"Recovered\", color=\"green\", linewidth=2)\n",
    "\n",
    "ax.set_xlabel(\"Time (days)\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of individuals\", fontsize=12)\n",
    "ax.set_title(f\"Synthetic SIR Epidemic (β = {BETA_TRUE}, γ = {GAMMA})\", fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(0, T)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Loss Function\n",
    "\n",
    "To fit the model, we need a loss function that measures how well a given β reproduces the observed infection curve. We'll use **mean squared error** between the predicted and observed number of infected individuals.\n",
    "\n",
    "Because `run_diff_sir` is differentiable, JAX can compute gradients of this loss with respect to β."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The observed infection curve we want to fit\n",
    "observed_I = data[\"I\"]\n",
    "\n",
    "def loss_fn(beta):\n",
    "    \"\"\"Compute MSE between predicted and observed infections.\"\"\"\n",
    "    pred = run_diff_sir(\n",
    "        N_agents=N_AGENTS,\n",
    "        I0=I0,\n",
    "        beta=beta,\n",
    "        gamma=GAMMA,\n",
    "        T=T,\n",
    "        config=DiffConfig(tau=0.8, hard=True),\n",
    "        key=jax.random.PRNGKey(0),  # Fixed key for reproducibility during optimization\n",
    "    )\n",
    "    return jnp.mean((pred[\"I\"] - observed_I) ** 2)\n",
    "\n",
    "# Test the loss function\n",
    "test_beta = jnp.array(0.15)\n",
    "print(f\"Loss at β = 0.15: {loss_fn(test_beta):.2f}\")\n",
    "print(f\"Loss at β = 0.35 (true): {loss_fn(jnp.array(BETA_TRUE)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Optimize β Using Gradient Descent\n",
    "\n",
    "Now we'll use `optimize_params` to find the β that minimizes the loss. This function uses **Optax** (specifically, the Adam optimizer) under the hood.\n",
    "\n",
    "We start from an initial guess of β = 0.15 and let the optimizer find the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess (deliberately wrong)\n",
    "beta_init = jnp.array(0.15)\n",
    "\n",
    "# Run optimization\n",
    "beta_hat, history = optimize_params(\n",
    "    loss_fn=loss_fn,\n",
    "    init_params=beta_init,\n",
    "    n_steps=150,\n",
    "    learning_rate=0.01,\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"  Initial β: {float(beta_init):.3f}\")\n",
    "print(f\"  Fitted β:  {float(beta_hat):.3f}\")\n",
    "print(f\"  True β:    {BETA_TRUE:.3f}\")\n",
    "print(f\"  Error:     {abs(float(beta_hat) - BETA_TRUE):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the optimization trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curve\n",
    "ax = axes[0]\n",
    "ax.plot(history[\"loss\"], color=\"steelblue\", linewidth=2)\n",
    "ax.set_xlabel(\"Optimization step\", fontsize=12)\n",
    "ax.set_ylabel(\"Loss (MSE)\", fontsize=12)\n",
    "ax.set_title(\"Training Loss\", fontsize=14)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Parameter trajectory\n",
    "ax = axes[1]\n",
    "ax.plot(history[\"params\"], color=\"steelblue\", linewidth=2, label=\"Estimated β\")\n",
    "ax.axhline(y=BETA_TRUE, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"True β = {BETA_TRUE}\")\n",
    "ax.set_xlabel(\"Optimization step\", fontsize=12)\n",
    "ax.set_ylabel(\"β\", fontsize=12)\n",
    "ax.set_title(\"Parameter Trajectory\", fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare Fitted vs True Model\n",
    "\n",
    "Finally, let's compare the epidemic curves from:\n",
    "- The **true** model (β = 0.35)\n",
    "- The **fitted** model (β ≈ estimated value)\n",
    "- The **initial** model (β = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with fitted and initial parameters\n",
    "pred_fitted = run_diff_sir(\n",
    "    N_agents=N_AGENTS, I0=I0, beta=beta_hat, gamma=GAMMA, T=T,\n",
    "    config=DiffConfig(tau=0.8, hard=True), key=jax.random.PRNGKey(0),\n",
    ")\n",
    "\n",
    "pred_initial = run_diff_sir(\n",
    "    N_agents=N_AGENTS, I0=I0, beta=beta_init, gamma=GAMMA, T=T,\n",
    "    config=DiffConfig(tau=0.8, hard=True), key=jax.random.PRNGKey(0),\n",
    ")\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "t = jnp.arange(T + 1)\n",
    "ax.plot(t, observed_I, \"o\", color=\"black\", markersize=6, label=\"Observed (true)\", alpha=0.7)\n",
    "ax.plot(t, pred_fitted[\"I\"], \"-\", color=\"green\", linewidth=2.5, label=f\"Fitted (β = {float(beta_hat):.3f})\")\n",
    "ax.plot(t, pred_initial[\"I\"], \"--\", color=\"orange\", linewidth=2, label=f\"Initial (β = {float(beta_init):.3f})\")\n",
    "\n",
    "ax.set_xlabel(\"Time (days)\", fontsize=12)\n",
    "ax.set_ylabel(\"Number infected\", fontsize=12)\n",
    "ax.set_title(\"Model Calibration: Fitted vs True Infection Curve\", fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(0, T)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\\n\\nIn this tutorial, we demonstrated:\\n\\n1. **Differentiable simulation**: Using `run_diff_sir` to simulate epidemics with gradients\\n2. **Gradient-based calibration**: Using `optimize_params` to fit model parameters\\n3. **Model comparison**: Visualizing how well the fitted model recovers the true dynamics\\n\\nThe key advantage of differentiable models is that we can use efficient gradient-based optimization instead of slower derivative-free methods (like grid search or MCMC). This becomes especially important for:\\n\\n- **High-dimensional parameter spaces**: When fitting many parameters simultaneously\\n- **Complex models**: Where each simulation is computationally expensive\\n- **Uncertainty quantification**: Combining with variational inference or Hamiltonian Monte Carlo\\n\\nSee the [API documentation](../api.rst) for more details on the available models and utilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
