[
  {
    "objectID": "examples/surrogate_notebook copy.html",
    "href": "examples/surrogate_notebook copy.html",
    "title": "Training Surrogates",
    "section": "",
    "text": "Open In Colab\nThis notebook demonstrates how to generate data using a Susceptible-Infected-Recovered (SIR) model with the emidm package. The generated data can be used to train deep learning surrogates for infectious disease modeling.\nThe first two sections (Generate Simulation Data and Prepare Training Dataset) make use of emidm to generate our training data and are provided in brief to show what data is being generated and to ease into the notebook. The next three sections introduce how to train your surrogate model, validate this and explore ways of using this.\nThe last section are possible extensions for those who finish early, which ask you to think about tweaking the code used to test your understanding about how surrogates are trained, or to explore how to use them further analysis."
  },
  {
    "objectID": "examples/surrogate_notebook copy.html#objectives",
    "href": "examples/surrogate_notebook copy.html#objectives",
    "title": "Training Surrogates",
    "section": "Objectives",
    "text": "Objectives\n\nSimulate SIR model dynamics using the emidm package.\nGenerate multiple realizations of the model with varying parameters.\nPrepare the simulated data for training deep learning surrogates.\nTrain different surrogate models and compare these\nVisualise performance of surrogates"
  },
  {
    "objectID": "examples/surrogate_notebook copy.html#prerequisites",
    "href": "examples/surrogate_notebook copy.html#prerequisites",
    "title": "Training Surrogates",
    "section": "Prerequisites",
    "text": "Prerequisites\nWe will be using the helper functions in the emidm package, which will be installed and all relevant modules from this as well as other required packages loaded below in two steps.\nFirst we will install emidm from Github:\n\n%pip install git+https://github.com/OJWatson/emidm.git\n\n155.41s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n\n\nCollecting git+https://github.com/OJWatson/emidm.git\n  Cloning https://github.com/OJWatson/emidm.git to /tmp/pip-req-build-b2stl05s\n  Running command git clone --filter=blob:none --quiet https://github.com/OJWatson/emidm.git /tmp/pip-req-build-b2stl05s\n  Resolved https://github.com/OJWatson/emidm.git to commit ce6af259f02b5dd99c4468ca5a92458f8a390be0\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nRequirement already satisfied: numpy in /home/oj/GoogleDrive/AcademicWork/Imperial/git/emidm/venv/lib/python3.10/site-packages (from emidm==0.1) (2.2.4)\nRequirement already satisfied: pandas in /home/oj/GoogleDrive/AcademicWork/Imperial/git/emidm/venv/lib/python3.10/site-packages (from emidm==0.1) (2.2.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/share/positron/resources/app/extensions/positron-python/python_files/lib/ipykernel/py3 (from pandas-&gt;emidm==0.1) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/oj/GoogleDrive/AcademicWork/Imperial/git/emidm/venv/lib/python3.10/site-packages (from pandas-&gt;emidm==0.1) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /home/oj/GoogleDrive/AcademicWork/Imperial/git/emidm/venv/lib/python3.10/site-packages (from pandas-&gt;emidm==0.1) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/share/positron/resources/app/extensions/positron-python/python_files/lib/ipykernel/py3 (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;emidm==0.1) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\nNext we will import any required modules once here. If this works then the rest of the notebook should work 🤞:\n\n# Imports from the emidm package that we have just installed\nfrom emidm.sir import run_sir, run_model_with_replicates, plot_model_outputs\nfrom emidm.sampler import generate_lhs_samples\n\n# imports from other packages\nimport pandas as pd\nimport numpy as np\n\n# for those who like me prescrbe to Hadley Wickham's one truth of a grammar of graphics\nfrom plotnine import ggplot, aes, geom_line, facet_wrap\n\n# progress on loops in notebooks\nfrom tqdm.notebook import tqdm"
  },
  {
    "objectID": "examples/surrogate_notebook copy.html#generate-simulation-data",
    "href": "examples/surrogate_notebook copy.html#generate-simulation-data",
    "title": "Training Surrogates",
    "section": "1. Generate Simulation Data",
    "text": "1. Generate Simulation Data\n\nRunning a Single SIR Model Simulation\nWe can use emidm to ssimulate the SIR model dynamics using default parameters:\n\n# Demonstrate running one model\nsingle = run_sir()\n\n# Show the output\nsingle\n\n\n\n\n\n\n\n\nt\nN\nS\nI\nR\n\n\n\n\n0\n0\n1000\n990\n10\n0\n\n\n1\n1\n1000\n987\n10\n3\n\n\n2\n2\n1000\n987\n9\n4\n\n\n3\n3\n1000\n985\n10\n5\n\n\n4\n4\n1000\n979\n16\n5\n\n\n...\n...\n...\n...\n...\n...\n\n\n96\n96\n1000\n168\n14\n818\n\n\n97\n97\n1000\n168\n12\n820\n\n\n98\n98\n1000\n166\n11\n823\n\n\n99\n99\n1000\n166\n11\n823\n\n\n100\n100\n1000\n166\n11\n823\n\n\n\n\n101 rows × 5 columns\n\n\n\nThe output is a pandas DataFrame containing the number of susceptible (S), infected (I), and recovered (R) individuals over time.\nTo visualize the results:\n\n# Show a single plot line\nsingle.plot(\"t\", [\"S\", \"I\", \"R\"])\n\n\n\n\n\n\n\n\nWe can adjust parameters such as the transmission rate (beta) to observe different dynamics:\n\n# We can also vary the parameters and plot these outputs\nalt = run_sir(beta = 0.3)\nalt.plot(\"t\", [\"S\", \"I\", \"R\"])\n\n\n\n\n\n\n\n\n\n\nRunning Multiple Stochastic Realisations\nTo account for stochasticity, we can run multiple realizations of the model:\n\n# we can run multiple realisations\nreps = run_model_with_replicates(model = run_sir, reps = 10)\n\n# and plot these - ahhh a ggplot my friend\np = plot_model_outputs(reps)\n\n\n\n\n\n\n\n\nAnd we can also pass through any of the arguments to run_sir to our run_model_with_replicates function.\n\n# we can also by args to run_sir through kwargs\nreps = run_model_with_replicates(model=run_sir, reps=10, beta = 0.3)\n\n# and plot these\np = plot_model_outputs(reps, columns = [\"I\", \"R\"])"
  },
  {
    "objectID": "examples/surrogate_notebook copy.html#prepare-training-dataset",
    "href": "examples/surrogate_notebook copy.html#prepare-training-dataset",
    "title": "Training Surrogates",
    "section": "2. Prepare Training Dataset",
    "text": "2. Prepare Training Dataset\n\nSampling Parameter Space with Latin Hypercube Sampling\nTo systematically explore the parameter space, we use Latin Hypercube Sampling (LHS), which we have again provided helper functions from emidm for you to use.\n\n# Start by providing a dictionary of the ranges for each parameter to be sampled\nparam_ranges = {\"beta\": [0.1, 0.5], \"gamma\": [0.05, 0.5]}\n\n# Generate Latin Hypercube Samples\ndf_samples = generate_lhs_samples(param_ranges, n_samples=9, seed=42)\ndf_samples\n\n\n\n\n\n\n\n\nbeta\ngamma\n\n\n\n\n0\n0.376713\n0.228056\n\n\n1\n0.150729\n0.165132\n\n\n2\n0.229148\n0.351219\n\n\n3\n0.421727\n0.310697\n\n\n4\n0.272084\n0.127481\n\n\n5\n0.350187\n0.253662\n\n\n6\n0.471384\n0.458862\n\n\n7\n0.302515\n0.088638\n\n\n8\n0.119796\n0.446809\n\n\n\n\n\n\n\nThis generates a set of parameter combinations, which we can then pass to our run_model_with_replicates function. We have just used 9 samples here initially just to show you the outputs and understand it. Later we will generate more samples to build a robust training dataset.\n\n# Run the model for each row of samples:\nresults = [\n    run_model_with_replicates(**row.to_dict(), reps=10).assign(**row.to_dict())\n    for _, row in df_samples.iterrows()\n]\n\n# Combine results into one DataFrame:\ndf_all_results = pd.concat(results, axis=0)\n\n\n# Reshape dataframe into tidy long-format\ndf_long = df_all_results.melt(\n    id_vars=[\"t\", \"replicate\", \"gamma\", \"beta\"],\n    value_vars=[\"S\", \"I\", \"R\"],\n    var_name=\"Compartment\",\n    value_name=\"Value\",\n)\n\n# Add unique identifier for group plotting\ndf_long = df_long.assign(\n    uid=df_long[\"Compartment\"]\n    + df_long[\"replicate\"].astype(str)\n)\n\n# Add facet identifier for group plotting\ndf_long = df_long.assign(\n    facet=\"beta = \"\n    + df_long[\"beta\"].round(3).astype(str)\n    + \",\\n\"\n    + \"gamma = \"\n    + df_long[\"gamma\"].round(3).astype(str)\n)\n\n# Plot: color by compartment, lines grouped by replicate\np = (\n    ggplot(\n        df_long,\n        aes(x=\"t\", y=\"Value\", group=\"uid\", color=\"Compartment\"),\n    )\n    + geom_line(alpha=0.7)\n    + facet_wrap(\"facet\")\n)\n\n# Explicitly plot\nggplot.show(p)\n\n\n\n\n\n\n\n\n\n\nGenerating Training and Test Data\nNow that we have seen how LHS is being used to sample different \\(\\beta\\) and \\(\\gamma\\) parameters and to generate simulations, we will now generate training and test data in much the same way:\n\nn_train_samples = 100\nn_test_samples = 10\n\n# generate train samples and data\ntrain_samples = generate_lhs_samples(param_ranges, n_samples=n_train_samples, seed=42)\ntrain_data = [\n    run_model_with_replicates(**row.to_dict(), reps=5).assign(**row.to_dict())\n    for _, row in tqdm(train_samples.iterrows(), total=len(train_samples))\n]\n\n# generate test samples\ntest_samples = generate_lhs_samples(param_ranges, n_samples=n_test_samples, seed=42)\ntest_data = [\n    run_model_with_replicates(**row.to_dict(), reps=5).assign(**row.to_dict())\n    for _, row in tqdm(test_samples.iterrows(), total = len(test_samples))\n]"
  },
  {
    "objectID": "examples/surrogate_notebook copy.html#train-a-neural-network",
    "href": "examples/surrogate_notebook copy.html#train-a-neural-network",
    "title": "Training Surrogates",
    "section": "3. Train a neural network",
    "text": "3. Train a neural network\n\nCreating Dataset Class and Dataloader\nWhile we have generated our training and test data, we need to prepare it into a PyTorch dataset and dataloader. The dataloader is a way of iterating through our data in batches, which is useful for training deep learning models. Batches are used to train the model in mini-batches, which is more efficient than training on the entire dataset at once. It also has the advantage of allowing us to use GPU acceleration if available.\nWe have not created this dataset class yet in emidm, so that we can show you how it works, so we will do that next. We will also use this an opportunity to learn a bit more about PyTorch and also how (more often) Python leverages classes.\nFirst, let’s remind ourselves what our data looks like\n\n\nDataset and Scaling\nWe first construct a custom PyTorch dataset that formats are simulation runs into input-output pairs. For each simulation run produces an input sequence X of shape (T, 1+2):\n\nThe first column is a normalized time feature (values between 0 and 1).\nThe remaining columns are the simulation parameters (\\(\\beta\\), \\(\\gamma\\)) repeated over all time steps.\n\nThe target Y is the time series of total incidence (per day). Both inputs and targets are scaled using StandardScaler.\nWe first construct a custom PyTorch dataset that for each simulation run produces an input sequence X of shape (T, 1+9):\nThe first column is a normalized time feature (values between 0 and 1). The remaining columns are the simulation parameters (latent period, infectious period, immunity period, Rt values, and switching times) repeated over all time steps. The target Y is the time series of total incidence (per day). Both inputs and targets are scaled using StandardScaler"
  },
  {
    "objectID": "examples/notebooks_intro.html",
    "href": "examples/notebooks_intro.html",
    "title": "Introduction to Jupyter and Colab Notebooks",
    "section": "",
    "text": "Open In Colab\n\n\nJupyter Notebooks and Google Colab are interactive computing environments widely used for data analysis, machine learning, and programming tutorials. Both platforms allow you to combine code, visualisations, explanatory text, and equations in one document, enhancing clarity, reproducibility, and collaboration.\n\nWhat is a Notebook?\nA notebook is a special file format (with a .ipynb extension) that stores not only the code but also the outputs of that code (such as plots, tables, and text), as well as any markdown-formatted explanations. Under the hood, it’s a JSON document that wraps code, output, and metadata in a structured format, often rendered as HTML when viewed in a browser (e.g. on GitHub). This allows you to view the outputs of a notebook—even without running the code—when it’s shared online.\n\n\nRun Order Matters\nOne important aspect of working with notebooks is that cells can be executed in any order, and their outputs are stored until cleared or overwritten. This means a notebook can appear to “work” even when the code is run out of sequence or relies on prior cell execution that hasn’t happened in a fresh session. Always restart the kernel and run all cells in order to ensure reproducibility.\n\n\nGetting Started\n\nJupyter Notebook: Typically runs locally on your computer via Anaconda or through a cloud service.\nGoogle Colab: Runs entirely online in your browser via Google’s infrastructure, providing easy access without setup.\n\n\n\nKey Components of the Notebook Interface\n\nCells: Notebooks consist of cells that hold either:\n\nCode (Python, R, etc.)\nMarkdown (formatted text)\n\nToolbar: Located at the top, contains essential buttons:\n\nRun Cell ▶️ to execute the current cell.\nAdd Cell ➕ to insert a new cell.\nCell Type drop-down to switch between Code and Markdown.\n\nFile Explorer (Jupyter): On the left, navigate files and folders.\nSidebar (Colab): On the left, access files, data, or settings.\n\n\n\nCode Cells\nCode cells can be interespersed with markdown cells (similar to mixed text and code chunks in Rmd or Quarto), such as below where we have a python code cell.\n\na = 1\nb = 2\na*b\n\n2\n\n\n\n\nChanging Runtime Type in Colab (GPUs and TPUs)\nGoogle Colab allows users to leverage GPU or TPU resources for computationally intensive tasks such as deep learning. To enable GPU or TPU:\n\nNavigate to Runtime &gt; Change runtime type.\nSelect the hardware accelerator (GPU or TPU) from the dropdown menu.\nClick Save to confirm your selection.\n\nAfter you click save, your runtime is reloaded so your active session, variables and environment will be lost.\n\nYou can check this by adding a code cell below and seeing if a and b still exist\n\n\n\nSaving and Managing Files in Colab\nGoogle Colab provides seamless integration with Google Drive and GitHub, allowing users to efficiently manage and store notebooks:\n\nSaving to Google Drive:\n\nAutomatically saves your notebooks to Google Drive in a dedicated “Colab Notebooks” folder.\nYou can manually save copies by selecting File &gt; Save a copy in Drive.\n\nIntegration with GitHub:\n\nColab allows direct loading of notebooks from GitHub repositories via File &gt; Open notebook &gt; GitHub.\nYou can save your notebook back to GitHub by selecting File &gt; Save a copy in GitHub (authentication required).\n\n\n\n\nCommon Keyboard Shortcuts\nMastering keyboard shortcuts significantly boosts productivity:\n\n\n\n\n\n\n\n\nAction\nJupyter Shortcut\nColab Shortcut\n\n\n\n\nRun Cell\nShift + Enter\nShift + Enter\n\n\nAdd Cell Below\nB (in command mode)\nCtrl + M, then B\n\n\nAdd Cell Above\nA (in command mode)\nCtrl + M, then A\n\n\nDelete Cell\nD, D\nCtrl + M, then D\n\n\nConvert Cell to Markdown\nM\nCtrl + M, then M\n\n\nConvert Cell to Code\nY\nCtrl + M, then Y\n\n\nInterrupt Execution\nI, I\nCtrl + M, then I\n\n\nHelp\nH\nCtrl + M, then H\n\n\n\nNote: Colab requires first pressing Ctrl + M to activate shortcuts.\n\n\nExample Code Cell: Plotting the Iris Dataset\nHere is a simple example using numpy, pandas, and matplotlib to plot the famous Iris dataset:\nRun the cell below using Shift + Enter to execute it and render the plot directly beneath the code.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\n\n# Load the Iris dataset\niris = load_iris()\ndf = pd.DataFrame(data=iris.data, columns=iris.feature_names)\ndf[\"species\"] = iris.target\n\n# Plot sepal length vs. sepal width\nplt.figure(figsize=(8, 6))\nfor species_id, species_name in enumerate(iris.target_names):\n    subset = df[df[\"species\"] == species_id]\n    plt.scatter(subset.iloc[:, 0], subset.iloc[:, 1], label=species_name)\n\nplt.xlabel(\"Sepal Length (cm)\")\nplt.ylabel(\"Sepal Width (cm)\")\nplt.title(\"Iris Dataset - Sepal Dimensions\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBest Practices\n\nRegularly save your notebook (Ctrl + S or Command + S).\nFrequently restart kernels (Runtime &gt; Restart in Colab; Kernel &gt; Restart in Jupyter) to clear memory and prevent issues.\nClearly document code with Markdown cells.\nUse cells for modular coding and step-by-step debugging.\nUse Run all cells (from the menu) to ensure reproducibility before sharing.\n\n\n\nAdditional Resources\n\nJupyter documentation: https://jupyter.org/documentation\nColab guide: https://colab.research.google.com/notebooks/welcome.ipynb"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "emidm",
    "section": "",
    "text": "Installation\nExample Usage\nLicense"
  },
  {
    "objectID": "index.html#table-of-contents",
    "href": "index.html#table-of-contents",
    "title": "emidm",
    "section": "",
    "text": "Installation\nExample Usage\nLicense"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "emidm",
    "section": "Installation",
    "text": "Installation\npip install git+https://github.com/OJWatson/emidm.git\nOr\ngit clone https://github.com/OJWatson/emidm.git\ncd emidm\npip install ."
  },
  {
    "objectID": "index.html#example-usage",
    "href": "index.html#example-usage",
    "title": "emidm",
    "section": "Example Usage",
    "text": "Example Usage\n\nfrom emidm.sir import run_sir, run_model_with_replicates, plot_model_outputs\nsingle = run_sir()\nsingle.plot(\"t\", [\"S\", \"I\", \"R\"])"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "emidm",
    "section": "License",
    "text": "License\nemidm is distributed under the terms of the MIT license."
  },
  {
    "objectID": "slides/emidm_intro1.html#python-vs-r-syntax-structure-reminders",
    "href": "slides/emidm_intro1.html#python-vs-r-syntax-structure-reminders",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Python vs R: Syntax & Structure Reminders",
    "text": "Python vs R: Syntax & Structure Reminders\n\nSyntax: Python uses indentation instead of {}. No &lt;- assignment (use =).\nIndexing: Python indices start at 0 (R starts at 1). Slicing in Python excludes end index.\nData structures: Python has lists, dicts, tuples (vs R’s vectors, lists, data frames). Python lists are heterogeneous like R lists.\nExample:\n\nIn Python, mylist = [10, 20, 30]; mylist[0] = 10.\nIn R, myvec &lt;- c(10,20,30); myvec[1] = 10."
  },
  {
    "objectID": "slides/emidm_intro1.html#python-vs-r-deeper-overview",
    "href": "slides/emidm_intro1.html#python-vs-r-deeper-overview",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Python vs R: Deeper Overview",
    "text": "Python vs R: Deeper Overview\n\nPython Workshop: Jesse and Paul python-workshop\n\n\n\n\nFeature\nR\nPython\n\n\n\n\nwhitespace\nignored\nmeaningful\n\n\ndata frames & stats\nout-of-box\nneed package\n\n\npackages\nfussy\neasy\n\n\noperate on language\nyes\nno\n\n\nmodifying variables\ncopy-on-modify\nmodify-in-place\n\n\nvariable assignment\n&lt;- (madness)\n= (sane)\n\n\n\n\nOJ Reflections on Above Table: 🤔"
  },
  {
    "objectID": "slides/emidm_intro1.html#python-vs-r-deeper-overview-1",
    "href": "slides/emidm_intro1.html#python-vs-r-deeper-overview-1",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Python vs R: Deeper Overview",
    "text": "Python vs R: Deeper Overview\n\nPython Workshop: Jesse and Paul python-workshop\nOJ Edits on Table: 🤔\n\n\n\n\nFeature\nR\nPython\n\n\n\n\nplotting\nheavenly\nhell\n\n\ndocumentation\nroxygen❤️\ndocstrings😒\n\n\ndependencies hell 😈\nmoderate\nfrequent\n\n\nvirtual environments\nless often\nstandard"
  },
  {
    "objectID": "slides/emidm_intro1.html#what-is-positron",
    "href": "slides/emidm_intro1.html#what-is-positron",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "What is Positron?",
    "text": "What is Positron?\n\nPositron is a next-generation IDE from Posit (RStudio) built on VS Code, tailored for data science. It feels like a blend of RStudio and VSCode in one interface.\nPolyglot support: Comes configured for both R and Python out of the box – you can run R scripts and Jupyter Python notebooks in the same environment.\nFamiliar interface: Shares RStudio’s layout (source, console, plots, environment) with VSCode’s extensibility. This makes the transition easier for R users.\nWhy use it? Simplifies working on projects that use R and Python together, without switching IDEs. Familiiar IDE experience for R users learning/transitioning to Python.\n\n(Positron) Positron IDE combines a Visual Studio Code foundation with an RStudio-like layout, supporting multi-language notebooks and scripts (R and Python) seamlessly."
  },
  {
    "objectID": "slides/emidm_intro1.html#benefits-for-r-users",
    "href": "slides/emidm_intro1.html#benefits-for-r-users",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Benefits for R Users",
    "text": "Benefits for R Users\n\nUnified Workflow: Work with .R and .py files in one place, share workspace and variables. For example, run an R analysis then a Python machine learning step in one project.\nJupyter integration: Built-in support for Jupyter notebooks (no separate JupyterLab needed).\nExtensions: Leverage VSCode extensions (linting, Git integration, etc.) in Positron. Most VSCode extensions (except a few Microsoft-specific) are available (Fun with Positron | Andrew Heiss – Andrew Heiss).\nTransition ease: Minimal setup – Positron auto-detects R and Python installations. Familiar shortcuts (e.g. Ctrl+Enter to run code) work for both languages.\nREPL-like development experience: Positron has a REPL-style development environment, similar to RStudio. You can run code, see results, and modify the environment as you go, putting you closer to understanding the code you write.\nBottom line: Positron lowers the barrier for R programmers to start incorporating Python into their workflow within a single IDE."
  },
  {
    "objectID": "slides/emidm_intro1.html#what-is-deep-learning",
    "href": "slides/emidm_intro1.html#what-is-deep-learning",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\n\nDefinition: Deep learning is a subset of machine learning that uses multi-layered neural networks to simulate complex decision-making, akin to the human brain (What Is Deep Learning? | IBM).\nKey idea: Instead of manual feature engineering, a deep neural network learns representations through layers of neurons.\nWhy it matters: Achieved breakthroughs in image recognition, natural language processing, etc. – many AI applications today are powered by deep learning (What Is Deep Learning? | IBM) (What Is Deep Learning? | IBM).\nExamples: Digital assistants (speech recognition), fraud detection, medical image analysis, and even epidemic forecasting models have benefited from deep learning techniques (What Is Deep Learning? | IBM).\nIn short: Deep learning can automatically extract complex patterns from data, making it extremely powerful for modeling nonlinear relationships."
  },
  {
    "objectID": "slides/emidm_intro1.html#key-concepts-neural-networks",
    "href": "slides/emidm_intro1.html#key-concepts-neural-networks",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Key Concepts: Neural Networks",
    "text": "Key Concepts: Neural Networks\n\nNeurons & Layers: Basic unit is a neuron (takes inputs, applies weights and activation). Neurons are organized into layers (input layer -&gt; hidden layers -&gt; output layer). Multiple hidden layers = a “deep” network.\nActivation Functions: Non-linear functions applied at neurons (e.g. ReLU, sigmoid). They enable networks to learn complex non-linear mappings.\nLoss Function: Metric that quantifies error between the network’s prediction and true values (e.g. mean squared error, cross-entropy). The network’s goal is to minimize this during training.\nForward Propagation: Data flows through the network layer by layer to produce an output (prediction) (What Is Deep Learning? | IBM).\nBackpropagation: The training algorithm – compute the loss, then propagate the error gradients backward adjusting weights (via gradient descent) (What Is Deep Learning? | IBM). This is how the network “learns” from mistakes.\nOptimization: An optimizer (SGD, Adam, etc.) uses those gradients to update weights iteratively, gradually improving the model’s performance."
  },
  {
    "objectID": "slides/emidm_intro1.html#training-process-recap",
    "href": "slides/emidm_intro1.html#training-process-recap",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Training Process Recap",
    "text": "Training Process Recap\n\nInitialize weights (often random small values).\nForward pass: Input data -&gt; compute outputs and loss.\nBackward pass: Compute gradients of loss w.rt each weight (this is automatic via backpropagation).\nWeight update: Adjust weights using gradients (optimizer step).\nIterate: Repeat for many epochs (passes through data) until loss converges or performance is sufficient.\nResult: A trained neural network model that hopefully generalizes to new data.\nThroughout training, we monitor metrics on a validation set to avoid overfitting. If validation performance plateaus or worsens, we consider techniques like early stopping or regularization."
  },
  {
    "objectID": "slides/emidm_intro1.html#what-is-pytorch",
    "href": "slides/emidm_intro1.html#what-is-pytorch",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "What is PyTorch?",
    "text": "What is PyTorch?\n\nPyTorch is an open-source deep learning framework based on Python (and Torch library). It’s one of the most popular platforms for deep learning research and deployment (What is PyTorch?).\nDeveloped by researchers at Facebook (Meta) in 2016, it accelerated from prototyping to production with a flexible, pythonic approach (What is PyTorch?) (What is PyTorch?).\nDynamic computation graph: PyTorch uses a “define-by-run” approach – the neural network graph is built on the fly as you run code, making it intuitive to debug and modify.\nWhy PyTorch?\n\nEasy to learn: Pythonic API feels natural if you know Python.\nFlexibility: Define complex models imperatively (no static graphs).\nCommunity & Ecosystem: Huge community, lots of pre-trained models and tutorials. Backed by Meta and the open-source community (now part of Linux Foundation).\n\nUsage: Widely used in academia and industry (Meta uses PyTorch to power all its AI workloads (What is PyTorch?)). It has become a go-to framework for computer vision, NLP, and many scientific applications."
  },
  {
    "objectID": "slides/emidm_intro1.html#core-components-of-pytorch",
    "href": "slides/emidm_intro1.html#core-components-of-pytorch",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Core Components of PyTorch",
    "text": "Core Components of PyTorch\n\nTensor: Fundamental data structure in PyTorch. A tensor is a homogeneous multi-dimensional array (similar to a NumPy array) that can be processed on CPU or GPU (PyTorch - Wikipedia).\n\nExample: torch.tensor([[1,2],[3,4]]) is a 2x2 tensor of integers.\n\nAutograd: PyTorch’s automatic differentiation engine. It records operations on tensors so that gradients can be computed via backpropagation. This means if you have a loss computed from tensors, you can call .backward() to get gradients of all parameters – no manual calculus needed.\nnn Module: High-level neural network APIs. torch.nn provides building blocks like layers (Linear, Conv2d, LSTM, etc.), activation functions, loss functions, etc., to easily build complex networks (PyTorch - Wikipedia).\n\nYou define a neural network as a class inheriting nn.Module, compose layers in the constructor, and define the forward pass. PyTorch takes care of gradient computation for the parameters.\n\nOptimizers: torch.optim has algorithms like SGD, Adam for updating model parameters based on computed gradients.\nDataLoader: Utility to load and batch your dataset conveniently, with shuffling and parallel loading.\nIn summary: PyTorch provides the pieces (tensors + autograd + nn modules) to build and train neural networks efficiently, abstracting away much of the math and boilerplate."
  },
  {
    "objectID": "slides/emidm_intro1.html#pytorch-in-action-basic-operations",
    "href": "slides/emidm_intro1.html#pytorch-in-action-basic-operations",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "PyTorch in Action: Basic Operations",
    "text": "PyTorch in Action: Basic Operations\nLet’s see a simple example creating a tensor, doing a computation, and using autograd to get gradients:\n\nimport torch\n\n# Create a tensor with gradient tracking\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n# Perform operations on the tensor\ny = x * 2  # y = [2.0, 4.0, 6.0]\ny_sum = y.sum()  # y_sum = 12.0 (scalar tensor)\n# Compute gradients (dy_sum/dx)\ny_sum.backward()  # backpropagate through the computation\nprint(x.grad)  # Gradient of y_sum w.r.t x\n# Expected output: tensor([2., 2., 2.])\n\ntensor([2., 2., 2.])\n\n\n\nIn this example, y = 2*x, and y_sum = 2*x1 + 2*x2 + 2*x3. The gradient ∂(y_sum)/∂x = [2, 2, 2], which PyTorch computes for us.\nThis illustrates how autograd frees us from manual gradient derivation. We can then use these gradients in an optimizer to update x (or, typically, model parameters) during training.\nPyTorch’s imperative style means we used standard Python control flow to compute y and y_sum. The framework built the computation graph dynamically and handled differentiation under the hood."
  },
  {
    "objectID": "slides/emidm_intro1.html#why-ai-in-epidemiology",
    "href": "slides/emidm_intro1.html#why-ai-in-epidemiology",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Why AI in Epidemiology?",
    "text": "Why AI in Epidemiology?\n\nData-driven insights: Infectious disease modeling traditionally relies on differential equations and statistical models. Machine learning (ML) offers an alternative approach to identify patterns in epidemiological data (e.g. forecasting outbreaks from trends).\nDeep learning advantages: Ability to model complex, non-linear relationships. For instance, neural networks can capture patterns in time-series infection data that might be hard to specify in a parametric model.\nLarge Development Community: PyTorch has a large and active community, with many pre-trained models and tutorials. Other popular tools such as Jax/flax underpin the development by large tech companies like Google and Meta, which likely predicates a more robust ecosystem and rapid development and contributions from the community."
  },
  {
    "objectID": "slides/emidm_intro1.html#why-ai-in-epidemiology-1",
    "href": "slides/emidm_intro1.html#why-ai-in-epidemiology-1",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Why AI in Epidemiology?",
    "text": "Why AI in Epidemiology?\n\nEnhancing traditional models: AI can be combined with mechanistic models. For example, researchers have integrated neural networks with compartmental models to help estimate parameters that are hard to infer otherwise (Epi-DNNs: Epidemiological priors informed deep neural networks for modeling COVID-19 dynamics - PMC). This can merge domain knowledge (e.g. SIR model structure) with data-driven flexibility.\nPhysics-informed NN: There is a trend of physics-informed neural networks for epidemic forecasting (Physics-informed deep learning for infectious disease forecasting) – these models incorporate the known dynamics (e.g. equations of disease spread) into the training of a neural network, ensuring predictions that respect known laws while still learning from data."
  },
  {
    "objectID": "slides/emidm_intro1.html#why-ai-in-epidemiology-2",
    "href": "slides/emidm_intro1.html#why-ai-in-epidemiology-2",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Why AI in Epidemiology?",
    "text": "Why AI in Epidemiology?\n\nSurrogate models: Using AI to approximate the input-output behavior of complex simulation models. This is particularly useful to speed up scenario analysis in infectious disease simulations that would otherwise be computationally intensive.\nIt is likely going to be everywhere: Artificial intelligence for modelling infectious disease epidemics"
  },
  {
    "objectID": "slides/emidm_intro1.html#surrogate-modeling-bridging-simulation-and-ai",
    "href": "slides/emidm_intro1.html#surrogate-modeling-bridging-simulation-and-ai",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Surrogate Modeling: Bridging Simulation and AI",
    "text": "Surrogate Modeling: Bridging Simulation and AI\n\nWhat is a surrogate model? It’s an AI model trained to emulate another process or simulation. For infectious diseases, a surrogate model can learn to reproduce the outcomes of a complex epidemic simulation (e.g. an agent-based model or a stochastic SIR model), given certain inputs, but much faster.\nWhy use it? Simulations (especially stochastic ones) can be slow when exploring many scenarios or doing real-time forecasting. A surrogate (once trained) runs almost instantly, allowing rapid experimentation or even real-time applications (like outbreak forecast updates).\nIn epidemiology: Surrogates can learn the mapping from disease parameters (like transmission rate, recovery rate) to outputs of interest (like peak infected, time series of infections). Then we can query the surrogate for any parameter combination instead of rerunning the simulation.\nConsiderations: Surrogate models need a comprehensive training dataset from the simulation (covering the range of scenarios). They should be validated to ensure they accurately reflect the simulation’s behavior, especially in the regime of interest (e.g. epidemic growth vs decline phases)."
  },
  {
    "objectID": "slides/emidm_intro1.html#case-study-surrogating-a-stochastic-sir-model",
    "href": "slides/emidm_intro1.html#case-study-surrogating-a-stochastic-sir-model",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Case Study: Surrogating a Stochastic SIR Model",
    "text": "Case Study: Surrogating a Stochastic SIR Model\n\nWe’ll use the classic SIR model (Susceptible-Infectious-Recovered) as an example of building a surrogate. In a stochastic SIR simulation, each run with given parameters produces a trajectory of S, I, R over time.\n\n\nfrom emidm.sir import run_sir, run_model_with_replicates, plot_model_outputs\nplot_model_outputs(run_model_with_replicates(run_sir, reps=10))"
  },
  {
    "objectID": "slides/emidm_intro1.html#building-the-surrogate",
    "href": "slides/emidm_intro1.html#building-the-surrogate",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Building the Surrogate",
    "text": "Building the Surrogate\n\n1. Generate simulation data: Sample a range of parameter sets (e.g. transmission rate β, recovery rate γ, possibly initial population sizes). For each set, run the SIR simulation and record the resulting infection curves (S(t), I(t), R(t) over time).\n2. Prepare training dataset: From these runs, construct input-output pairs for learning. One approach is to provide the parameters (β, γ, time t) as inputs and the corresponding S, I, R at that time as outputs. (Alternatively, train a model that directly outputs the entire time-series given β and γ.)\n3. Train a neural network: Use PyTorch to define a network (for example, a simple feed-forward network or an RNN) that takes in parameters (and time) and outputs the state. Train it on the simulation data by minimizing the error between the network’s predicted epidemic curve and the simulation’s actual values.\n4. Validate the model: Test the surrogate on simulation runs it hasn’t seen. Check that it can predict the trajectory for new β, γ with reasonable accuracy (e.g., the peak and timing of infections match the simulation).\n5. Use the surrogate: Now you have a fast approximation of the SIR model. You can sweep through parameter space quickly, perform uncertainty quantification (by sampling many β, γ from distributions and getting outcomes rapidly), or embed this surrogate inside larger frameworks (e.g., optimization or real-time forecasting systems)."
  },
  {
    "objectID": "slides/emidm_intro1.html#surrogate-model-visualization-validation",
    "href": "slides/emidm_intro1.html#surrogate-model-visualization-validation",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Surrogate Model Visualization (Validation)",
    "text": "Surrogate Model Visualization (Validation)\n\nOnce trained, we can visualize how well the surrogate matches the actual simulation:\n\nPlot the infection curve from the true simulation and the surrogate’s predicted curve for a few test parameter sets. Ideally, they overlap closely.\nPlot predicted vs actual values (parity plot) for key outcomes (e.g. final epidemic size, peak infection) to quantify accuracy.\n\nIf the surrogate is accurate, we can be confident using it for further experiments. For example, we could vary β continuously and see how peak infection changes, using the surrogate outputs instantly rather than running hundreds of simulations.\nIt’s also insightful to examine the surrogate’s learned parameters. In the SEINN example, the network inferred β and γ. If those learned values align with the true parameters used in simulation, it validates that the network not only predicts well but also captures the underlying epidemic parameters."
  },
  {
    "objectID": "slides/emidm_intro1.html#surrogate-notebook",
    "href": "slides/emidm_intro1.html#surrogate-notebook",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Surrogate Notebook",
    "text": "Surrogate Notebook\nTraining Surrogates"
  },
  {
    "objectID": "slides/emidm_intro1.html#conditional-variational-autoencoders-cvaes.-what-is-a-cvae",
    "href": "slides/emidm_intro1.html#conditional-variational-autoencoders-cvaes.-what-is-a-cvae",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Conditional Variational Autoencoders (cVAEs). What is a cVAE?",
    "text": "Conditional Variational Autoencoders (cVAEs). What is a cVAE?\n\nA Conditional Variational Autoencoder (cVAE) is an extension of the Variational Autoencoder that incorporates additional information (conditions) into the generation process (Conditional Variational Autoencoders).\nRecap VAE: A VAE consists of an encoder that compresses input data into a latent distribution (usually a Gaussian in a low-dimensional space) and a decoder that reconstructs data from a sample of that latent distribution. It’s trained to reconstruct inputs while keeping latent variables meaningful (via a KL divergence regularization).\nConditional part: In a cVAE, we “condition” both encoder and decoder on some extra context. For example, when dealing with images of digits, we can provide the digit label as a condition. The encoder then learns latent variables given that label, and the decoder can generate data conditioned on a specific label (Conditional Variational Autoencoders).\nEffect: This allows directed generation – e.g., “generate samples that look like digit 5” or, in our context, “generate epidemic curves under a certain scenario”. The latent space then captures variations other than the condition.\n\nFor digits, the label fixes which digit, and the latent variables can capture style (thickness of writing, slant, etc.) (Conditional Variational Autoencoders).\nFor epidemics, one could imagine conditioning on, say, the basic reproduction number \\(R_0\\) or other known factors, and the latent variables capture random effects or unknown influences.\n\nUncertainty modeling: cVAEs are useful for representing uncertainty. Instead of a single prediction, a cVAE can generate a distribution of possible outcomes for a given condition. For instance, given an initial infection count and \\(R_0\\), a cVAE could generate many possible epidemic trajectories (reflecting stochastic variations)."
  },
  {
    "objectID": "slides/emidm_intro1.html#potential-application-of-cvae-in-epidemiology",
    "href": "slides/emidm_intro1.html#potential-application-of-cvae-in-epidemiology",
    "title": "Introduction to Deep Learning Frameworks with Python and PyTorch",
    "section": "Potential Application of cVAE in Epidemiology",
    "text": "Potential Application of cVAE in Epidemiology\n\nScenario: We have many observed epidemic curves (from simulations or real data) under various conditions (e.g. different intervention strategies). We want to model the distribution of epidemic outcomes for a new condition.\nUsing cVAE: We could train a cVAE where:\n\nThe input to the encoder is an epidemic trajectory with its condition (e.g. “with lockdown” vs “no lockdown”).\nThe condition is also fed into the decoder.\nThe cVAE learns a latent space of other factors (like unobserved socio-behavioral factors or stochastic effects).\n\nOnce trained, for a given condition (say “lockdown from day 30”), we can sample different latent vectors to generate a variety of plausible epidemic curves that all reflect that condition. This gives a principled way to explore uncertainty and variability in outcomes.\nWhy cVAE? Unlike a standard deterministic model, a cVAE provides a distribution of outcomes, not just one. This is valuable for risk assessment – e.g., what’s the worst-case scenario vs best-case scenario under a specific intervention?\nNote: This is an advanced technique and an active research area. It combines deep learning’s generative power with the need in epidemiology to quantify uncertainty."
  },
  {
    "objectID": "examples/surrogate_notebook.html",
    "href": "examples/surrogate_notebook.html",
    "title": "Training Surrogates",
    "section": "",
    "text": "Open In Colab\nThis notebook demonstrates how to generate data using a Susceptible-Infected-Recovered (SIR) model with the emidm package. The generated data can be used to train deep learning surrogates for infectious disease modeling.\nThe first two sections (Generate Simulation Data and Prepare Training Dataset) make use of emidm to generate our training data and are provided in brief to show what data is being generated and to ease into the notebook. The next three sections introduce how to train your surrogate model, validate this and explore ways of using this.\nThe last section are possible extensions for those who finish early, which ask you to think about tweaking the code used to test your understanding about how surrogates are trained, or to explore how to use them further analysis."
  },
  {
    "objectID": "examples/surrogate_notebook.html#objectives",
    "href": "examples/surrogate_notebook.html#objectives",
    "title": "Training Surrogates",
    "section": "Objectives",
    "text": "Objectives\n\nSimulate SIR model dynamics using the emidm package.\nGenerate multiple realizations of the model with varying parameters.\nPrepare the simulated data for training deep learning surrogates.\nTrain different surrogate models and compare these\nVisualise performance of surrogates"
  },
  {
    "objectID": "examples/surrogate_notebook.html#enabling-gpu-acceleration",
    "href": "examples/surrogate_notebook.html#enabling-gpu-acceleration",
    "title": "Training Surrogates",
    "section": "Enabling GPU Acceleration",
    "text": "Enabling GPU Acceleration\nTo utilize GPUs for faster training of our neural networks, we need to change the runtime type in your Colab notebook or similar cloud-based environments. Here are the general steps:\n\nNavigate to Runtime Settings:\n\n\nIn Colab, go to “Runtime” &gt; “Change runtime type.”\nIn other environments, look for similar options in the settings or configuration menu.\n\n\nSelect Hardware Accelerator:\n\n\nChoose “GPU” from the “Hardware accelerator” dropdown menu.\n\n\nSave and Restart Runtime:\n\n\nClick “Save” to apply the changes. This will usually restart the runtime environment.\n\n\nVerify GPU Availability:\n\n\nAfter the restart, you can run a code snippet like this to confirm that the GPU is recognized and accessible.\nYou do not need to do this as we will check this later, but if you want to (and want to practice adding a code cell then plaese do\n\nimport torch\n\n     if torch.cuda.is_available():\n         print(\"GPU is available!\")\n         print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n     else:\n         print(\"GPU is not available. Using CPU.\")"
  },
  {
    "objectID": "examples/surrogate_notebook.html#prerequisites",
    "href": "examples/surrogate_notebook.html#prerequisites",
    "title": "Training Surrogates",
    "section": "Prerequisites",
    "text": "Prerequisites\nWe will be using the helper functions in the emidm package, which will be installed and all relevant modules from this as well as other required packages loaded below in two steps.\nFirst we will install emidm from Github:\n\n%pip install git+https://github.com/OJWatson/emidm.git\n\nCollecting git+https://github.com/OJWatson/emidm.git\n  Cloning https://github.com/OJWatson/emidm.git to /tmp/pip-req-build-dndn8y7c\n  Running command git clone --filter=blob:none --quiet https://github.com/OJWatson/emidm.git /tmp/pip-req-build-dndn8y7c\n  Resolved https://github.com/OJWatson/emidm.git to commit 518a34918d2be024332e1b246dca74aca73351c4\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from emidm==0.1) (2.0.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from emidm==0.1) (2.2.2)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas-&gt;emidm==0.1) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas-&gt;emidm==0.1) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas-&gt;emidm==0.1) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;emidm==0.1) (1.17.0)\n\n\nNext we will import any required modules once here. If this works then the rest of the notebook should work 🤞:\n\n# Imports from our own package\nfrom emidm.sir import run_sir, run_model_with_replicates, plot_model_outputs\nfrom emidm.sampler import generate_lhs_samples\n\n# imports of other common packages\nimport pandas as pd\nimport numpy as np\nimport random\nimport os\nimport json\nimport matplotlib.pyplot as plt\n\n# for those who like me prescrbe to Hadley Wickham's one truth of a grammar of graphics\nfrom plotnine import ggplot, aes, geom_line, facet_wrap\n\n# for providing times on notebook for loops\nfrom tqdm.notebook import tqdm\n\n# Import necessary libraries for neural networks and ML aspect\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "examples/surrogate_notebook.html#generate-simulation-data",
    "href": "examples/surrogate_notebook.html#generate-simulation-data",
    "title": "Training Surrogates",
    "section": "1. Generate Simulation Data",
    "text": "1. Generate Simulation Data\n\nRunning a Single SIR Model Simulation\nWe can use emidm to ssimulate the SIR model dynamics using default parameters:\n\n# Demonstrate running one model\nsingle = run_sir()\n\n# Show the output\nsingle\n\n\n  \n    \n\n\n\n\n\n\nt\nN\nS\nI\nR\n\n\n\n\n0\n0\n1000\n990\n10\n0\n\n\n1\n1\n1000\n989\n11\n0\n\n\n2\n2\n1000\n986\n11\n3\n\n\n3\n3\n1000\n983\n13\n4\n\n\n4\n4\n1000\n980\n16\n4\n\n\n...\n...\n...\n...\n...\n...\n\n\n96\n96\n1000\n161\n29\n810\n\n\n97\n97\n1000\n161\n25\n814\n\n\n98\n98\n1000\n161\n23\n816\n\n\n99\n99\n1000\n160\n21\n819\n\n\n100\n100\n1000\n158\n23\n819\n\n\n\n\n101 rows × 5 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nThe output is a pandas DataFrame containing the number of susceptible (S), infected (I), and recovered (R) individuals over time.\nTo visualize the results:\n\n# Show a single plot line\nsingle.plot(\"t\", [\"S\", \"I\", \"R\"])\n\n\n\n\n\n\n\n\nWe can adjust parameters such as the transmission rate (beta) to observe different dynamics:\n\n# We can also vary the parameters\nalt = run_sir(beta = 0.3)\nalt.plot(\"t\", [\"S\", \"I\", \"R\"])\n\n\n\n\n\n\n\n\n\n\nRunning Multiple Stochastic Realisations\nTo account for stochasticity, we can run multiple realizations of the model:\n\n# we can run multiple realisations\nreps = run_model_with_replicates(model = run_sir, reps = 10)\n\n# and plot these\np = plot_model_outputs(reps)\n\n\n\n\n\n\n\n\nAnd we can also pass through any of the arguments to run_sir to our run_model_with_replicates function.\n\n# we can also by args to run_sir through kwargs\nreps = run_model_with_replicates(model=run_sir, reps=10, beta = 0.3)\n\n# and plot these\np = plot_model_outputs(reps, columns = [\"I\", \"R\"])"
  },
  {
    "objectID": "examples/surrogate_notebook.html#prepare-training-dataset",
    "href": "examples/surrogate_notebook.html#prepare-training-dataset",
    "title": "Training Surrogates",
    "section": "2. Prepare Training Dataset",
    "text": "2. Prepare Training Dataset\n\nSampling Parameter Space with Latin Hypercube Sampling\nTo systematically explore the parameter space, we use Latin Hypercube Sampling (LHS), which we have again provided helper functions from emidm for you to use.\n\n# now to generate a lhs sample based on R0 and gamma\ndef beta_gamma_from_r0_gamma(n_samples, param_ranges, seed = None):\n    df_samples = generate_lhs_samples(param_ranges, n_samples=n_samples, seed=seed)\n    df_samples = df_samples.assign(beta = lambda x: x[\"R0\"] * x[\"gamma\"])\n    df_samples = df_samples.drop(columns=[\"R0\"])\n    return df_samples\n\nparam_ranges = {\"R0\": [1.1, 4], \"gamma\": [0.05, 0.25]}\ndf_samples = beta_gamma_from_r0_gamma(n_samples=9, seed=42, param_ranges = param_ranges)\ndf_samples\n\n\n  \n    \n\n\n\n\n\n\ngamma\nbeta\n\n\n\n\n0\n0.129136\n0.401118\n\n\n1\n0.101170\n0.148495\n\n\n2\n0.183875\n0.374429\n\n\n3\n0.165865\n0.569336\n\n\n4\n0.084436\n0.198222\n\n\n5\n0.140516\n0.409444\n\n\n6\n0.231716\n0.878792\n\n\n7\n0.067172\n0.172515\n\n\n8\n0.226360\n0.281483\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nThis generates a set of parameter combinations, which we can then pass to our run_model_with_replicates function. We have just used 9 samples here initially just to show you the outputs and understand it. Later we will generate more samples to build a robust training dataset.\n\n# Run the model for each row of samples:\nresults = [\n    run_model_with_replicates(**row.to_dict(), reps=10).assign(**row.to_dict())\n    for _, row in df_samples.iterrows()\n]\n\n# Combine results into one DataFrame:\ndf_all_results = pd.concat(results, axis=0)\n\n\n# Reshape dataframe into tidy long-format\ndf_long = df_all_results.melt(\n    id_vars=[\"t\", \"replicate\", \"gamma\", \"beta\"],\n    value_vars=[\"S\", \"I\", \"R\"],\n    var_name=\"Compartment\",\n    value_name=\"Value\",\n)\n\n# Add unique identifier for group plotting\ndf_long = df_long.assign(\n    uid=df_long[\"Compartment\"]\n    + df_long[\"replicate\"].astype(str)\n)\n\n# Add facet identifier for group plotting\ndf_long = df_long.assign(\n    facet=\"beta = \"\n    + df_long[\"beta\"].round(3).astype(str)\n    + \",\\n\"\n    + \"gamma = \"\n    + df_long[\"gamma\"].round(3).astype(str)\n)\n\n# Plot: color by compartment, lines grouped by replicate\np = (\n    ggplot(\n        df_long,\n        aes(x=\"t\", y=\"Value\", group=\"uid\", color=\"Compartment\"),\n    )\n    + geom_line(alpha=0.7)\n    + facet_wrap(\"facet\")\n)\n\n# Explicitly plot\nggplot.show(p)\n\n\n\n\n\n\n\n\n\n\nGenerating Training and Test Data\nNow that we have seen how LHS is being used to sample different \\(\\beta\\) and \\(\\gamma\\) parameters and to generate simulations, we will now generate training, validation and test data in much the same way:\n\n# Set random seed for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Create output directory for saving models and plots\noutput_dir = \"emulator_results\"\nos.makedirs(output_dir, exist_ok=True)\n\n# larger training data\nn_train = 1000\nn_test = 200\nn_valid = 100\n\n# generate train samples and data\ntrain_samples = beta_gamma_from_r0_gamma(n_samples=n_train, param_ranges = param_ranges)\ntrain_data = pd.concat([\n    run_model_with_replicates(**row.to_dict(), reps=5).assign(**row.to_dict())\n    for _, row in tqdm(train_samples.iterrows(), total=len(train_samples))\n], axis = 0)\n\n# generate test samples\ntest_samples = beta_gamma_from_r0_gamma(n_samples=n_test, param_ranges = param_ranges)\ntest_data = pd.concat([\n    run_model_with_replicates(**row.to_dict(), reps=5).assign(**row.to_dict())\n    for _, row in tqdm(test_samples.iterrows(), total = len(test_samples))\n], axis = 0)\n\n# generate valid samples\nvalid_samples = beta_gamma_from_r0_gamma(n_samples=n_valid, param_ranges = param_ranges)\nvalid_data = pd.concat([\n    run_model_with_replicates(**row.to_dict(), reps=5).assign(**row.to_dict())\n    for _, row in tqdm(valid_samples.iterrows(), total = len(valid_samples))\n], axis = 0)"
  },
  {
    "objectID": "examples/surrogate_notebook.html#train-a-neural-network",
    "href": "examples/surrogate_notebook.html#train-a-neural-network",
    "title": "Training Surrogates",
    "section": "3. Train a neural network",
    "text": "3. Train a neural network\n\nCreating Dataset Class and Dataloader\nWhile we have generated our training and test data, we need to prepare it into a PyTorch dataset and dataloader. The dataloader is a way of iterating through our data in batches, which is useful for training deep learning models. Batches are used to train the model in mini-batches, which is more efficient than training on the entire dataset at once. It also has the advantage of allowing us to use GPU acceleration if available.\nWe have not created this dataset class yet in emidm, so that we can show you how it works, so we will do that next. We will also use this an opportunity to learn a bit more about PyTorch and also how (more often) Python leverages classes.\n\nclass SIRTimeSeriesDataset(Dataset):\n    def __init__(self, dataframe, features=['beta', 'gamma'], targets=['S', 'I']):\n        self.features = features\n        self.targets = targets\n\n        # Group by parameter sets\n        self.grouped = dataframe.groupby(features + ['replicate'])\n        self.param_sets = list(self.grouped.groups.keys())\n        self.dataframe = dataframe\n\n        # Extract timepoints (assuming they're the same for all parameter sets)\n        self.timepoints = dataframe['t'].unique()\n        self.time_length = len(self.timepoints)\n        self.N = dataframe['N'].iloc[0]\n\n        # Create samples\n        self.samples = []\n        for param_set in self.param_sets:\n            df_group = self.grouped.get_group(param_set).sort_values('t')\n\n            # Extract feature and target time series\n            feature_values = np.array([param_set[features.index('beta')],\n                                      param_set[features.index('gamma')]])\n\n            # Extract full target time series\n            target_series = np.column_stack([df_group[target].values / self.N for target in targets])\n\n            # Store full time series with parameter info\n            self.samples.append({\n                'features': feature_values,\n                'targets': target_series,\n                'param_values': param_set\n            })\n\n        # Normalize input features\n        feature_array = np.array([s['features'] for s in self.samples])\n        self.feature_scaler = StandardScaler()\n        self.feature_scaler.fit(feature_array)\n\n        # No need to normalize S and I as they're already in [0,1] range\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n\n        # Normalize features\n        features_normalized = self.feature_scaler.transform(sample['features'].reshape(1, -1)).flatten()\n\n        return torch.tensor(features_normalized, dtype=torch.float32), \\\n               torch.tensor(sample['targets'], dtype=torch.float32)\n\nHaving made our daaSIRTimeSeriesDataset class, we can use this to create a SIRTimeSeriesDataset object for each of our different data sets (train, validation, test).\nAfter this we then create DataLoaders. This is a PyTorch class used to efficiently iterate through the datasets during training. It handles tasks like batching, shuffling (for the training set), and potentially loading data in parallel.\nBatching controls the size of the data that will be fed to the model, which here we are doing in groups of 64 samples at a time.\n\n# Create datasets\ntrain_dataset = SIRTimeSeriesDataset(train_data)\nval_dataset = SIRTimeSeriesDataset(valid_data)\ntest_dataset = SIRTimeSeriesDataset(test_data)\n\n# Create data loaders\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n\nBatch Size Explained\nIn the code above, batch_size is set to 64. This means that during training, the model will see 64 samples of data before updating its internal parameters (weights and biases). This process of seeing a batch of data and then updating is called one iteration.\nInstead of training on the entire dataset at once (which can be computationally expensive and memory-intensive), the data is divided into smaller batches. The model iterates through these batches, making adjustments to its parameters after seeing each batch.\n\nWhy Use Batches?\n\nComputational Efficiency: Processing the entire dataset in one go can be very slow, especially for large datasets. Batches make the process more manageable by breaking it down into smaller steps. This is crucial for training deep learning models which often require vast amounts of data.\nMemory Management: Loading the entire dataset into memory might not be feasible, especially when dealing with very large datasets or limited hardware resources. Batching allows the model to work with a smaller subset of the data at any given time, reducing memory requirements.\nGeneralization: Training on batches can improve the model’s ability to generalize to unseen data. This is because the model is exposed to a variety of data points in each batch, preventing it from overfitting to specific examples in the training set. Updates based on a single data point at a time (e.g., with a batch size of 1 which is called stochastic gradient descent) could update the weights in a way that is not good for the model’s prediction performance over all of the data. Using batches provides a better average for what data the model tends to see and thus better update performance.\nNoise Reduction: The gradients (directions for updating model parameters) calculated on a batch are less noisy compared to those calculated on individual samples. This leads to more stable and smoother training, potentially helping the model converge faster to a good solution.\n\n\n\nChoosing the Right Batch Size\nThe choice of batch size is a hyperparameter that can significantly impact the training process. There’s no one-size-fits-all answer, and the optimal batch size often depends on factors like:\n\nDataset Size: Larger datasets can handle larger batch sizes, while smaller datasets might require smaller batches to avoid overfitting.\nModel Architecture: Complex models with many parameters might benefit from larger batch sizes for better gradient estimations.\nHardware: Available memory and processing power influence the maximum batch size you can use.\nTraining Time: Larger batches can lead to faster training epochs (one pass through the entire dataset), but they might require more epochs to converge. Smaller batches require more iterations per epoch and are usually slower but are helpful in preventing issues like overfitting.\n\nIn Practice:\n\nCommon Batch Sizes: 32, 64, 128, 256 are frequently used batch sizes.\nExperimentation: It’s often necessary to experiment with different batch sizes to find the best one for a particular problem. You can evaluate performance on a validation set to guide your choice.\n\n\n\n\n\nBuilding Neural Network Models\nThis section of the code defines and trains three different types of neural networks to predict the Susceptible (S) and Infected (I) populations in the SIR model given the input parameters beta and gamma.\nBefore we delve into the specific model types, let’s define some key terminology in neural networks:\n\nInput Size: The number of input features to the network. In this case, it’s 2, representing beta and gamma.\nHidden Size: The number of neurons in the hidden layers of the network. This controls the complexity and capacity of the model. A larger hidden size means the model can learn more complex patterns but might be prone to overfitting. Here, hidden_size is set to 64.\nOutput Size: The number of output values the network produces. Here, it’s 2, corresponding to the predicted S and I values.\nLayers: Neural networks consist of interconnected layers of neurons. Hidden layers process the input data and extract features, while the output layer produces the final predictions. Deeper networks (more hidden layers) can learn more complex relationships, but they are also more computationally intensive to train. This code uses hidden layers.\nDropout: A regularization technique that helps prevent overfitting. During training, dropout randomly ignores a fraction of the neurons in a layer, forcing the network to learn more robust features that are not dependent on any single neuron. dropout_prob (set to 0.1 here) controls the probability of a neuron being dropped out.\n\n\n# Define constants\ninput_size = 2  # beta and gamma\nhidden_size = 64\noutput_size = 2  # S and I\nnum_layers = 2\ndropout_prob = 0.1\n\n\nFeedforward Neural Network (FFNN)\nThis is the simplest type of neural network, where data flows in one direction from input to output. It has multiple layers, each containing a number of neurons (or units). It uses dropout for regularization, with a probability defined by dropout_prob that a neuron is ignored in a given step. It also has batch normalization and ReLU activation function for each hidden layer.\nIn our case, The FFNN model takes \\(\\beta\\) and \\(\\gamma\\) as input and aims to predict the time series of S and I values. Here’s a simplified breakdown of how it works:\n\nInput: The input values (beta and gamma) are fed into the first layer of the network.\nHidden Layers: The input values are processed through a series of hidden layers. Each layer consists of neurons that perform calculations on the input data using weights and biases.\n\nThe output of each neuron is passed through an activation function (ReLU here), which introduces non-linearity to the model.\nDropout is applied within the hidden layers to prevent overfitting.\nBatch normalization is used to improve training stability and performance by normalizing the inputs to each layer.\n\nOutput Layer: The final hidden layer’s output is fed to the output layer, which produces the predictions for S and I. The output uses a sigmoid activation function, ensuring output values are between 0 and 1, representing the proportion of the population.\nTraining: During training, the network’s weights and biases are adjusted to minimize the difference between the predicted and actual S and I values (the loss). This adjustment is done using an optimization algorithm like Adam.\n\n\n# Feedforward Neural Network\nclass FFNN(nn.Module):\n    def __init__(self, input_size, hidden_size, time_steps, output_channels):\n        super(FFNN, self).__init__()\n        self.time_steps = time_steps\n        self.output_channels = output_channels\n        self.sigmoid = nn.Sigmoid()\n\n        # Deeper network with dropout and batch normalization\n        self.network = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.BatchNorm1d(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(dropout_prob),\n\n            nn.Linear(hidden_size, hidden_size*2),\n            nn.BatchNorm1d(hidden_size*2),\n            nn.ReLU(),\n            nn.Dropout(dropout_prob),\n\n            nn.Linear(hidden_size*2, hidden_size*2),\n            nn.BatchNorm1d(hidden_size*2),\n            nn.ReLU(),\n            nn.Dropout(dropout_prob),\n\n            nn.Linear(hidden_size*2, time_steps * output_channels)\n        )\n\n    def forward(self, x):\n        # Output shape: [batch_size, time_steps, output_channels]\n        output = self.network(x)\n        output = output.view(-1, self.time_steps, self.output_channels)\n        output = self.sigmoid(output)  # Apply sigmoid\n        return output\n\n\n\nGated Recurrent Unit (GRU)\nThis is a type of recurrent neural network (RNN) that is designed to handle sequential data, like the time series data from the SIR model. GRUs have a special mechanism called “gates” that help them learn long-term dependencies in the data. The key features of GRUs are:\n\nUpdate Gate: Decides how much past information to keep and how much to update.\nReset Gate: Controls how much past information to ignore when computing the new state.\nHidden State: Represents the current input and relevant past information.\n\nHow it Works Here:\n\nInside the forward method of the GRUModel, this input vector is projected to a higher-dimensional space and then repeated for each time step to create a sequence (x_seq). This effectively creates a constant input sequence where the same beta and gamma values are presented to the GRU at each time step.\nThe GRU layer then processes this input sequence, but its primary focus is on learning the temporal relationships within the output sequence (S and I over time). The hidden state of the GRU evolves based on both the input and the previous hidden state, capturing the dynamic changes in S and I as the SIR model progresses.\n\n\n# GRU Model\nclass GRUModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, dropout_prob, num_layers=2):\n        super(GRUModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.sigmoid = nn.Sigmoid()\n\n        # Project parameters to a sequence\n        self.input_projection = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU()\n        )\n\n        # GRU layer\n        self.gru = nn.GRU(\n            hidden_size, hidden_size,\n            num_layers=num_layers,\n            dropout=dropout_prob if num_layers &gt; 1 else 0.0,\n            batch_first=True\n        )\n\n        # Output layers\n        self.fc = nn.Linear(hidden_size, output_size)\n        self.ln = nn.LayerNorm(hidden_size)\n        self.dropout = nn.Dropout(dropout_prob)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        time_steps = train_dataset.time_length\n\n        # Create a sequence from the parameter input\n        x_seq = self.input_projection(x).unsqueeze(1).repeat(1, time_steps, 1)\n\n        # Process with GRU\n        out, _ = self.gru(x_seq)\n        out = self.ln(out)\n        out = self.dropout(out)\n        out = self.fc(out)\n\n        # Apply sigmoid activation\n        out = self.sigmoid(out)\n        return out\n\n\n\nLong Short-Term Memory (LSTM)\nThis is another type of RNN, closely related to GRUs, also designed to handle sequential data like the time series from the SIR model. LSTMs use a more complex gating mechanism than GRUs, involving three gates (input, forget, output) and a cell state, enabling them to learn long-term dependencies and handle vanishing gradients effectively. The key features of LSTMs are:\n\nInput Gate: Regulates the flow of new information into the cell state.\nForget Gate: Controls what information to discard from the cell state.\nOutput Gate: Determines what information from the cell state is outputted.\nCell State: Acts as a memory unit, storing and carrying information across time steps.\nHidden State: Represents the current output and is influenced by the cell state and the output gate.\n\nHow it Works Here:\nSimilar to the GRU, inside the forward method of the LSTMModel, the input vector is projected to a higher-dimensional space and repeated for each time step to form a sequence (x_seq). This creates a constant input sequence where the same beta and gamma values are presented to the LSTM at each time step.\nThe LSTM layer processes this input sequence, but its primary focus is on learning the temporal relationships within the output sequence (S and I over time). Using its three gates and the cell state, the LSTM carefully controls the flow of information, allowing it to selectively remember and forget relevant parts of the past while updating its hidden state to capture the dynamic changes in S and I as the SIR model progresses.\n\n# LSTM Model\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, dropout_prob, num_layers=2):\n        super(LSTMModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.sigmoid = nn.Sigmoid()\n\n        # Project parameters to a sequence\n        self.input_projection = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU()\n        )\n\n        # LSTM layer\n        self.lstm = nn.LSTM(\n            hidden_size, hidden_size,\n            num_layers=num_layers,\n            dropout=dropout_prob if num_layers &gt; 1 else 0.0,\n            batch_first=True\n        )\n\n        # Output layers\n        self.fc = nn.Linear(hidden_size, output_size)\n        self.ln = nn.LayerNorm(hidden_size)\n        self.dropout = nn.Dropout(dropout_prob)\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        time_steps = train_dataset.time_length\n\n        # Create a sequence from the parameter input\n        x_seq = self.input_projection(x).unsqueeze(1).repeat(1, time_steps, 1)\n\n        # Process with LSTM\n        out, _ = self.lstm(x_seq)\n        out = self.ln(out)\n        out = self.dropout(out)\n        out = self.fc(out)\n\n        # Apply sigmoid activation\n        out = self.sigmoid(out)\n        return out\n\n\n\n\nCreating and Training Our Models\nNow that we have created our NN classes, we can initialise these models, and determine whether a GPU is available for computation (it should be if you changed your Runtime earlier).\nIf a GPU is found (torch.cuda.is_available() returns True), it sets the device to ‘cuda’ (indicating GPU usage); otherwise, it defaults to ‘cpu’ for CPU-based calculations.\n\n# Initialize models\nffnn_model = FFNN(input_size, hidden_size, train_dataset.time_length, output_size)\ngru_model = GRUModel(input_size, hidden_size, output_size, dropout_prob, num_layers)\nlstm_model = LSTMModel(input_size, hidden_size, output_size, dropout_prob, num_layers)\n\n# Move models to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nffnn_model = ffnn_model.to(device)\ngru_model = gru_model.to(device)\nlstm_model = lstm_model.to(device)\n\nprint(f\"Models initialized and moved to {device}\")\n\nModels initialized and moved to cuda\n\n\n\nModel Training\nBelow, we have provided the train_model function, which trains the neural network models using the following steps:\n\nInitialization:\n\nDefines the loss function (nn.MSELoss for Mean Squared Error).\nSets up the optimizer (torch.optim.Adam) to update model parameters.\nCreates a learning rate scheduler (ReduceLROnPlateau) to adjust the learning rate by a factor (here, 0.5) when the validation stops improving for a certain number of epochs (here, patience=5).\nEarly stopping criterria are also set, so if there is no improvement in validation loss for a number of epochs (here, patience=10), then training is stopped earlier.\n\nTraining Loop:\n\nIterates through a specified number of epochs.\nTraining Phase:\n\nThe model is set to training mode (model.train()).\nProcesses batches of training data, making predictions and calculating the loss:\n\nForward Pass: The model makes predictions (outputs) based on the input data (inputs).\nCalculate Loss: The loss function (criterion) is used to calculate the error between the predictions (outputs) and the actual target values (targets)\nBackward Pass and Optimise: optimizer.zero_grad() resets the gradients of the model’s parameters. loss.backward() calculates the gradients of the loss with respect to the model’s parameters. optimizer.step() updates the model’s parameters based on the calculated gradients and the learning rate.\n\nTracks the average training loss for the epoch.\n\nValidation Phase:\n\nThe model is set to evaluation mode (model.eval()).\nProcesses batches of validation data, making predictions and calculating the validation loss (without updating model parameters).\nTracks the average validation loss for the epoch.\n\n\nModel Saving and Early Stopping:\n\nSaves the best model (lowest validation loss) during training.\nImplements early stopping to prevent overfitting if the validation loss doesn’t improve for a certain number of epochs.\n\nReturning Results:\n\nReturns the trained model and a history dictionary containing training and validation losses, epochs, and information about the best model.\n\n\n\ndef train_model(model, train_loader, val_loader, epochs, lr, model_name, device, patience=10):\n    # Initialize criterion, optimizer and scheduler\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n\n    # For tracking loss and best model\n    train_losses = []\n    val_losses = []\n    best_val_loss = float('inf')\n    patience_counter = 0\n    best_epoch = 0\n\n    # Path to save best model\n    best_model_path = os.path.join(output_dir, f\"{model_name}_best.pt\")\n\n    for epoch in range(1, epochs + 1):\n        # Training phase\n        model.train()\n        total_train_loss = 0.0\n\n        for inputs, targets in train_loader:\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n\n            # Calculate loss\n            loss = criterion(outputs, targets)\n\n            # Backward pass and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_train_loss += loss.item() * inputs.size(0)\n\n        # Calculate average training loss\n        avg_train_loss = total_train_loss / len(train_loader.dataset)\n        train_losses.append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        total_val_loss = 0.0\n\n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs = inputs.to(device)\n                targets = targets.to(device)\n\n                # Forward pass\n                outputs = model(inputs)\n\n                # Calculate loss\n                loss = criterion(outputs, targets)\n                total_val_loss += loss.item() * inputs.size(0)\n\n        # Calculate average validation loss\n        avg_val_loss = total_val_loss / len(val_loader.dataset)\n        val_losses.append(avg_val_loss)\n\n        # Update scheduler\n        scheduler.step(avg_val_loss)\n\n        # Print progress every 10 epochs\n        if epoch % 10 == 0:\n            print(f'Epoch {epoch}/{epochs}, {model_name} - '\n                  f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n\n        # Check if this is the best model so far\n        if avg_val_loss &lt; best_val_loss:\n            best_val_loss = avg_val_loss\n            best_epoch = epoch\n            patience_counter = 0\n\n            # Save the best model\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_loss': avg_val_loss,\n                'train_loss': avg_train_loss\n            }, best_model_path)\n\n            print(f\"New best model saved at epoch {epoch} with validation loss: {avg_val_loss:.6f}\")\n        else:\n            patience_counter += 1\n            if epoch % 10 == 0:\n                print(f\"Validation loss did not improve. Patience: {patience_counter}/{patience}\")\n\n        # Early stopping check\n        if patience_counter &gt;= patience:\n            print(f\"Early stopping triggered after {epoch} epochs. Best was epoch {best_epoch}.\")\n            break\n\n    # Save training history\n    history = {\n        'train_loss': train_losses,\n        'val_loss': val_losses,\n        'epochs': list(range(1, len(train_losses) + 1)),\n        'best_epoch': best_epoch,\n        'best_val_loss': best_val_loss\n    }\n\n    with open(os.path.join(output_dir, f\"{model_name}_history.json\"), 'w') as f:\n        json.dump(history, f)\n\n    # Load the best model\n    checkpoint = torch.load(best_model_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n\n    return model, history\n\n\nWe can now actually train our models!\n\n# Set training parameters\nlearning_rate = 1e-3\nnum_epochs = 100\npatience = 10\n\nprint(\"Training FFNN model...\")\nffnn_model, ffnn_history = train_model(\n    ffnn_model, train_loader, val_loader, num_epochs, learning_rate, \"ffnn\", device, patience\n)\n\nprint(\"Training GRU model...\")\ngru_model, gru_history = train_model(\n    gru_model, train_loader, val_loader, num_epochs, learning_rate, \"gru\", device, patience\n)\n\nprint(\"Training LSTM model...\")\nlstm_model, lstm_history = train_model(\n    lstm_model, train_loader, val_loader, num_epochs, learning_rate, \"lstm\", device, patience\n)\n\nTraining FFNN model...\n\n\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n\n\nNew best model saved at epoch 1 with validation loss: 0.005126\nNew best model saved at epoch 2 with validation loss: 0.004278\nNew best model saved at epoch 3 with validation loss: 0.002465\nNew best model saved at epoch 4 with validation loss: 0.002412\nNew best model saved at epoch 6 with validation loss: 0.002259\nNew best model saved at epoch 7 with validation loss: 0.002001\nEpoch 10/100, ffnn - Train Loss: 0.0038, Val Loss: 0.0022\nValidation loss did not improve. Patience: 3/10\nNew best model saved at epoch 14 with validation loss: 0.001909\nEpoch 20/100, ffnn - Train Loss: 0.0033, Val Loss: 0.0024\nValidation loss did not improve. Patience: 6/10\nNew best model saved at epoch 24 with validation loss: 0.001860\nEpoch 30/100, ffnn - Train Loss: 0.0034, Val Loss: 0.0026\nValidation loss did not improve. Patience: 6/10\nEarly stopping triggered after 34 epochs. Best was epoch 24.\nTraining GRU model...\n\n\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n\n\nNew best model saved at epoch 1 with validation loss: 0.007618\nNew best model saved at epoch 2 with validation loss: 0.004958\nNew best model saved at epoch 4 with validation loss: 0.002279\nNew best model saved at epoch 5 with validation loss: 0.001895\nNew best model saved at epoch 8 with validation loss: 0.001868\nEpoch 10/100, gru - Train Loss: 0.0024, Val Loss: 0.0017\nNew best model saved at epoch 10 with validation loss: 0.001749\nNew best model saved at epoch 12 with validation loss: 0.001736\nNew best model saved at epoch 13 with validation loss: 0.001695\nEpoch 20/100, gru - Train Loss: 0.0020, Val Loss: 0.0019\nValidation loss did not improve. Patience: 7/10\nNew best model saved at epoch 23 with validation loss: 0.001627\nEpoch 30/100, gru - Train Loss: 0.0019, Val Loss: 0.0017\nValidation loss did not improve. Patience: 7/10\nNew best model saved at epoch 32 with validation loss: 0.001612\nNew best model saved at epoch 39 with validation loss: 0.001605\nEpoch 40/100, gru - Train Loss: 0.0019, Val Loss: 0.0017\nValidation loss did not improve. Patience: 1/10\nNew best model saved at epoch 46 with validation loss: 0.001600\nEpoch 50/100, gru - Train Loss: 0.0019, Val Loss: 0.0016\nValidation loss did not improve. Patience: 4/10\nEarly stopping triggered after 56 epochs. Best was epoch 46.\nTraining LSTM model...\n\n\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n\n\nNew best model saved at epoch 1 with validation loss: 0.006858\nNew best model saved at epoch 2 with validation loss: 0.003884\nNew best model saved at epoch 3 with validation loss: 0.002322\nNew best model saved at epoch 6 with validation loss: 0.001754\nEpoch 10/100, lstm - Train Loss: 0.0024, Val Loss: 0.0018\nValidation loss did not improve. Patience: 4/10\nNew best model saved at epoch 13 with validation loss: 0.001706\nNew best model saved at epoch 19 with validation loss: 0.001700\nEpoch 20/100, lstm - Train Loss: 0.0021, Val Loss: 0.0018\nValidation loss did not improve. Patience: 1/10\nNew best model saved at epoch 21 with validation loss: 0.001685\nNew best model saved at epoch 24 with validation loss: 0.001647\nNew best model saved at epoch 26 with validation loss: 0.001610\nEpoch 30/100, lstm - Train Loss: 0.0020, Val Loss: 0.0017\nValidation loss did not improve. Patience: 4/10\nEarly stopping triggered after 36 epochs. Best was epoch 26.\n\n\n\n\n\nModel Training History\nBelow we visualize the training history of three different neural network models (FFNN, GRU, and LSTM), showing the training loss and validation loss over the training epochs and highlighting the epoch where each model achieved its best validation performance.\nThis is important to track the learning process of each model and evaluate their overall performance, and potentially assess for overfitting to the training data, in which training loss can be low but the validation loss is not decreasing. This could require changing model parameters such as hidden_size, the number of hidden layers in the network, or using more regularisation techniques.\nHowever, for these simple models, we will see that the models train well and reaching best performance quickly.\n\nplt.figure(figsize=(15, 5))\n\n# Plot FFNN losses\nplt.subplot(1, 3, 1)\nplt.plot(ffnn_history['epochs'], ffnn_history['train_loss'], label='Train Loss')\nplt.plot(ffnn_history['epochs'], ffnn_history['val_loss'], label='Validation Loss')\nplt.axvline(x=ffnn_history['best_epoch'], color='r', linestyle='--',\n            label=f\"Best epoch ({ffnn_history['best_epoch']})\")\nplt.title('FFNN Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(alpha=0.3)\n\n# Plot GRU losses\nplt.subplot(1, 3, 2)\nplt.plot(gru_history['epochs'], gru_history['train_loss'], label='Train Loss')\nplt.plot(gru_history['epochs'], gru_history['val_loss'], label='Validation Loss')\nplt.axvline(x=gru_history['best_epoch'], color='r', linestyle='--',\n            label=f\"Best epoch ({gru_history['best_epoch']})\")\nplt.title('GRU Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(alpha=0.3)\n\n# Plot LSTM losses\nplt.subplot(1, 3, 3)\nplt.plot(lstm_history['epochs'], lstm_history['train_loss'], label='Train Loss')\nplt.plot(lstm_history['epochs'], lstm_history['val_loss'], label='Validation Loss')\nplt.axvline(x=lstm_history['best_epoch'], color='r', linestyle='--',\n            label=f\"Best epoch ({lstm_history['best_epoch']})\")\nplt.title('LSTM Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, \"training_history.png\"))\nplt.show()"
  },
  {
    "objectID": "examples/surrogate_notebook.html#validate-the-model",
    "href": "examples/surrogate_notebook.html#validate-the-model",
    "title": "Training Surrogates",
    "section": "4. Validate the model",
    "text": "4. Validate the model\nNow that we have trained the models, and checked for possible issues around overfitting, we can start using these to make predictions.\nTo do so, we have created a simple function predict_random_samples which predicts the time series of S and I for random samples of beta and gamma combinations from a provided SIRTimeSeriesDataset. The function makes predictions for whichever models you pass, and from the predictions creates a data frame with the predictions as well as the equivalent ground-truth from the actual SIR model.\n\ndef predict_random_samples(models, dataset, model_names, num_samples=9, features=['beta', 'gamma'], targets=['S', 'I']):\n    \"\"\"\n    Predicts the time series of S and I for random samples of beta and gamma combinations,\n    compares to ground truth, and returns a DataFrame with predictions and ground truth.\n\n    Args:\n        models: List of trained models [FFNN, GRU, LSTM].\n        dataset: The dataset containing the input features and target values.\n        model_names: List of model names [\"FFNN\", \"GRU\", \"LSTM\"].\n        num_samples: Number of random samples to generate (default: 9).\n        features: List of feature names (default: ['beta', 'gamma']).\n        targets: List of target names (default: ['S', 'I']).\n\n    Returns:\n        df_long: A Pandas DataFrame containing predictions, ground truth, and metadata.\n    \"\"\"\n    all_predictions = []\n\n    # Get unique beta and gamma combinations (ignoring replicates)\n    unique_combinations = [tuple(param_set[:2]) for param_set in dataset.param_sets]  # Extract only beta and gamma\n    unique_combinations = list(set(unique_combinations))  # Remove duplicates\n    selected_combinations = random.sample(unique_combinations, num_samples)\n    for model, model_name in zip(models, model_names):\n      model.eval()  # Set model to evaluation mode\n      for beta, gamma in selected_combinations:\n        # Normalize features using the dataset's scaler\n        features_values = np.array([beta, gamma])  # Create features array\n        features_normalized = dataset.feature_scaler.transform(features_values.reshape(1, -1)).flatten()\n\n        # Normalize features using the dataset's scaler\n        features_normalized = dataset.feature_scaler.transform(features_values.reshape(1, -1)).flatten()\n\n        # Create input tensor\n        inputs = torch.tensor(features_normalized, dtype=torch.float32).unsqueeze(0).to(device)\n\n\n        # Predict using the model\n        with torch.no_grad():\n            predictions = model(inputs).cpu().numpy().squeeze()\n\n        # Store predictions and ground truth for each replicate\n        for t in range(predictions.shape[0]):\n            all_predictions.append({\n                'model': model_name,  # Add model name\n                **dict(zip(features, features_values)),\n                **dict(zip(targets, predictions[t]*test_dataset.N)),\n                't': t\n            })\n\n    # Create DataFrame for plotting\n    df_predictions = pd.DataFrame(all_predictions)\n    df_predictions = df_predictions.assign(replicate = 0)\n    df_predictions = df_predictions.assign(N = test_dataset.N)\n    df_predictions = df_predictions.assign(R = test_dataset.N - df_predictions[\"I\"] - df_predictions[\"S\"])\n\n    # Create filtered of test_data\n    filtered_test_data = dataset.dataframe[test_data[['beta', 'gamma']].apply(tuple, axis=1).isin(df_predictions[['beta', 'gamma']].apply(tuple, axis=1))]\n    filtered_test_data = filtered_test_data.assign(model=\"TRUTH\")\n    # Combine\n    df_combine = pd.concat([filtered_test_data, df_predictions])\n\n    return df_combine\n\n\nWhen we created our datasets, we kept one dataset back to be our test dataset, which will use here by selecting 9 random combinations of \\(\\beta\\) and \\(\\gamma\\) and creating the predictions of each model as well as the true SIR model runs.\n\ndf_predictions = predict_random_samples(\n    models = [ffnn_model, gru_model, lstm_model],\n    dataset = test_dataset,\n    model_names = [\"FFNN\", \"GRU\", \"LSTM\"],\n    num_samples = 9\n    )\n\nWe can then wrangle this into long data and return to our beloved ggplot style for plotting the model predictions and the replicates of the stochastic SIR model.\n\n# Reshape dataframe into tidy long-format\ndf_long_preds = df_predictions.melt(\n    id_vars=[\"t\", \"gamma\", \"beta\", \"replicate\", \"model\"],  # Include model in id_vars\n    value_vars=[\"S\", \"I\", \"R\"],\n    var_name=\"Compartment\",\n    value_name=\"Value\",\n)\n\n# Add unique identifier for group plotting\ndf_long_preds = df_long_preds.assign(\n    uid=df_long_preds[\"Compartment\"]\n    + df_long_preds[\"replicate\"].astype(str)\n    + df_long_preds[\"model\"].astype(str)\n)\n\n# Add facet identifier for group plotting\ndf_long_preds = df_long_preds.assign(\n    facet=\"beta = \"\n    + df_long_preds[\"beta\"].round(3).astype(str)\n    + \",\\n\"\n    + \"gamma = \"\n    + df_long_preds[\"gamma\"].round(3).astype(str)\n)\n\np = (\n    ggplot(\n        df_long_preds,\n        aes(x=\"t\", y=\"Value\", group=\"uid\", color=\"Compartment\", linetype=\"model\"),\n    )\n    + geom_line(alpha=0.7)\n    + facet_wrap(\"facet\")\n)\nggplot.show(p)"
  },
  {
    "objectID": "examples/surrogate_notebook.html#conclusion",
    "href": "examples/surrogate_notebook.html#conclusion",
    "title": "Training Surrogates",
    "section": "Conclusion",
    "text": "Conclusion\nIn this notebook, we explored the process of building and training deep learning surrogates for infectious disease modeling using the SIR model as an example. We covered the following key steps:\n\nData Generation: We used the emidm package to simulate SIR model dynamics with varying parameters using Latin Hypercube Sampling (LHS) to systematically explore the parameter space and generate training, validation, and test datasets.\nData Preparation: We created a custom PyTorch Dataset class (SIRTimeSeriesDataset) to efficiently handle the time series data and implemented DataLoader for batch processing during training.\nModel Building and Training: We defined and trained three different neural network architectures:\n\nFeedforward Neural Network (FFNN): A basic neural network with multiple layers.\nGated Recurrent Unit (GRU): A recurrent neural network designed for sequential data.\nLong Short-Term Memory (LSTM): Another recurrent neural network with more complex gating mechanisms. We trained these models using the Adam optimizer and a learning rate scheduler, monitoring their performance on validation data to prevent overfitting. We also applied a sigmoid activation function to the final layer of each model to ensure the predictions were bound between 0 and 1.\n\nModel Validation: We assessed the trained models’ performance by predicting on a held-out test dataset and comparing the predictions to the ground truth SIR model simulations.\nVisualization: We visualized the training history, showing the training and validation losses over epochs, and highlighted the best-performing epochs for each model."
  },
  {
    "objectID": "examples/surrogate_notebook.html#extensions-for-further-exploration",
    "href": "examples/surrogate_notebook.html#extensions-for-further-exploration",
    "title": "Training Surrogates",
    "section": "Extensions for Further Exploration",
    "text": "Extensions for Further Exploration\nIf you’ve completed the main sections of this notebook and have some extra time, consider exploring these extensions to deepen your understanding of surrogate modeling.\n\n1. Hyperparameter Tuning\nChallenge: Experiment with different hyperparameters of the neural network models (e.g., hidden size, number of layers, dropout rate, learning rate) to see how they affect performance.\nHint: Use a grid search or random search approach to systematically explore different hyperparameter combinations and evaluate their impact on validation loss.\nCode Snippet (Grid Search Example):\nimport itertools\n\n# Define hyperparameter ranges\nhidden_sizes = [32, 64, 128]\nnum_layers = [1, 2, 3]\ndropout_rates = [0.1, 0.2, 0.3]\n\n# Create all possible combinations\nhyperparameter_combinations = list(itertools.product(hidden_sizes, num_layers, dropout_rates))\n\n# Loop through combinations and train models\nfor hidden_size, num_layers, dropout_rate in hyperparameter_combinations:\n\n# Create and train model with current hyperparameters\n# ...\n\n\n2. Capturing Stochastic Uncertainty\nChallenge: Modify the models to predict the variance in stochastic replicates over time, rather than just the point estimate. This can be used to create a surrogate that captures stochastic uncertainty, providing a more comprehensive representation of the SIR model’s behavior.\nHint: Instead of predicting only the mean values of S and I, train the models to predict both the mean and variance (or standard deviation) for each time step. You’ll need to adjust the output layer of the models and modify the loss function to account for both mean and variance predictions. You can consider using metrics like the negative log-likelihood (NLL) for evaluating the performance of models predicting distributions.\nCode Snippet (Modifying the FFNN model):\nclass FFNN(nn.Module):\n\n    def forward(self, x):\n        # Output now includes both mean and variance\n        output = self.network(x)\n        output = output.view(-1, self.time_steps, self.output_channels, 2)\n        mean = self.sigmoid(output[:, :, :, 0])\n        variance = self.softplus(output[:, :, :, 1])  \n        return mean, variance\n\nFurther Hint: Instead of predicting only the mean values of S and I, train the models to predict both the mean and variance (or standard deviation) for each time step. You’ll need to adjust the output layer of the models and modify the loss function to account for both mean and variance predictions. Importantly, you’ll also need to change the SIRTimeSeriesDataset class to ensure that all stochastic replicates for a given parameter set are available during training, as the model now needs to learn the distribution of outcomes. You can consider using metrics like the negative log-likelihood (NLL) for evaluating the performance of models predicting distributions.\n\n\n\n3. Surrogate-Assisted Inference\nChallenge: Use the trained surrogate model to perform tasks like parameter estimation or sensitivity analysis, which are typically computationally expensive with the original SIR model.\nHint: You can use optimization algorithms to find parameter values that minimize the difference between the surrogate’s predictions and observed data. For parameter estimation, you can define an objective function that calculates the loss between the surrogate’s predictions and the observed data for a given set of parameters. Then, use an optimization algorithm like scipy.optimize.minimize to find the parameter values that minimize this loss. For sensitivity analysis, you can vary the input parameters of the surrogate model and observe the corresponding changes in the output to understand the model’s sensitivity to different parameters.\nCode Snippet (Parameter Estimation):\nscipy.optimize import minimize\n\ndef objective_function(params, surrogate_model, observed_data):\n  # ... (calculate surrogate predictions using params) ...\n  # ... (calculate difference between predictions and observed_data) ...\n  return loss\n\n# Perform optimization\nresult = minimize(objective_function, initial_params, args=(surrogate_model, observed_data))\n\n\nFurther Hint: You can generate your own observed data by simulating an SIR epidemic using the functions from emidm. Or you could get data from a real outbreak from https://www.reconverse.org/outbreaks/, e.g. the outbreak of influenza A (H1N1) in 1978 at a British boarding school of 763 children and changing your data generation to use a different N."
  }
]